# app.py
# -*- coding: utf-8 -*-
# KRW Momentum Radar - v3.0.7
# 
# ì£¼ìš” ê¸°ëŠ¥:
# - FMS(Fast Momentum Score) ê¸°ë°˜ ëª¨ë©˜í…€ ë¶„ì„
# - ë‹¤êµ­ê°€ ì‹œì¥ í†µí•© ë¶„ì„ (ë¯¸êµ­, í•œêµ­, ì¼ë³¸)
# - ìˆ˜ìµë¥ -ë³€ë™ì„± ì´ë™ë§µ (ì •ì /ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œ)
# - ì‹¤ì‹œê°„ ë°ì´í„° ì—…ë°ì´íŠ¸ ë° ì‹œê°í™”
# - ë™ì  ê´€ì‹¬ì¢…ëª© ê´€ë¦¬ ë° ì‹ ê·œ ì¢…ëª© íƒìƒ‰ ì—”ì§„
#
# v3.0.4 ê°œì„ ì‚¬í•­:
# - FMS ì „ëµ ë‹¨ì¼í™”: ì•ˆì • ì„±ì¥í˜• ì „ëµìœ¼ë¡œ í†µì¼í•˜ì—¬ ì¼ê´€ëœ ëª¨ë©˜í…€ ë¶„ì„
# - 3Mìˆ˜ìµë¥  ì§€í‘œ: 3ê°œì›”(63ê±°ë˜ì¼) ìˆ˜ìµë¥ ì„ í†µí•œ ì¤‘ê¸° ëª¨ë©˜í…€ í‰ê°€
# - ë³€ë™ì„± ê°€ì†ë„ ì§€í‘œ: (20ì¼ í‘œì¤€í¸ì°¨) / (120ì¼ í‘œì¤€í¸ì°¨)ë¡œ ê¸‰ë“± íŒ¨í„´ ê°ì§€
# - ì´ë²¤íŠ¸ì„± ê¸‰ë“±ì£¼ í•„í„°ë§: ë³€ë™ì„± ê°€ì†ë„ë¡œ ìˆ˜ì§ í­ë“± ì¢…ëª© ìë™ ì œê±°
# - ì•ˆì •ì  ì¶”ì„¸ ì¢…ëª© ë°œêµ´: ê¾¸ì¤€í•˜ê³  ì§€ì† ê°€ëŠ¥í•œ ìƒìŠ¹ ì¶”ì„¸ ì¢…ëª© ìš°ì„  í‘œì‹œ
# - ë³€ë™ì„± ì œì–´ ê°•í™”: ë³€ë™ì„± í˜ë„í‹° 4ë°° ê°•í™”ë¡œ ì•ˆì •ì„± ì¤‘ì‹œ
#
# v3.0.3 ê°œì„ ì‚¬í•­:
# - UI/UX ê°œì„ : í˜ì´ì§• ì»¨íŠ¸ë¡¤ì„ ê°€ë¡œ ë°°ì¹˜ë¡œ ë³€ê²½ (â¬…ï¸â¡ï¸ ë²„íŠ¼ ì–‘ìª½ ë ë°°ì¹˜)
# - ì‚¬ìš©ì ê²½í—˜: ê´€ì‹¬ì¢…ëª© ì¶”ê°€ ì‹œ ë¶ˆí•„ìš”í•œ ë©”ì‹œì§€ ì œê±°ë¡œ ê¹”ë”í•œ UI ì œê³µ
# - í˜ì´ì§• ì•ˆì „ì„±: ì¢…ëª© ì¶”ê°€ í›„ í˜ì´ì§•ì´ ê¹¨ì§€ì§€ ì•Šë„ë¡ ì•ˆì „ì¥ì¹˜ ì¶”ê°€
# - ìœ ë‹ˆë²„ìŠ¤ ì‹ ì„ ë„ ì²´í¬: Streamlit ì›¨ì´í¬ì—… ì‹œ íŒŒì¼ íƒ€ì„ìŠ¤íƒ¬í”„ ë³€ê²½ ë¬¸ì œ í•´ê²°
# - ì¬í‰ê°€ UI ê°œì„ : ì¬í‰ê°€ í›„ ì œê±° ì œì•ˆ ì¢…ëª©ì—ì„œ íœ´ì§€í†µ ë²„íŠ¼ í´ë¦­ ì‹œ ëª©ë¡ì—ì„œ ì¦‰ì‹œ ì œê±°
# - ë²„íŠ¼ ë¹„í™œì„±í™”: ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—… ì‹¤í–‰ ì¤‘ ê´€ë ¨ ë²„íŠ¼ë“¤ ìë™ ë¹„í™œì„±í™”ë¡œ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
# - ìƒíƒœ í‘œì‹œ: ì‘ì—… ì§„í–‰ ì¤‘ ë²„íŠ¼ í…ìŠ¤íŠ¸ ë³€ê²½ìœ¼ë¡œ í˜„ì¬ ìƒíƒœ ëª…í™•íˆ í‘œì‹œ
# - ìœ ë‹ˆë²„ìŠ¤ ìŠ¤í¬ë¦¬ë‹ ê³ ë„í™”: ì¶”ì„¸ í’ˆì§ˆ ì¤‘ì‹¬ í•„í„°ë§ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì¢…ëª© ì œê±° ë° ì•ˆì •ì  ëª¨ë©˜í…€ ì¢…ëª© ì„ ë³„
# - ì›Œì¹˜ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°ê°’ ì—…ë°ì´íŠ¸: ë” ê· í˜•ì¡íŒ ê¸€ë¡œë²Œ í¬íŠ¸í´ë¦¬ì˜¤ë¡œ ì´ˆê¸° ê´€ì‹¬ì¢…ëª© ëª©ë¡ ê°œì„ 
# - ìŠ¤ìº” ì™„ë£Œ í›„ UI ì •ë¦¬: FMS ìŠ¤ìº” ì™„ë£Œ ì‹œ ìŠ¤ìº” ì¤‘ë‹¨ ë²„íŠ¼ì´ ìë™ìœ¼ë¡œ ì‚¬ë¼ì§€ë„ë¡ ê°œì„ 
# - ìŠ¤ìº” ìƒíƒœ í‘œì‹œ ê°œì„ : ìŠ¤ìº” ì™„ë£Œ/ì¤‘ì§€ ì‹œ "ìŠ¤ìº” ì¤‘..." í‘œì‹œê°€ ì •í™•íˆ ì‚¬ë¼ì§€ë„ë¡ ê°œì„ 
# - ë³€ìˆ˜ëª… ê°œì„ : col1, col2, col3 â†’ prev_col, spacer_col, next_col ë“±ìœ¼ë¡œ ëª…í™•í™”
# - ì—ëŸ¬ ì²˜ë¦¬: print ë¬¸ì„ ì£¼ì„ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì½˜ì†” ì¶œë ¥ ì •ë¦¬

import os
os.environ.setdefault("CURL_CFFI_DISABLE_CACHE", "1")  # curl_cffi sqlite ìºì‹œ ë¹„í™œì„±í™”

import warnings
import time
from datetime import datetime
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import pytz
import re
import streamlit as st
import yfinance as yf
from watchlist_utils import load_watchlist, save_watchlist, add_to_watchlist, remove_from_watchlist, export_watchlist_to_csv, import_watchlist_from_csv
from universe_utils import check_universe_file_freshness, update_universe_file, load_universe_file, save_scan_results, load_latest_scan_results, get_scan_results_info
from config import FMS_FORMULA, FMS_DESCRIPTION

warnings.filterwarnings("ignore", category=ResourceWarning)
KST = pytz.timezone("Asia/Seoul")

# ------------------------------
# ê¸°ë³¸ ìœ ë‹ˆë²„ìŠ¤ (ê´€ì‹¬ì¢…ëª© ì´ˆê¸°í™”ìš©)
# ------------------------------
DEFAULT_USD_SYMBOLS = [
    'AAPL','ABBV','AMZN','ARKK','AVGO','BND','BRK-B','CAT','COST','CRM','CVX','DIA',
    'DIS','EEM','EFA','EWJ','GLD','GOOGL','HD','ICLN','INDA','IWM','IYT','JNJ','JPM',
    'KO','LLY','META','MRK','MSFT','NFLX','NVDA','PFE','PG','QQQ','SLV','SMH','SOXX',
    'SPY','T','TSLA','UNH','URA','V','VNQ','WMT','XLE','XLF','XLI','XLK','XLP','XLV','XLY'
]
DEFAULT_KRW_SYMBOLS = [
    '000660.KS','005930.KS'
]
DEFAULT_JPY_SYMBOLS = ['7203.T']



def classify(sym):
    # symì´ floatì´ë‚˜ ë‹¤ë¥¸ íƒ€ì…ì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ strë¡œ ë³€í™˜
    sym_str = str(sym)
    if sym_str.endswith(".KS"): return "KOR"
    if sym_str.endswith(".T"):  return "JPN"
    return "USA"

# ------------------------------
# í˜ì´ì§€/ìŠ¤íƒ€ì¼
# ------------------------------
st.set_page_config(page_title="KRW Momentum Radar v3.0.7", page_icon="âš¡", layout="wide")
st.markdown("""
<style>
.block-container {padding-top: 0.8rem;}
.badge {display:inline-block; padding:2px 8px; border-radius:999px; font-size:0.75rem; margin-right:6px; background:#f1f3f5;}
.kpi {border:1px solid #eee; border-radius:16px; padding:10px 14px; box-shadow:0 1px 6px rgba(0,0,0,0.06);}
.small {font-size:0.8rem; color:#555;}
</style>
""", unsafe_allow_html=True)

# ------------------------------
# ê´€ì‹¬ì¢…ëª© ì´ˆê¸°í™” (UIë³´ë‹¤ ë¨¼ì € ì‹¤í–‰)
# ------------------------------
if 'watchlist' not in st.session_state:
    default_symbols = DEFAULT_USD_SYMBOLS + DEFAULT_KRW_SYMBOLS + DEFAULT_JPY_SYMBOLS
    st.session_state.watchlist = load_watchlist(default_symbols)
    # ê´€ì‹¬ì¢…ëª© ì´ˆê¸°í™” ì™„ë£Œ

# í˜„ì¬ ê´€ì‹¬ì¢…ëª©ì„ ê¸°ì¡´ ë³€ìˆ˜ëª…ìœ¼ë¡œ ë§¤í•‘ (í•˜ìœ„ í˜¸í™˜ì„±)
USD_SYMBOLS = [str(s) for s in st.session_state.watchlist if classify(s) == "USA"]
KRW_SYMBOLS = [str(s) for s in st.session_state.watchlist if classify(s) == "KOR"]
JPY_SYMBOLS = [str(s) for s in st.session_state.watchlist if classify(s) == "JPN"]

# ------------------------------
# ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ------------------------------
def _extract_adj_close(df_chunk, tickers):
    if df_chunk is None or len(df_chunk)==0:
        return pd.DataFrame(columns=tickers, dtype=float)
    if isinstance(df_chunk.columns, pd.MultiIndex):
        if 'Adj Close' in df_chunk.columns.get_level_values(0):
            adj = df_chunk['Adj Close'].copy()
        elif 'Close' in df_chunk.columns.get_level_values(0):
            adj = df_chunk['Close'].copy()
        else:
            parts=[]
            for t in tickers:
                try:
                    if ('Adj Close', t) in df_chunk.columns:
                        s = df_chunk[('Adj Close', t)].rename(t)
                    elif ('Close', t) in df_chunk.columns:
                        s = df_chunk[('Close', t)].rename(t)
                    else:
                        s = pd.Series(dtype=float, name=t)
                except Exception:
                    s = pd.Series(dtype=float, name=t)
                parts.append(s)
            adj = pd.concat(parts, axis=1)
    else:
        cols = df_chunk.columns
        if 'Adj Close' in cols:
            adj = df_chunk[['Adj Close']].copy(); adj.columns = tickers[:1]
        elif 'Close' in cols:
            adj = df_chunk[['Close']].copy(); adj.columns = tickers[:1]
        else:
            adj = df_chunk.copy()
            keep = [c for c in adj.columns if c in tickers]
            adj = adj[keep] if keep else pd.DataFrame(columns=tickers, dtype=float)
    adj = adj.loc[:, ~adj.columns.duplicated()]
    return adj

@st.cache_data(ttl=60*60*6, show_spinner=False)
def download_prices(tickers, period_="2y", interval="1d", chunk=25):
    frames=[]; missing=[]
    tickers = list(dict.fromkeys(tickers))
    for i in range(0, len(tickers), chunk):
        part = tickers[i:i+chunk]
        try:
            raw = yf.download(part, period=period_, interval=interval, auto_adjust=False,
                              group_by='column', progress=False, threads=True)
            adj = _extract_adj_close(raw, part)
        except Exception as e:
            log(f"ERROR download chunk: {part[:3]}... -> {e}")
            adj = pd.DataFrame()
        if adj.empty or adj.isna().all().all():
            pframes=[]
            for t in part:
                try:
                    r = yf.download(t, period=period_, interval=interval, auto_adjust=False,
                                    group_by='column', progress=False, threads=False)
                    a = _extract_adj_close(r, [t])
                    pframes.append(a)
                except Exception as e:
                    log(f"ERROR download single: {t} -> {e}")
                    missing.append(t)
            if pframes:
                frames.append(pd.concat(pframes, axis=1))
        else:
            frames.append(adj)
    if not frames:
        return pd.DataFrame(), missing
    out = pd.concat(frames, axis=1)
    out = out.loc[:, ~out.columns.duplicated()].sort_index()
    all_nan = out.columns[out.isna().all()]
    if len(all_nan):
        log(f"DROP all-NaN columns: {list(all_nan)[:5]}{' ...' if len(all_nan)>5 else ''}")
    out = out.drop(columns=all_nan)
    return out, sorted(list(dict.fromkeys(list(missing)+list(all_nan))))

@st.cache_data(ttl=60*60*6, show_spinner=False)
def download_ohlc_prices(tickers, period_="2y", interval="1d", chunk=25):
    """
    ê±°ë˜ ì í•©ì„± í•„í„°ë¥¼ ìœ„í•œ OHLC ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        tickers (list): ë‹¤ìš´ë¡œë“œí•  í‹°ì»¤ ëª©ë¡
        period_ (str): ë°ì´í„° ê¸°ê°„
        interval (str): ë°ì´í„° ê°„ê²©
        chunk (int): ë°°ì¹˜ í¬ê¸°
    
    Returns:
        tuple: (ohlc_data, missing_tickers)
    """
    frames=[]; missing=[]
    tickers = list(dict.fromkeys(tickers))
    
    for i in range(0, len(tickers), chunk):
        part = tickers[i:i+chunk]
        try:
            raw = yf.download(part, period=period_, interval=interval, auto_adjust=False,
                              group_by='column', progress=False, threads=True)
            
            if raw.empty:
                missing.extend(part)
                continue
                
            # OHLC ë°ì´í„° ì¶”ì¶œ
            if isinstance(raw.columns, pd.MultiIndex):
                ohlc_data = {}
                for t in part:
                    if ('High', t) in raw.columns and ('Low', t) in raw.columns and ('Close', t) in raw.columns:
                        ohlc_data[t] = pd.DataFrame({
                            'High': raw[('High', t)],
                            'Low': raw[('Low', t)],
                            'Close': raw[('Close', t)]
                        })
                    else:
                        missing.append(t)
            else:
                # ë‹¨ì¼ í‹°ì»¤ì¸ ê²½ìš°
                if len(part) == 1 and 'High' in raw.columns and 'Low' in raw.columns and 'Close' in raw.columns:
                    t = part[0]
                    ohlc_data[t] = pd.DataFrame({
                        'High': raw['High'],
                        'Low': raw['Low'],
                        'Close': raw['Close']
                    })
                else:
                    missing.extend(part)
                    continue
            
            if ohlc_data:
                frames.append(pd.concat(ohlc_data, axis=1))
                
        except Exception as e:
            log(f"ERROR download OHLC chunk: {part[:3]}... -> {e}")
            missing.extend(part)
    
    if not frames:
        return pd.DataFrame(), missing
    
    # ëª¨ë“  OHLC ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í•©ì¹˜ê¸°
    all_ohlc = pd.concat(frames, axis=1)
    all_ohlc = all_ohlc.loc[:, ~all_ohlc.columns.duplicated()].sort_index()
    
    return all_ohlc, sorted(list(dict.fromkeys(missing)))

@st.cache_data(ttl=60*60*6, show_spinner=False)
def download_fx(period_="2y", interval="1d"):
    fx_krw, miss1 = download_prices(["KRW=X"], period_, interval)
    fx_jpy, miss2 = download_prices(["JPY=X"], period_, interval)
    usdkrw = fx_krw.iloc[:,0].rename("USDKRW") if not fx_krw.empty else pd.Series(dtype=float, name="USDKRW")
    usdjpy = fx_jpy.iloc[:,0].rename("USDJPY") if not fx_jpy.empty else pd.Series(dtype=float, name="USDJPY")
    if not usdkrw.empty and not usdjpy.empty:
        start=min(usdkrw.index.min(), usdjpy.index.min())
        end=max(usdkrw.index.max(), usdjpy.index.max())
        idx = pd.date_range(start, end, freq='B')
        usdkrw = usdkrw.reindex(idx).ffill()
        usdjpy = usdjpy.reindex(idx).ffill()
        jpykrw = (usdkrw/usdjpy).rename("JPYKRW")
    else:
        jpykrw = pd.Series(dtype=float, name="JPYKRW")
    return usdkrw, usdjpy, jpykrw, (miss1+miss2)

def harmonize_calendar(df, coverage=0.9):
    if df.empty: return df
    idx = pd.date_range(df.index.min(), df.index.max(), freq='B')
    df = df.reindex(idx).ffill()
    # coverage ì²´í¬
    valid_ratio = df.count().div(len(df))
    keep_cols = valid_ratio[valid_ratio >= coverage].index
    return df[keep_cols] if len(keep_cols) > 0 else pd.DataFrame()

def align_bday_ffill(df):
    if df is None or len(df)==0: return df
    idx = pd.date_range(df.index.min(), df.index.max(), freq='B')
    return df.reindex(idx).ffill()

# ------------------------------
# ë¡œê¹… í•¨ìˆ˜
# ------------------------------
if "LOG" not in st.session_state:
    st.session_state["LOG"] = []
def log(msg):
    ts = datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S")
    st.session_state["LOG"].append(f"[{ts}] {msg}")

# ------------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ------------------------------
def warn_to_log(fn, *args, **kwargs):
    with warnings.catch_warnings(record=True) as wlist:
        result = fn(*args, **kwargs)
        for w in wlist:
            st.session_state["LOG"].append(f"WARNING: {w.category.__name__}: {str(w.message)}")
        return result

# ------------------------------
# ì§€í‘œ/ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜ë“¤
# ------------------------------
def ema(s, span): return s.ewm(span=span, adjust=False).mean()

def returns_pct(df, n):
    if df.shape[0] <= n: 
        return pd.Series(index=df.columns, dtype=float)
    dff = df.ffill()
    r = warn_to_log(dff.pct_change, periods=n, fill_method=None).iloc[-1]
    return r

def ytd_return(df):
    if df.empty: return pd.Series(dtype=float)
    dff = df.ffill()
    last = dff.index[-1]
    y0 = pd.Timestamp(datetime(last.year, 1, 1))
    start_idx = dff.index.get_indexer([y0], method='nearest')[0]
    return dff.iloc[-1] / dff.iloc[start_idx] - 1.0

def last_vol_annualized(df, window=20):
    rets = warn_to_log(df.ffill().pct_change, fill_method=None).dropna()
    if rets.empty: return pd.Series(index=df.columns, dtype=float)
    vol = rets.rolling(window).std().iloc[-1] * np.sqrt(252.0)
    return vol

def calculate_tradeability_filters(ohlc_data, symbols):
    """
    ê±°ë˜ ì í•©ì„± ì‹¤ê²© í•„í„°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        ohlc_data (pd.DataFrame): OHLC ë°ì´í„° (MultiIndex columns)
        symbols (list): ì‹¬ë³¼ ëª©ë¡
    
    Returns:
        dict: ê° ì‹¬ë³¼ë³„ ì‹¤ê²© ì—¬ë¶€ (Trueë©´ ì‹¤ê²©)
    """
    disqualification = {}
    
    for symbol in symbols:
        try:
            # OHLC ë°ì´í„° ì¶”ì¶œ
            if isinstance(ohlc_data.columns, pd.MultiIndex):
                if ((symbol, 'High') in ohlc_data.columns and 
                    (symbol, 'Low') in ohlc_data.columns and 
                    (symbol, 'Close') in ohlc_data.columns):
                    high = ohlc_data[(symbol, 'High')].dropna()
                    low = ohlc_data[(symbol, 'Low')].dropna()
                    close = ohlc_data[(symbol, 'Close')].dropna()
                else:
                    disqualification[symbol] = True
                    continue
            else:
                # ë‹¨ì¼ ì‹¬ë³¼ì¸ ê²½ìš°
                if 'High' in ohlc_data.columns and 'Low' in ohlc_data.columns and 'Close' in ohlc_data.columns:
                    high = ohlc_data['High'].dropna()
                    low = ohlc_data['Low'].dropna()
                    close = ohlc_data['Close'].dropna()
                else:
                    disqualification[symbol] = True
                    continue
            
            if len(close) < 63:  # ìµœì†Œ 63ê±°ë˜ì¼ ë°ì´í„° í•„ìš”
                disqualification[symbol] = True
                continue
            
            # ì¼ì¼ ë³€ë™í­ ê³„ì‚°: (ë‹¹ì¼ ê³ ê°€ - ë‹¹ì¼ ì €ê°€) / ì „ì¼ ì¢…ê°€
            daily_range = (high - low) / close.shift(1)
            
            # ì¼ì¼ í•˜ë°© ë¦¬ìŠ¤í¬ ê³„ì‚°: (ë‹¹ì¼ ì €ê°€ / ì „ì¼ ì¢…ê°€) - 1
            daily_downside_risk = (low / close.shift(1)) - 1
            
            # í•„í„° 1: ì¹˜ëª…ì  ë³€ë™ì„± í•„í„° (63ê±°ë˜ì¼ ë‚´ ì¼ì¼ ë³€ë™í­ 15% ì´ˆê³¼)
            recent_63_days = daily_range.tail(63)
            extreme_volatility_days = recent_63_days[recent_63_days > 0.15]  # ì›ë˜ ìš”ì²­: 15%
            
            # í•„í„° 2: ë°˜ë³µì  í•˜ë°© ë¦¬ìŠ¤í¬ í•„í„° (20ê±°ë˜ì¼ ë‚´ í•˜ë°© ë¦¬ìŠ¤í¬ -7% ë¯¸ë§Œ 4ì¼ ì´ìƒ)
            recent_20_days = daily_downside_risk.tail(20)
            severe_downside_days = recent_20_days[recent_20_days < -0.07]  # ì›ë˜ ìš”ì²­: -7%, 4ì¼
            
            # ì‹¤ê²© ì¡°ê±´ í™•ì¸
            is_disqualified = (
                len(extreme_volatility_days) > 0 or  # ì¹˜ëª…ì  ë³€ë™ì„± 1ì¼ ì´ìƒ (15% ì´ˆê³¼)
                len(severe_downside_days) >= 4      # ì‹¬ê°í•œ í•˜ë°© ë¦¬ìŠ¤í¬ 4ì¼ ì´ìƒ (-7% ë¯¸ë§Œ)
            )
            
            
            disqualification[symbol] = is_disqualified
            
        except Exception as e:
            log(f"ê±°ë˜ ì í•©ì„± í•„í„° ê³„ì‚° ì˜¤ë¥˜ {symbol}: {str(e)}")
            disqualification[symbol] = True
    
    return disqualification

def _mom_snapshot(prices_krw, reference_prices_krw=None, ohlc_data=None, symbols=None):
    """
    ëª¨ë©˜í…€ ìŠ¤ëƒ…ìƒ·ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        prices_krw (pd.DataFrame): KRW í™˜ì‚° ê°€ê²© ë°ì´í„°
        reference_prices_krw (pd.DataFrame, optional): Z-score ê³„ì‚° ê¸°ì¤€ì´ ë˜ëŠ” ì°¸ì¡° ë°ì´í„°
        ohlc_data (pd.DataFrame, optional): OHLC ë°ì´í„° (ê±°ë˜ ì í•©ì„± í•„í„°ìš©)
        symbols (list, optional): ì‹¬ë³¼ ëª©ë¡ (ê±°ë˜ ì í•©ì„± í•„í„°ìš©)
    
    Returns:
        pd.DataFrame: ëª¨ë©˜í…€ ì§€í‘œë“¤ì´ í¬í•¨ëœ DataFrame
    """
    r_1m = returns_pct(prices_krw, 21)
    r_3m = returns_pct(prices_krw, 63)  # 3ê°œì›” ìˆ˜ìµë¥ 
    
    above_ema50 = {}
    
    for c in prices_krw.columns:
        s = prices_krw[c].dropna()
        if s.empty:
            above_ema50[c] = np.nan
            continue
            
        e50 = ema(s, 50)
        above_ema50[c] = (s.iloc[-1]/e50.iloc[-1]-1.0) if e50.iloc[-1] > 0 else np.nan
    
    above_ema50 = pd.Series(above_ema50, name="AboveEMA50")
    vol20 = last_vol_annualized(prices_krw, 20).rename("Vol20(ann)")

    # ê±°ë˜ ì í•©ì„± ì‹¤ê²© í•„í„° ì ìš©
    disqualification_flags = {}
    if ohlc_data is not None and symbols is not None:
        disqualification_flags = calculate_tradeability_filters(ohlc_data, symbols)
    
    # Z-score ê³„ì‚° ê¸°ì¤€ ê²°ì •
    if reference_prices_krw is not None:
        # ì°¸ì¡° ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì°¸ì¡° ë°ì´í„°ë¡œ Z-score ê³„ì‚°
        ref_r_1m = returns_pct(reference_prices_krw, 21)
        ref_r_3m = returns_pct(reference_prices_krw, 63)
        
        ref_above_ema50 = {}
        
        for c in reference_prices_krw.columns:
            s = reference_prices_krw[c].dropna()
            if s.empty:
                ref_above_ema50[c] = np.nan
                continue
                
            e50 = ema(s, 50)
            ref_above_ema50[c] = (s.iloc[-1]/e50.iloc[-1]-1.0) if e50.iloc[-1] > 0 else np.nan
        
        ref_above_ema50 = pd.Series(ref_above_ema50, name="AboveEMA50")
        ref_vol20 = last_vol_annualized(reference_prices_krw, 20).rename("Vol20(ann)")
        
        # ì°¸ì¡° ë°ì´í„°ë¡œ Z-score ê³„ì‚°
        def z_with_reference(x, ref_x):
            x = x.astype(float)
            ref_x = ref_x.astype(float)
            m = np.nanmean(ref_x); sd = np.nanstd(ref_x)
            return (x-m)/sd if sd and not np.isnan(sd) else x*0.0
        
        FMS = (0.4*z_with_reference(r_1m, ref_r_1m) + 
               0.3*z_with_reference(r_3m, ref_r_3m) + 
               0.2*z_with_reference(above_ema50, ref_above_ema50) 
               - 0.4*z_with_reference(vol20.fillna(vol20.median()), ref_vol20.fillna(ref_vol20.median())))
    else:
        # ê¸°ì¡´ ë°©ì‹: í˜„ì¬ ë°ì´í„°ë¡œ Z-score ê³„ì‚°
        def z(x):
            x = x.astype(float)
            m = np.nanmean(x); sd = np.nanstd(x)
            return (x-m)/sd if sd and not np.isnan(sd) else x*0.0

        FMS = (0.4*z(r_1m) + 0.3*z(r_3m) + 0.2*z(above_ema50) 
               - 0.4*z(vol20.fillna(vol20.median())))
    
    # ê±°ë˜ ì í•©ì„± ì‹¤ê²© í•„í„° ì ìš©: ì‹¤ê²©ëœ ì¢…ëª©ì€ FMSë¥¼ -999ë¡œ ì„¤ì •
    if disqualification_flags:
        for symbol in FMS.index:
            if symbol in disqualification_flags and disqualification_flags[symbol]:
                FMS[symbol] = -999.0
                log(f"ê±°ë˜ ì í•©ì„± ì‹¤ê²©: {symbol} (FMS = -999)")
    
    # ê²°ê³¼ DataFrame êµ¬ì„±
    snap = pd.concat([r_1m.rename("R_1M"), r_3m.rename("R_3M"), above_ema50, 
                     vol20, FMS.rename("FMS")], axis=1)
    
    return snap

def momentum_now_and_delta(prices_krw, reference_prices_krw=None, ohlc_data=None, symbols=None):
    """
    ëª¨ë©˜í…€ê³¼ ë¸íƒ€ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        prices_krw (pd.DataFrame): KRW í™˜ì‚° ê°€ê²© ë°ì´í„°
        reference_prices_krw (pd.DataFrame, optional): Z-score ê³„ì‚° ê¸°ì¤€ì´ ë˜ëŠ” ì°¸ì¡° ë°ì´í„°
        ohlc_data (pd.DataFrame, optional): OHLC ë°ì´í„° (ê±°ë˜ ì í•©ì„± í•„í„°ìš©)
        symbols (list, optional): ì‹¬ë³¼ ëª©ë¡ (ê±°ë˜ ì í•©ì„± í•„í„°ìš©)
    
    Returns:
        pd.DataFrame: ëª¨ë©˜í…€ ì§€í‘œì™€ ë¸íƒ€ê°€ í¬í•¨ëœ DataFrame
    """
    now = _mom_snapshot(prices_krw, reference_prices_krw, ohlc_data, symbols)
    d1 = _mom_snapshot(prices_krw.iloc[:-1], reference_prices_krw, ohlc_data, symbols) if len(prices_krw)>1 else now*np.nan
    d5 = _mom_snapshot(prices_krw.iloc[:-5], reference_prices_krw, ohlc_data, symbols) if len(prices_krw)>5 else now*np.nan
    df = now.copy()
    df["Î”FMS_1D"] = df["FMS"] - d1["FMS"]
    df["Î”FMS_5D"] = df["FMS"] - d5["FMS"]
    df["R_1W"] = returns_pct(prices_krw, 5)
    df["R_6M"] = returns_pct(prices_krw, 126)
    df["R_YTD"] = ytd_return(prices_krw)
    return df.sort_values("FMS", ascending=False)

# ------------------------------
# ìœ ë‹ˆë²„ìŠ¤ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ë“¤ì€ universe_utils.pyë¡œ ì´ë™
# ------------------------------

# ------------------------------
# ì‹ ê·œ ì¢…ëª© íƒìƒ‰ ì—”ì§„ í•¨ìˆ˜ë“¤
# ------------------------------
def calculate_fms_for_batch(symbols_batch, period_="1y", interval="1d", reference_prices_krw=None):
    """
    ë°°ì¹˜ ë‹¨ìœ„ë¡œ FMSë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    API ì œí•œì„ íšŒí”¼í•˜ê¸° ìœ„í•´ ì¬ì‹œë„ ë¡œì§ê³¼ íƒ€ì„ì•„ì›ƒì„ í¬í•¨í•©ë‹ˆë‹¤.
    ê±°ë˜ ì í•©ì„± ì‹¤ê²© í•„í„°ê°€ ê¸°ë³¸ì ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤.
    
    Args:
        symbols_batch (list): ê³„ì‚°í•  ì‹¬ë³¼ ëª©ë¡
        period_ (str): ë°ì´í„° ê¸°ê°„
        interval (str): ë°ì´í„° ê°„ê²©
        reference_prices_krw (pd.DataFrame, optional): Z-score ê³„ì‚° ê¸°ì¤€ì´ ë˜ëŠ” ì°¸ì¡° ë°ì´í„°
        
    Returns:
        pd.DataFrame: FMS ê³„ì‚° ê²°ê³¼
    """
    if not symbols_batch:
        return pd.DataFrame()
    
    max_retries = 3
    retry_delay = 2  # ì´ˆ
    
    for attempt in range(max_retries):
        try:
            # ê°€ê²© ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            prices, missing = download_prices(symbols_batch, period_, interval)
            if prices.empty:
                if attempt < max_retries - 1:
                    log(f"ë°°ì¹˜ ë°ì´í„° ì—†ìŒ, ì¬ì‹œë„ {attempt + 1}/{max_retries}")
                    time.sleep(retry_delay)
                    continue
                return pd.DataFrame()
            
            # OHLC ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ê±°ë˜ ì í•©ì„± í•„í„°ìš©)
            ohlc_data, ohlc_missing = download_ohlc_prices(symbols_batch, period_, interval)
            if ohlc_data.empty:
                ohlc_data = None
            
            # KRW í™˜ì‚°ì„ ìœ„í•œ FX ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            usd_symbols = [str(s) for s in symbols_batch if classify(s) == "USA"]
            if usd_symbols:
                usdkrw, _, _, _ = download_fx(period_, interval)
                if not usdkrw.empty:
                    usdkrw_matched = usdkrw.reindex(prices.index).ffill()
                    usd_prices = prices[[s for s in usd_symbols if s in prices.columns]]
                    if not usd_prices.empty:
                        prices[usd_prices.columns] = usd_prices.mul(usdkrw_matched, axis=0)
            
            # JPY ì‹¬ë³¼ ì²˜ë¦¬
            jpy_symbols = [str(s) for s in symbols_batch if classify(s) == "JPN"]
            if jpy_symbols:
                _, _, jpykrw, _ = download_fx(period_, interval)
                if not jpykrw.empty:
                    jpykrw_matched = jpykrw.reindex(prices.index).ffill()
                    jpy_prices = prices[[s for s in jpy_symbols if s in prices.columns]]
                    if not jpy_prices.empty:
                        prices[jpy_prices.columns] = jpy_prices.mul(jpykrw_matched, axis=0)
            
            # ìº˜ë¦°ë” ì •ê·œí™”
            prices_krw = harmonize_calendar(prices, coverage=0.9)
            if prices_krw.empty:
                if attempt < max_retries - 1:
                    log(f"ìº˜ë¦°ë” ì •ê·œí™” ì‹¤íŒ¨, ì¬ì‹œë„ {attempt + 1}/{max_retries}")
                    time.sleep(retry_delay)
                    continue
                return pd.DataFrame()
            
            # FMS ê³„ì‚° (ì°¸ì¡° ë°ì´í„° ë° ê±°ë˜ ì í•©ì„± í•„í„° ì‚¬ìš©)
            df = momentum_now_and_delta(prices_krw, reference_prices_krw, ohlc_data, symbols_batch)
            return df.sort_values("FMS", ascending=False)
            
        except Exception as e:
            error_msg = str(e).lower()
            if any(keyword in error_msg for keyword in ["rate limit", "too many requests", "429", "timeout"]):
                if attempt < max_retries - 1:
                    wait_time = retry_delay * (2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                    log(f"API ì œí•œ ê°ì§€, {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ {attempt + 1}/{max_retries}")
                    time.sleep(wait_time)
                    continue
                else:
                    log(f"API ì œí•œìœ¼ë¡œ ì¸í•œ ìµœì¢… ì‹¤íŒ¨: {str(e)}")
                    return pd.DataFrame()
            else:
                log(f"FMS ê³„ì‚° ì¤‘ ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}): {str(e)}")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    continue
                return pd.DataFrame()
    
    return pd.DataFrame()

def scan_market_for_new_opportunities():
    """
    ìœ ë‹ˆë²„ìŠ¤ ì—…ë°ì´íŠ¸ í›„ FMS ìŠ¤ì½”ì–´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆë„ë¡ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.
    
    Returns:
        tuple: (top_performers_df, message)
    """
    # 1ë‹¨ê³„: ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ ì‹ ì„ ë„ í™•ì¸ ë° ì—…ë°ì´íŠ¸
    log("ğŸ” ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ ìƒíƒœ í™•ì¸ ì¤‘...")
    
    is_fresh, last_modified, hours_since_update = check_universe_file_freshness()
    
    # ìœ ë‹ˆë²„ìŠ¤ ì—…ë°ì´íŠ¸ ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ ì»¨í…Œì´ë„ˆ ìƒì„±
    universe_progress_container = st.empty()
    universe_status_container = st.empty()
    
    if is_fresh:
        universe_status_container.text(f"âœ… ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ì´ ìµœì‹ ì…ë‹ˆë‹¤ (ì—…ë°ì´íŠ¸: {last_modified.strftime('%Y-%m-%d %H:%M:%S')}, {hours_since_update:.1f}ì‹œê°„ ì „)")
        log(f"âœ… ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ì´ ìµœì‹ ì…ë‹ˆë‹¤ (ì—…ë°ì´íŠ¸: {last_modified.strftime('%Y-%m-%d %H:%M:%S')}, {hours_since_update:.1f}ì‹œê°„ ì „)")
    else:
        if last_modified:
            universe_status_container.text(f"âš ï¸ ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ì´ ì˜¤ë˜ë˜ì—ˆìŠµë‹ˆë‹¤ (ì—…ë°ì´íŠ¸: {last_modified.strftime('%Y-%m-%d %H:%M:%S')}, {hours_since_update:.1f}ì‹œê°„ ì „)")
            log(f"âš ï¸ ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ì´ ì˜¤ë˜ë˜ì—ˆìŠµë‹ˆë‹¤ (ì—…ë°ì´íŠ¸: {last_modified.strftime('%Y-%m-%d %H:%M:%S')}, {hours_since_update:.1f}ì‹œê°„ ì „)")
        else:
            universe_status_container.text("âš ï¸ ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            log("âš ï¸ ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        
        universe_status_container.text("ğŸ”„ ìœ ë‹ˆë²„ìŠ¤ ì—…ë°ì´íŠ¸ ì‹œì‘...")
        log("ğŸ”„ ìœ ë‹ˆë²„ìŠ¤ ì—…ë°ì´íŠ¸ ì‹œì‘...")
        
        # ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜ ì •ì˜
        def progress_callback(progress, message):
            universe_progress_container.progress(progress, text=message)
            log(f"ì§„í–‰ë¥  {progress*100:.0f}%: {message}")
        
        def status_callback(message):
            universe_status_container.text(message)
            log(message)
        
        # ìœ ë‹ˆë²„ìŠ¤ ì—…ë°ì´íŠ¸ ì‹¤í–‰ (ì§„í–‰ ìƒí™© í‘œì‹œ í¬í•¨)
        update_success, update_message, symbol_count = update_universe_file(
            progress_callback=progress_callback,
            status_callback=status_callback
        )
        
        if not update_success:
            error_msg = f"ìœ ë‹ˆë²„ìŠ¤ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {update_message}"
            universe_status_container.text(f"âŒ {error_msg}")
            log(error_msg)
            return pd.DataFrame(), error_msg
        
        universe_status_container.text(f"âœ… {update_message}")
        log(f"âœ… {update_message}")
    
    # ìœ ë‹ˆë²„ìŠ¤ ì—…ë°ì´íŠ¸ ì»¨í…Œì´ë„ˆ ì •ë¦¬
    universe_progress_container.empty()
    universe_status_container.empty()
    
    # 2ë‹¨ê³„: ìŠ¤í¬ë¦¬ë‹ëœ ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ ë¡œë“œ
    try:
        success, master_list, load_message = load_universe_file()
        
        if not success:
            error_msg = f"ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {load_message}"
            log(error_msg)
            return pd.DataFrame(), error_msg
        
        log(f"ğŸ“Š {load_message}")
        
    except Exception as e:
        error_msg = f"ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        log(error_msg)
        return pd.DataFrame(), error_msg

    # ê¸°ì¡´ ê´€ì‹¬ì¢…ëª© ì œì™¸
    current_watchlist = st.session_state.get('watchlist', [])
    scan_targets = [s for s in master_list if s not in current_watchlist]
    
    if not scan_targets:
        return pd.DataFrame(), "ì•Œë¦¼: í˜„ì¬ ìœ ë§ì£¼ ëª©ë¡ì˜ ëª¨ë“  ì¢…ëª©ì´ ì´ë¯¸ ê´€ì‹¬ì¢…ëª©ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."

    # ê´€ì‹¬ì¢…ëª© ë°ì´í„°ë¥¼ ì°¸ì¡° ë°ì´í„°ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ê°€ì ¸ì˜¤ê¸°
    log("ğŸ“Š ê´€ì‹¬ì¢…ëª© ë°ì´í„°ë¥¼ ì°¸ì¡° ê¸°ì¤€ìœ¼ë¡œ ë¡œë“œ ì¤‘...")
    try:
        reference_prices_krw, _ = build_prices_krw("1y", current_watchlist)
        if reference_prices_krw.empty:
            log("âš ï¸ ê´€ì‹¬ì¢…ëª© ë°ì´í„°ê°€ ì—†ì–´ì„œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ FMS ê³„ì‚°í•©ë‹ˆë‹¤.")
            reference_prices_krw = None
        else:
            log(f"âœ… ê´€ì‹¬ì¢…ëª© ì°¸ì¡° ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(reference_prices_krw.columns)}ê°œ ì¢…ëª©")
    except Exception as e:
        log(f"âš ï¸ ê´€ì‹¬ì¢…ëª© ì°¸ì¡° ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ FMS ê³„ì‚°í•©ë‹ˆë‹¤.")
        reference_prices_krw = None

    log(f"ì´ {len(scan_targets)}ê°œ ì‹ ê·œ ì¢…ëª©ì„ ìŠ¤ìº”í•©ë‹ˆë‹¤...")
    
    # ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ìƒíƒœ ì´ˆê¸°í™”
    if 'scan_progress' not in st.session_state:
        st.session_state.scan_progress = {
            'total_batches': 0,
            'completed_batches': 0,
            'current_batch': 0,
            'successful_symbols': 0,
            'failed_symbols': 0,
            'start_time': None,
            'last_update': None
        }
    
    # ìŠ¤ìº” ìƒíƒœ ì´ˆê¸°í™”
    st.session_state.scan_progress.update({
        'total_batches': 0,
        'completed_batches': 0,
        'current_batch': 0,
        'successful_symbols': 0,
        'failed_symbols': 0,
        'start_time': datetime.now(KST),
        'last_update': datetime.now(KST)
    })
    
    # ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì • (API ì œí•œ ê³ ë ¤)
    batch_size = 20  # Yahoo Finance API ì œí•œì„ ê³ ë ¤í•œ ìµœì  ë°°ì¹˜ í¬ê¸°
    total_batches = (len(scan_targets) - 1) // batch_size + 1
    st.session_state.scan_progress['total_batches'] = total_batches
    
    log(f"ë°°ì¹˜ í¬ê¸°: {batch_size}ê°œ, ì´ ë°°ì¹˜ ìˆ˜: {total_batches}ê°œ")
    
    all_results = []
    failed_batches = []
    
    # ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ ì»¨í…Œì´ë„ˆ ìƒì„±
    progress_container = st.empty()
    status_container = st.empty()
    
    try:
        for i in range(0, len(scan_targets), batch_size):
            batch_num = i // batch_size + 1
            batch = scan_targets[i:i+batch_size]
            
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            st.session_state.scan_progress.update({
                'current_batch': batch_num,
                'last_update': datetime.now(KST)
            })
            
            # ì§„í–‰ë¥  ê³„ì‚°
            progress = batch_num / total_batches
            elapsed_time = (datetime.now(KST) - st.session_state.scan_progress['start_time']).total_seconds()
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            progress_container.progress(progress, text=f"ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ ì¢…ëª©)")
            status_container.text(f"ì²˜ë¦¬ ì¤‘: {batch[0]} ~ {batch[-1]} | ê²½ê³¼ì‹œê°„: {elapsed_time:.0f}ì´ˆ")
            
            log(f"ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ ì¢…ëª©: {batch[0]} ~ {batch[-1]})")
            
            try:
                # ë°°ì¹˜ ì²˜ë¦¬ (ì°¸ì¡° ë°ì´í„° í¬í•¨)
                batch_results = calculate_fms_for_batch(batch, reference_prices_krw=reference_prices_krw)
                
                if not batch_results.empty:
                    all_results.append(batch_results)
                    st.session_state.scan_progress['successful_symbols'] += len(batch_results)
                    log(f"âœ… ë°°ì¹˜ {batch_num} ì™„ë£Œ: {len(batch_results)}ê°œ ì¢…ëª© ì„±ê³µ")
                else:
                    st.session_state.scan_progress['failed_symbols'] += len(batch)
                    failed_batches.append(batch_num)
                    log(f"âš ï¸ ë°°ì¹˜ {batch_num} ì‹¤íŒ¨: ë°ì´í„° ì—†ìŒ")
                
            except Exception as e:
                st.session_state.scan_progress['failed_symbols'] += len(batch)
                failed_batches.append(batch_num)
                log(f"âŒ ë°°ì¹˜ {batch_num} ì˜¤ë¥˜: {str(e)}")
                
                # yfinance API ì œí•œ ê°ì§€ ì‹œ ì ì‹œ ëŒ€ê¸°
                if "rate limit" in str(e).lower() or "too many requests" in str(e).lower():
                    log("â³ API ì œí•œ ê°ì§€, 5ì´ˆ ëŒ€ê¸°...")
                    time.sleep(5)
            
            st.session_state.scan_progress['completed_batches'] = batch_num
            
            # ë°°ì¹˜ ê°„ ëŒ€ê¸° (API ì œí•œ ë°©ì§€)
            time.sleep(2)  # Yahoo Finance API ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸° ì‹œê°„
    
    except Exception as e:
        log(f"âŒ ìŠ¤ìº” ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {str(e)}")
        return pd.DataFrame(), f"ìŠ¤ìº” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    finally:
        # ì§„í–‰ ìƒí™© ì»¨í…Œì´ë„ˆ ì •ë¦¬
        progress_container.empty()
        status_container.empty()
    
    # ìµœì¢… ê²°ê³¼ ì²˜ë¦¬
    if not all_results:
        return pd.DataFrame(), "ì•Œë¦¼: ìŠ¤ìº” ëŒ€ìƒ ì¢…ëª©ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    
    # ëª¨ë“  ê²°ê³¼ í•©ì¹˜ê¸°
    combined_results = pd.concat(all_results)
    
    # FMS ìˆœìœ¼ë¡œ ì •ë ¬
    all_performers = combined_results.sort_values("FMS", ascending=False)
    
    # ìµœì¢… í†µê³„
    total_time = (datetime.now(KST) - st.session_state.scan_progress['start_time']).total_seconds()
    success_rate = (st.session_state.scan_progress['successful_symbols'] / 
                   (st.session_state.scan_progress['successful_symbols'] + st.session_state.scan_progress['failed_symbols'])) * 100
    
    scan_message = (f"âœ… ìŠ¤ìº” ì™„ë£Œ! "
                   f"ì„±ê³µ: {st.session_state.scan_progress['successful_symbols']}ê°œ, "
                   f"ì‹¤íŒ¨: {st.session_state.scan_progress['failed_symbols']}ê°œ, "
                   f"ì„±ê³µë¥ : {success_rate:.1f}%, "
                   f"ì†Œìš”ì‹œê°„: {total_time:.0f}ì´ˆ")
    
    log(scan_message)
    
    # ì‹¤íŒ¨í•œ ë°°ì¹˜ê°€ ìˆìœ¼ë©´ ê²½ê³ 
    if failed_batches:
        log(f"âš ï¸ ì‹¤íŒ¨í•œ ë°°ì¹˜: {failed_batches[:10]}{'...' if len(failed_batches) > 10 else ''}")
    
    # FMS 2.0 ì´ìƒì¸ ì¢…ëª©ë§Œ ì €ì¥
    fms_threshold = 2.0
    filtered_results = all_performers[all_performers['FMS'] >= fms_threshold]
    
    if not filtered_results.empty:
        # ìŠ¤ìº” ê²°ê³¼ íŒŒì¼ë¡œ ì €ì¥
        save_success, save_message, saved_count = save_scan_results(filtered_results, fms_threshold)
        if save_success:
            log(f"ğŸ’¾ {save_message}")
        else:
            log(f"âš ï¸ ì €ì¥ ì‹¤íŒ¨: {save_message}")
    
    # ìŠ¤ìº” ì™„ë£Œ í›„ ì§„í–‰ ìƒíƒœ ì´ˆê¸°í™”
    if 'scan_progress' in st.session_state:
        del st.session_state.scan_progress
    
    return all_performers, scan_message

def get_dynamic_candidates(scan_results_df, current_watchlist, page_size=10, page_num=1):
    """
    í˜„ì¬ ê´€ì‹¬ì¢…ëª©ì— ì—†ëŠ” ì¢…ëª©ë“¤ì„ ë™ì ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    í˜ì´ì§• ì²˜ë¦¬ë¥¼ í†µí•´ ëŒ€ëŸ‰ì˜ í›„ë³´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        scan_results_df (pd.DataFrame): ì „ì²´ ìŠ¤ìº” ê²°ê³¼
        current_watchlist (list): í˜„ì¬ ê´€ì‹¬ì¢…ëª© ëª©ë¡
        page_size (int): í˜ì´ì§€ë‹¹ í‘œì‹œí•  ì¢…ëª© ìˆ˜
        page_num (int): í˜„ì¬ í˜ì´ì§€ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)
    
    Returns:
        tuple: (candidates_df, total_pages, current_page)
    """
    if scan_results_df.empty:
        return pd.DataFrame(), 0, 1
    
    # í˜„ì¬ ê´€ì‹¬ì¢…ëª©ì— ì—†ëŠ” ì¢…ëª©ë§Œ í•„í„°ë§
    available_candidates = scan_results_df[~scan_results_df.index.isin(current_watchlist)].copy()
    
    if available_candidates.empty:
        return pd.DataFrame(), 0, 1
    
    # FMS ìˆœìœ¼ë¡œ ì •ë ¬ (ì´ë¯¸ ì •ë ¬ë˜ì–´ ìˆì§€ë§Œ í™•ì‹¤íˆ í•˜ê¸° ìœ„í•´)
    available_candidates = available_candidates.sort_values("FMS", ascending=False)
    
    # í˜ì´ì§• ì²˜ë¦¬
    total_candidates = len(available_candidates)
    total_pages = (total_candidates - 1) // page_size + 1
    
    # í˜ì´ì§€ ë²ˆí˜¸ ìœ íš¨ì„± ê²€ì‚¬
    page_num = max(1, min(page_num, total_pages))
    
    # í˜„ì¬ í˜ì´ì§€ì˜ ì¢…ëª©ë“¤ ì¶”ì¶œ
    start_idx = (page_num - 1) * page_size
    end_idx = start_idx + page_size
    current_page_candidates = available_candidates.iloc[start_idx:end_idx]
    
    return current_page_candidates, total_pages, page_num

# ------------------------------
# UI ê´€ë ¨ í•¨ìˆ˜ë“¤
# ------------------------------
def get_button_states():
    """
    ë²„íŠ¼ ë¹„í™œì„±í™” ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        tuple: (is_scanning, is_reassessing, button_disabled)
            - is_scanning (bool): ìœ ë‹ˆë²„ìŠ¤ ìŠ¤ìº” ì§„í–‰ ì¤‘ ì—¬ë¶€
            - is_reassessing (bool): ì¬í‰ê°€ ì§„í–‰ ì¤‘ ì—¬ë¶€
            - button_disabled (bool): ë²„íŠ¼ ë¹„í™œì„±í™” ì—¬ë¶€
    """
    is_scanning = ('scan_progress' in st.session_state and 
                   st.session_state.scan_progress.get('total_batches', 0) > 0 and
                   st.session_state.scan_progress.get('completed_batches', 0) < st.session_state.scan_progress.get('total_batches', 0))
    is_reassessing = 'reassessing' in st.session_state and st.session_state.reassessing
    return is_scanning, is_reassessing, is_scanning or is_reassessing
def display_name(sym):
    """ì‹¬ë³¼ì„ í‘œì‹œìš© ì´ë¦„ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if 'NAME_MAP' not in globals():
        return sym
    nm = NAME_MAP.get(sym, sym)
    return f"{nm} ({sym})" if nm and nm != sym else sym

def only_name(sym):
    """ì‹¬ë³¼ì˜ ì´ë¦„ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if 'NAME_MAP' not in globals():
        return sym
    nm = NAME_MAP.get(sym, sym)
    return nm if nm else sym

def update_candidates_after_addition(symbol_to_remove):
    """
    ì¢…ëª© ì¶”ê°€ í›„ í›„ë³´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    ìŠ¤ìº” ê²°ê³¼ì—ì„œ í•´ë‹¹ ì¢…ëª©ì„ ì œê±°í•˜ì—¬ UIì—ì„œ ì‚¬ë¼ì§€ë„ë¡ í•©ë‹ˆë‹¤.
    
    Args:
        symbol_to_remove (str): ì œê±°í•  ì¢…ëª© ì‹¬ë³¼
    
    Returns:
        bool: ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # í˜„ì¬ ì„¸ì…˜ ìƒíƒœì˜ ìŠ¤ìº” ê²°ê³¼ì—ì„œ í•´ë‹¹ ì¢…ëª© ì œê±°
        if 'scan_results' in st.session_state and st.session_state['scan_results'] is not None:
            current_results = st.session_state['scan_results']
            if symbol_to_remove in current_results.index:
                # í•´ë‹¹ ì¢…ëª© ì œê±°
                updated_results = current_results.drop(symbol_to_remove)
                st.session_state['scan_results'] = updated_results
                return True
        return False
    except Exception as e:
        log(f"í›„ë³´ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False

# ------------------------------
# ì¢Œì¸¡ ì œì–´ - ê¹”ë”í•˜ê²Œ ì •ë¦¬ëœ ë©”ë‰´ êµ¬ì¡°
# ------------------------------

# 1. ë¶„ì„ ì„¤ì •
with st.sidebar.expander("ğŸ“Š ë¶„ì„ ì„¤ì •", expanded=True):
    period = st.selectbox("ì°¨íŠ¸ ê¸°ê°„", ["3M","6M","1Y","2Y","5Y"], index=0)
    
    rank_by = st.selectbox("ì •ë ¬ ê¸°ì¤€", ["Î”FMS(1D)","Î”FMS(5D)","FMS(í˜„ì¬)","1M ìˆ˜ìµë¥ "], index=2)
    TOP_N = st.slider("Top N", 5, 60, 20, step=5)
    use_log_scale = st.checkbox("ë¹„êµì°¨íŠ¸ ë¡œê·¸ ìŠ¤ì¼€ì¼", True)

# 2. ê´€ì‹¬ì¢…ëª© ê´€ë¦¬
with st.sidebar.expander("ğŸ“‹ ê´€ì‹¬ì¢…ëª© ê´€ë¦¬", expanded=False):
    # í˜„ì¬ ê´€ì‹¬ì¢…ëª© ì •ë³´
    st.info(f"í˜„ì¬ ê´€ì‹¬ì¢…ëª©: **{len(st.session_state.watchlist)}ê°œ**")
    
    # íŒŒì¼ ê´€ë¦¬
    st.markdown("**ğŸ“ íŒŒì¼ ê´€ë¦¬**")
    
    # ë‹¤ìš´ë¡œë“œ
    if st.button("ğŸ’¾ ê´€ì‹¬ì¢…ëª© ë‹¤ìš´ë¡œë“œ", help="í˜„ì¬ ê´€ì‹¬ì¢…ëª©ì„ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."):
        csv_data = export_watchlist_to_csv(
            st.session_state.watchlist, 
            country_classifier=classify, 
            name_display=display_name
        )
        
        if csv_data:
            st.download_button(
                label="ğŸ“¥ CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=csv_data,
                file_name=f"watchlist_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
        else:
            st.error("âŒ ë‹¤ìš´ë¡œë“œ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    # ì—…ë¡œë“œ
    uploaded_watchlist = st.file_uploader(
        "ğŸ“¤ ê´€ì‹¬ì¢…ëª© ì—…ë¡œë“œ", 
        type=['csv'],
        help="CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ê´€ì‹¬ì¢…ëª©ì„ êµì²´í•©ë‹ˆë‹¤.",
        key="watchlist_uploader"
    )
    
    if uploaded_watchlist is not None and not st.session_state.get('upload_processed', False):
        try:
            csv_data = uploaded_watchlist.read().decode('utf-8-sig')
            new_symbols, message = import_watchlist_from_csv(csv_data)
            
            if new_symbols:
                st.session_state.watchlist = new_symbols
                st.cache_data.clear()
                st.success(message)
                st.session_state.upload_processed = True
                st.rerun()
            else:
                st.error(message)
                
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # ì—…ë¡œë“œ ì²˜ë¦¬ ì™„ë£Œ í›„ í”Œë˜ê·¸ ë¦¬ì…‹
    if st.session_state.get('upload_processed', False):
        st.session_state.upload_processed = False
    
    # êµ¬ë¶„ì„ 
    st.divider()
    
    # ì¬í‰ê°€ ê¸°ëŠ¥
    st.markdown("**ğŸ”„ ì¬í‰ê°€**")
    is_scanning, is_reassessing, button_disabled = get_button_states()
    button_text = 'â³ ì¬í‰ê°€ ì¤‘...' if is_reassessing else 'ğŸ“Š ì¬í‰ê°€ ì‹¤í–‰'
    
    if st.button(button_text, disabled=button_disabled, help="í˜„ì¬ ê´€ì‹¬ì¢…ëª©ì˜ FMSë¥¼ ì¬ê³„ì‚°í•˜ì—¬ ì €ì„±ê³¼ ì¢…ëª©ì„ ì‹ë³„í•©ë‹ˆë‹¤."):
        # ì¬í‰ê°€ ìƒíƒœ ì„¤ì •
        st.session_state.reassessing = True
        
        with st.spinner("ê´€ì‹¬ì¢…ëª©ì„ ì¬í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):
            watchlist_fms = calculate_fms_for_batch(st.session_state.watchlist, period_="1y")
            
            if not watchlist_fms.empty:
                fms_25th = watchlist_fms['FMS'].quantile(0.25)
                stale_candidates = watchlist_fms[watchlist_fms['FMS'] < fms_25th].sort_values('FMS')
                
                if not stale_candidates.empty:
                    st.warning(f"FMS í•˜ìœ„ 25% ì¢…ëª© ({len(stale_candidates)}ê°œ) ë°œê²¬")
                    st.session_state['reassessment_results'] = stale_candidates
                else:
                    st.success("ëª¨ë“  ê´€ì‹¬ì¢…ëª©ì´ ì–‘í˜¸í•œ ìƒíƒœì…ë‹ˆë‹¤!")
                    st.session_state['reassessment_results'] = None
            else:
                st.error("ì¬í‰ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.session_state['reassessment_results'] = None
        
        # ì¬í‰ê°€ ì™„ë£Œ
        st.session_state.reassessing = False
    
    # ì¬í‰ê°€ ê²°ê³¼ í‘œì‹œ
    if 'reassessment_results' in st.session_state and st.session_state['reassessment_results'] is not None:
        st.markdown("**ğŸ“‹ ì œê±° ì œì•ˆ ì¢…ëª©:**")
        stale_candidates = st.session_state['reassessment_results']
        
        for symbol in stale_candidates.index[:5]:
            col1, col2 = st.columns([3, 1])
            with col1:
                fms_score = stale_candidates.loc[symbol, 'FMS']
                st.write(f"**{symbol}** (FMS: {fms_score:.1f})")
            with col2:
                if st.button("ğŸ—‘ï¸", key=f"remove_{symbol}"):
                    # ê´€ì‹¬ì¢…ëª©ì—ì„œ ì œê±°
                    st.session_state.watchlist = remove_from_watchlist(st.session_state.watchlist, [symbol])
                    
                    # ì¬í‰ê°€ ê²°ê³¼ì—ì„œë„ ì œê±°
                    if 'reassessment_results' in st.session_state and st.session_state['reassessment_results'] is not None:
                        if symbol in st.session_state['reassessment_results'].index:
                            st.session_state['reassessment_results'] = st.session_state['reassessment_results'].drop(symbol)
                    
                    st.cache_data.clear()
                    st.rerun()

# 3. ì‹ ê·œ ì¢…ëª© íƒìƒ‰
with st.sidebar.expander("ğŸš€ ì‹ ê·œ ì¢…ëª© íƒìƒ‰", expanded=False):
    
    # ìŠ¤ìº” ì‹¤í–‰
    st.markdown("**ğŸ” ì¢…ëª© ìŠ¤ìº”**")
    
    # ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ ìƒíƒœ í‘œì‹œ
    is_fresh, last_modified, hours_since_update = check_universe_file_freshness()
    if is_fresh and last_modified:
        st.info(f"ğŸ“Š ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ ìµœì‹  ìƒíƒœ: {last_modified.strftime('%Y-%m-%d %H:%M:%S')} ({hours_since_update:.1f}ì‹œê°„ ì „)")
    elif last_modified:
        st.warning(f"âš ï¸ ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ ì˜¤ë˜ë¨: {last_modified.strftime('%Y-%m-%d %H:%M:%S')} ({hours_since_update:.1f}ì‹œê°„ ì „) - ì—…ë°ì´íŠ¸ í•„ìš”")
    else:
        st.error("âŒ ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ ì—†ìŒ - ì—…ë°ì´íŠ¸ í•„ìš”")
    
    # ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ ì—…ë¡œë“œ
    uploaded_universe = st.file_uploader(
        "ğŸ“¤ ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ ì—…ë¡œë“œ", 
        type=['csv'],
        help="CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ìœ ë‹ˆë²„ìŠ¤ë¥¼ êµì²´í•©ë‹ˆë‹¤. (ì„ íƒì‚¬í•­)",
        key="universe_uploader"
    )
    
    if uploaded_universe is not None:
        try:
            # ì—…ë¡œë“œëœ íŒŒì¼ì„ ë©”ëª¨ë¦¬ì—ì„œ ì½ê¸°
            temp_universe = pd.read_csv(uploaded_universe)
            if 'Symbol' in temp_universe.columns:
                temp_universe.to_csv('screened_universe.csv', index=False)
                st.success(f"âœ… ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤: {len(temp_universe)}ê°œ ì¢…ëª©")
                st.rerun()
            else:
                st.error("âŒ CSV íŒŒì¼ì— 'Symbol' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # ìŠ¤ìº” ì§„í–‰ ìƒí™© í‘œì‹œ
    if 'scan_progress' in st.session_state and st.session_state.scan_progress['total_batches'] > 0:
        progress = st.session_state.scan_progress['completed_batches'] / st.session_state.scan_progress['total_batches']
        st.progress(progress, text=f"FMS ìŠ¤ìº” ì§„í–‰ë¥ : {st.session_state.scan_progress['completed_batches']}/{st.session_state.scan_progress['total_batches']} ë°°ì¹˜")
        
        if st.session_state.scan_progress['start_time']:
            elapsed = (datetime.now(KST) - st.session_state.scan_progress['start_time']).total_seconds()
            st.caption(f"ê²½ê³¼ì‹œê°„: {elapsed:.0f}ì´ˆ | ì„±ê³µ: {st.session_state.scan_progress['successful_symbols']}ê°œ | ì‹¤íŒ¨: {st.session_state.scan_progress['failed_symbols']}ê°œ")
        
        # ìŠ¤ìº”ì´ ì™„ë£Œë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì¤‘ë‹¨ ë²„íŠ¼ í‘œì‹œ
        if st.session_state.scan_progress['completed_batches'] < st.session_state.scan_progress['total_batches']:
            if st.button('â¹ï¸ ìŠ¤ìº” ì¤‘ë‹¨', help="ì§„í–‰ ì¤‘ì¸ ìŠ¤ìº”ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤."):
                if 'scan_progress' in st.session_state:
                    del st.session_state.scan_progress
                st.rerun()
    
    # FMS ì„ê³„ê°’ ì„¤ì •
    fms_threshold = st.slider("FMS ì„ê³„ê°’", 0.0, 5.0, 2.0, 0.1, help="ì´ ê°’ ì´ìƒì˜ FMSë¥¼ ê°€ì§„ ì¢…ëª©ë§Œ í‘œì‹œë©ë‹ˆë‹¤.")
    
    # ì €ì¥ëœ ìŠ¤ìº” ê²°ê³¼ ë¡œë“œ ë²„íŠ¼
    if st.button('ğŸ“‚ ì €ì¥ëœ ê²°ê³¼ ë¡œë“œ', help="ì´ì „ì— ì €ì¥ëœ ìŠ¤ìº” ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."):
        try:
            success, loaded_results, load_message = load_latest_scan_results(fms_threshold)
            if success and not loaded_results.empty:
                st.success(load_message)
                st.session_state['scan_results'] = loaded_results
                st.session_state['scan_page'] = 1  # í˜ì´ì§€ ì´ˆê¸°í™”
            else:
                st.warning(load_message)
        except Exception as e:
            st.error(f"ê²°ê³¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
   
    # ìŠ¤ìº” ì‹¤í–‰ ë²„íŠ¼
    is_scanning, is_reassessing, button_disabled = get_button_states()
    button_text = 'â³ ìŠ¤ìº” ì¤‘...' if is_scanning else 'ğŸš€ ìœ ë‹ˆë²„ìŠ¤ ìŠ¤ìº”'
    if st.button(button_text, type="primary", disabled=button_disabled, help="ìœ ë‹ˆë²„ìŠ¤ ì—…ë°ì´íŠ¸ í›„ FMS ìƒìœ„ ì¢…ëª©ì„ íƒìƒ‰í•©ë‹ˆë‹¤. (ì‹¤ì œ ì§„í–‰ë¥ ì€ ì½˜ì†”ì—ì„œ í™•ì¸ ê°€ëŠ¥)"):
        # ìŠ¤ìº” ìƒíƒœ ì´ˆê¸°í™”
        if 'scan_progress' in st.session_state:
            del st.session_state.scan_progress
        
        try:
            scan_results, scan_message = scan_market_for_new_opportunities()
            
            if not scan_results.empty:
                st.success(scan_message)
                # FMS ì„ê³„ê°’ ì ìš©
                filtered_results = scan_results[scan_results['FMS'] >= fms_threshold]
                if not filtered_results.empty:
                    st.session_state['scan_results'] = filtered_results
                    st.session_state['scan_page'] = 1  # í˜ì´ì§€ ì´ˆê¸°í™”
                else:
                    st.warning(f"FMS {fms_threshold} ì´ìƒì¸ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                    st.session_state['scan_results'] = None
            else:
                st.error(f"ìŠ¤ìº” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤: {scan_message}")
                st.session_state['scan_results'] = None
                
        except Exception as e:
            st.error(f"ìŠ¤ìº” ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.session_state['scan_results'] = None
    
    # ìŠ¤ìº” ê²°ê³¼ í‘œì‹œ
    if 'scan_results' in st.session_state and st.session_state['scan_results'] is not None:
        st.markdown("**ğŸ“‹ ë°œê²¬ëœ ì¢…ëª©:**")
        
        # í˜ì´ì§• ì„¤ì •
        page_size = st.selectbox("í˜ì´ì§€ë‹¹ í‘œì‹œ ì¢…ëª© ìˆ˜", [5, 10, 15, 20, 25, 30], index=1)
        
        # í˜„ì¬ í˜ì´ì§€ ì´ˆê¸°í™”
        if 'scan_page' not in st.session_state:
            st.session_state['scan_page'] = 1
        
        # ë™ì  í›„ë³´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        current_watchlist = st.session_state.get('watchlist', [])
        candidates_df, total_pages, current_page = get_dynamic_candidates(
            st.session_state['scan_results'], 
            current_watchlist, 
            page_size, 
            st.session_state['scan_page']
        )
        
        if not candidates_df.empty:
            # í˜ì´ì§€ ì •ë³´ í‘œì‹œ
            st.info(f"ğŸ“„ í˜ì´ì§€ {current_page}/{total_pages}")
            
            # í˜ì´ì§• ì»¨íŠ¸ë¡¤
            prev_col, spacer_col, next_col = st.columns([1, 2, 1])
            with prev_col:
                if st.button("â¬…ï¸", disabled=(current_page <= 1), key=f"prev_page_{current_page}"):
                    st.session_state['scan_page'] = max(1, current_page - 1)
                    st.rerun()
            with next_col:
                if st.button("â¡ï¸", disabled=(current_page >= total_pages), key=f"next_page_{current_page}"):
                    st.session_state['scan_page'] = min(total_pages, current_page + 1)
                    st.rerun()
            
            # ì¢…ëª© ëª©ë¡ í‘œì‹œ
            for idx, (symbol, row) in enumerate(candidates_df.iterrows()):
                info_col, button_col = st.columns([3, 1])
                with info_col:
                    fms_score = row['FMS']
                    fms_color = "ğŸŸ¢" if fms_score >= 3.0 else "ğŸŸ¡" if fms_score >= 2.0 else "ğŸ”´"
                    st.write(f"{fms_color} **{symbol}** (FMS: {fms_score:.1f})")
                with button_col:
                    if st.button("â•", key=f"add_{symbol}_{idx}"):
                        # ê´€ì‹¬ì¢…ëª©ì— ì¶”ê°€ (ì´ë¯¸ ìˆì–´ë„ ì¤‘ë³µ ì œê±°ë¨)
                        st.session_state.watchlist = add_to_watchlist(st.session_state.watchlist, [symbol])
                        
                        # í›„ë³´ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì œê±° (ì„±ê³µ/ì‹¤íŒ¨ ê´€ê³„ì—†ì´)
                        update_candidates_after_addition(symbol)
                        
                        # í˜ì´ì§• ì•ˆì „ì„± ë³´ì¥: í˜„ì¬ í˜ì´ì§€ê°€ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ì²« í˜ì´ì§€ë¡œ
                        if 'scan_results' in st.session_state and st.session_state['scan_results'] is not None:
                            remaining_candidates = st.session_state['scan_results'][~st.session_state['scan_results'].index.isin(st.session_state.watchlist)]
                            if not remaining_candidates.empty:
                                total_pages = (len(remaining_candidates) - 1) // page_size + 1
                                if st.session_state.get('scan_page', 1) > total_pages:
                                    st.session_state['scan_page'] = 1
                        
                        # ìºì‹œ ì´ˆê¸°í™” ë° í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                        st.cache_data.clear()
                        st.rerun()

        else:
            st.info("ë” ì´ìƒ ì¶”ê°€í•  ìˆ˜ ìˆëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì €ì¥ëœ ìŠ¤ìº” ê²°ê³¼ íŒŒì¼ ì •ë³´ í‘œì‹œ
            scan_files_info = get_scan_results_info()
            if scan_files_info:
                st.markdown("**ğŸ“ ì €ì¥ëœ ìŠ¤ìº” ê²°ê³¼ íŒŒì¼:**")
                for file_info in scan_files_info[:3]:  # ìµœê·¼ 3ê°œë§Œ í‘œì‹œ
                    st.caption(f"ğŸ“„ {file_info['formatted_time']} - {file_info['symbol_count']}ê°œ ì¢…ëª©")
    

# 4. ìˆ˜ë™ ê´€ë¦¬ (ê°„ë‹¨í•œ ì¶”ê°€/ì‚­ì œ)
with st.sidebar.expander("âœï¸ ìˆ˜ë™ ê´€ë¦¬", expanded=False):
    # í‹°ì»¤ ì¶”ê°€
    new_ticker = st.text_input("í‹°ì»¤ ì¶”ê°€ (ì˜ˆ: AAPL)", "").upper().strip()
    if st.button("â• ì¶”ê°€"):
        if new_ticker and new_ticker not in st.session_state.watchlist:
            st.session_state.watchlist = add_to_watchlist(st.session_state.watchlist, [new_ticker])
            st.success(f"'{new_ticker}' ì¶”ê°€ë¨")
            st.rerun()
        elif new_ticker in st.session_state.watchlist:
            st.warning(f"'{new_ticker}'ëŠ” ì´ë¯¸ ê´€ì‹¬ì¢…ëª©ì— ìˆìŠµë‹ˆë‹¤.")
        else:
            st.error("ìœ íš¨í•œ í‹°ì»¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    # í‹°ì»¤ ì‚­ì œ
    if st.session_state.watchlist:
        ticker_to_remove = st.selectbox("ì‚­ì œí•  í‹°ì»¤ ì„ íƒ", [""] + st.session_state.watchlist)
        if st.button("ğŸ—‘ï¸ ì‚­ì œ"):
            if ticker_to_remove:
                st.session_state.watchlist = remove_from_watchlist(st.session_state.watchlist, [ticker_to_remove])
                st.success(f"'{ticker_to_remove}' ì‚­ì œë¨")
                st.rerun()
            else:
                st.error("ì‚­ì œí•  ì¢…ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

with st.sidebar.expander("ğŸ”§ ë„êµ¬ ë° ë„ì›€ë§", expanded=False):
    # FMS ì„¤ëª…
    st.markdown("**ğŸ“Š FMS (Fast Momentum Score)**")
    
    st.markdown(f"""
    **FMS = {FMS_FORMULA}**
    
    â€¢ **ì¶”ì„¸ ì§€ì†ì„±**: 1M + 3M ìˆ˜ìµë¥ ë¡œ ë‹¨ê¸°/ì¤‘ê¸° ëª¨ë©˜í…€ ì¢…í•© í‰ê°€
    â€¢ **ì•ˆì •ì„± ì¤‘ì‹œ**: ë³€ë™ì„± í˜ë„í‹° ê°•í™” (-0.4)ë¡œ ê¸‰ë“± ì¢…ëª© í•„í„°ë§
    â€¢ **EMA ìƒëŒ€ìœ„ì¹˜**: 50ì¼ ì§€ìˆ˜ì´ë™í‰ê·  ëŒ€ë¹„ í˜„ì¬ê°€ ìœ„ì¹˜ë¡œ ì¶”ì„¸ ê°•ë„ ì¸¡ì •
    â€¢ **ê±°ë˜ ì í•©ì„± í•„í„°**: 
      - ì¹˜ëª…ì  ë³€ë™ì„±: 63ê±°ë˜ì¼ ë‚´ ì¼ì¼ ë³€ë™í­ 15% ì´ˆê³¼ ì‹œ ì‹¤ê²©
      - ë°˜ë³µì  í•˜ë°©ë¦¬ìŠ¤í¬: 20ê±°ë˜ì¼ ë‚´ í•˜ë°©ë¦¬ìŠ¤í¬ -7% ë¯¸ë§Œ 4ì¼ ì´ìƒ ì‹œ ì‹¤ê²©
    â€¢ **ëª©í‘œ**: ê¾¸ì¤€í•˜ê³  ì§€ì† ê°€ëŠ¥í•œ ìƒìŠ¹ ì¶”ì„¸ ì¢…ëª© ë°œêµ´
    """)
    
    st.markdown("---")
    
    # ë„êµ¬ ë²„íŠ¼ë“¤
    if st.button("ğŸ—‚ï¸ ë°ì´í„° ìºì‹œ ì´ˆê¸°í™”"):
        st.cache_data.clear()
        st.success("ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    is_scanning, is_reassessing, button_disabled = get_button_states()
    if st.button("ğŸ”„ ê´€ì‹¬ì¢…ëª© ì´ˆê¸°í™”", disabled=button_disabled):
        default_symbols = DEFAULT_USD_SYMBOLS + DEFAULT_KRW_SYMBOLS + DEFAULT_JPY_SYMBOLS
        st.session_state.watchlist = default_symbols
        save_watchlist(default_symbols)
        st.success("ê´€ì‹¬ì¢…ëª©ì´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.rerun()



@st.cache_data(ttl=60*60*6, show_spinner=True)
def build_prices_krw(period_key="6M", watchlist_symbols=None):
    period_map = {"3M":"6mo","6M":"1y","1Y":"2y","2Y":"5y","5Y":"10y"}
    yf_period = period_map.get(period_key, "1y")
    interval = "1d"

    # ê´€ì‹¬ì¢…ëª© ëª©ë¡ì„ ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ì•„ì„œ ìºì‹œ í‚¤ì— í¬í•¨
    if watchlist_symbols is None:
        watchlist_symbols = st.session_state.watchlist

    # í˜„ì¬ ê´€ì‹¬ì¢…ëª©ì—ì„œ êµ­ê°€ë³„ë¡œ ë¶„ë¥˜
    usd_symbols = [str(s) for s in watchlist_symbols if classify(s) == "USA"]
    krw_symbols = [str(s) for s in watchlist_symbols if classify(s) == "KOR"]
    jpy_symbols = [str(s) for s in watchlist_symbols if classify(s) == "JPN"]

    usdkrw, usdjpy, jpykrw, fx_missing = download_fx(yf_period, interval)
    usd_df, miss_us = download_prices(usd_symbols, yf_period, interval)
    krw_df, miss_kr = download_prices(krw_symbols, yf_period, interval)
    jpy_df, miss_jp = download_prices(jpy_symbols, yf_period, interval)

    usd_df = align_bday_ffill(usd_df)
    krw_df = align_bday_ffill(krw_df)
    jpy_df = align_bday_ffill(jpy_df)
    usdkrw = align_bday_ffill(usdkrw.to_frame()).iloc[:,0] if not usdkrw.empty else usdkrw
    jpykrw = align_bday_ffill(jpykrw.to_frame()).iloc[:,0] if not jpykrw.empty else jpykrw

    frames=[]
    if not usd_df.empty and not usdkrw.empty:
        usdkrw_matched = usdkrw.reindex(usd_df.index).ffill()
        frames.append(usd_df.mul(usdkrw_matched, axis=0))
    if not krw_df.empty:
        frames.append(krw_df)
    if not jpy_df.empty and not jpykrw.empty:
        jpykrw_matched = jpykrw.reindex(jpy_df.index).ffill()
        frames.append(jpy_df.mul(jpykrw_matched, axis=0))

    if not frames:
        return pd.DataFrame(), {"fx_missing": fx_missing, "price_missing": miss_us+miss_kr+miss_jp}

    prices_krw = pd.concat(frames, axis=1).sort_index()
    prices_krw = prices_krw.loc[:, ~prices_krw.columns.duplicated()]
    prices_krw = harmonize_calendar(prices_krw, coverage=0.9)

    miss_dict = {
        "fx_missing": fx_missing,
        "price_missing": sorted(list(set(miss_us+miss_kr+miss_jp)))
    }
    last_row = prices_krw.iloc[-1]
    usa_cols = [c for c in prices_krw.columns if classify(c)=="USA"]
    na_usa = last_row[usa_cols].isna().sum()
    log(f"Final DF shape: {prices_krw.shape}; last row USA NaNs: {na_usa}/{len(usa_cols)}")
    return prices_krw, miss_dict

# ------------------------------
# ì´ë¦„ ìºì‹œ
# ------------------------------
@st.cache_data(ttl=60*60*24, show_spinner=False)
def fetch_long_names(symbols):
    out = {}
    for s in symbols:
        name = None
        try:
            info = yf.Ticker(s).get_info()
            name = info.get("longName") or info.get("shortName")
        except Exception as e:
            log(f"INFO name fetch fail: {s} -> {e}")
        out[s] = name if name else s
    return out





# ------------------------------
# ë°ì´í„° ë¡œë“œ ë° ì´ë¦„
# ------------------------------
with st.spinner("ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
    prices_krw, miss = build_prices_krw(period, st.session_state.watchlist)
if prices_krw.empty:
    st.error("ê°€ê²© ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

with st.spinner("ì¢…ëª©ëª…(í’€ë„¤ì„) ë¡œë”© ì¤‘â€¦(ìµœì´ˆ 1íšŒë§Œ ë‹¤ì†Œ ì§€ì—°)"):
    NAME_MAP = fetch_long_names(list(prices_krw.columns))


st.title("âš¡ KRW Momentum Radar v3.0.7")



# ------------------------------
# ëª¨ë©˜í…€/ê°€ì† ê³„ì‚° (ê±°ë˜ ì í•©ì„± í•„í„° ì ìš©)
# ------------------------------
with st.spinner("ëª¨ë©˜í…€/ê°€ì† ê³„ì‚° ì¤‘â€¦"):
    # ê´€ì‹¬ì¢…ëª©ì˜ OHLC ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ê±°ë˜ ì í•©ì„± í•„í„°ìš©)
    watchlist_symbols = list(prices_krw.columns)
    period_map = {"3M":"6mo","6M":"1y","1Y":"2y","2Y":"5y","5Y":"10y"}
    ohlc_data, ohlc_missing = download_ohlc_prices(watchlist_symbols, period_map.get(period, "1y"), "1d")
    if ohlc_data.empty:
        ohlc_data = None
    
    mom = momentum_now_and_delta(prices_krw, ohlc_data=ohlc_data, symbols=watchlist_symbols)
rank_col = {"Î”FMS(1D)":"Î”FMS_1D","Î”FMS(5D)":"Î”FMS_5D","FMS(í˜„ì¬)":"FMS","1M ìˆ˜ìµë¥ ":"R_1M"}[rank_by]
mom_ranked = mom.sort_values(rank_col, ascending=False)

# ------------------------------
# â‘  ê°€ì† ë³´ë“œ
# ------------------------------
st.subheader("ê°€ì† ë³´ë“œ")
topN = mom_ranked.head(TOP_N)
bar = go.Figure([go.Bar(
    x=topN.index, y=topN[rank_col],
    customdata=np.array([only_name(s) for s in topN.index]),
    hovertemplate="%{customdata} (%{x})<br>"+rank_col+": %{y:.2f}<extra></extra>"
)])
bar.update_layout(height=320, margin=dict(l=10,r=10,t=10,b=10), xaxis_tickangle=-45, yaxis_title=rank_col)
st.plotly_chart(bar, use_container_width=True, config={"displayModeBar": False})

# ------------------------------
# â‘¡ ë¹„êµ ì°¨íŠ¸ â€” Top N
# ------------------------------
st.subheader(f"ë¹„êµ ì°¨íŠ¸ â€” ìƒìœ„ {TOP_N} (ê¸°ì¤€: {rank_col})")
sel_syms = list(topN.index)
df_view = prices_krw[sel_syms].dropna(how="all")
win_map={"3M":63,"6M":126,"1Y":252,"2Y":504,"5Y":1260}
win = win_map.get(period,126)
if df_view.shape[0]>win: df_view = df_view.iloc[-win:]
df_base = df_view/df_view.iloc[0]*100.0
fig_comp = go.Figure()
for c in df_base.columns:
    nm_only = only_name(c)
    fig_comp.add_trace(go.Scatter(
        x=df_base.index, y=df_base[c], mode="lines", name=c,
        customdata=np.array([nm_only]*len(df_base)),
        hovertemplate="%{customdata} ("+c+")<br>%{x|%Y-%m-%d}<br>Index:%{y:.2f}<extra></extra>"
    ))
fig_comp.update_layout(
    height=420, margin=dict(l=10,r=10,t=10,b=10),
    yaxis=dict(type="log" if use_log_scale else "linear", title="Rebased 100"),
    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
)
st.plotly_chart(fig_comp, use_container_width=True)

# ==============================
# â‘¢ ìˆ˜ìµë¥ â€“ë³€ë™ì„± ì´ë™ë§µ
# ==============================
st.subheader("ìˆ˜ìµë¥ â€“ë³€ë™ì„± ì´ë™ë§µ (ìµœê·¼ ìƒíƒœ â†’ ì–´ë””ì„œ ì™”ëŠ”ê°€)")

cc1, cc2, cc3, cc4 = st.columns([1.2,1.2,1.2,1.6])
with cc1:
    rv_window = st.selectbox("ìˆ˜ìµë¥ /ë³€ë™ì„± ì°½(ê±°ë˜ì¼)", [21, 42, 63], index=0, help="ì—°ìœ¨í™”: 252 ê¸°ì¤€")
with cc2:
    plot_n = st.selectbox("í‘œì‹œ ì¢…ëª© ìˆ˜", [10, 15, 20, 25, 30], index=2, help="ìƒìœ„ ë­í‚¹ ê¸°ì¤€ìœ¼ë¡œ ì œí•œí•´ ê³¼ë°€ë„ ì™„í™”")
with cc4:
    motion_mode = st.selectbox("ëª¨ì…˜(ì• ë‹ˆë©”ì´ì…˜)", ["ë„ê¸°", "ìµœê·¼ 10ì¼", "ìµœê·¼ 20ì¼"], index=0,
                               help="í”„ë ˆì„ë§ˆë‹¤ í˜„ì¬ ìœ„ì¹˜ì™€ ê¼¬ë¦¬ë¥¼ ë™ì‹œì— ê°±ì‹ ")
with cc3:
    # ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œê°€ ì„ íƒë˜ë©´ ê¼¬ë¦¬ ê¸¸ì´ë¥¼ 5ë¡œ ìë™ ì„¤ì •
    if motion_mode != "ë„ê¸°":
        tail_days = st.selectbox("ê¼¬ë¦¬ ê¸¸ì´(ìµœê·¼ nì¼ ê²½ë¡œ)", [0, 3, 5, 10], index=2, help="ì˜¤ëŠ˜ ê¸°ì¤€ ê³¼ê±° nê±°ë˜ì¼ì˜ ì´ë™ ê²½ë¡œë¥¼ ì ì„ ìœ¼ë¡œ í‘œì‹œ")
    else:
        tail_days = st.selectbox("ê¼¬ë¦¬ ê¸¸ì´(ìµœê·¼ nì¼ ê²½ë¡œ)", [0, 3, 5, 10], index=0, help="ì˜¤ëŠ˜ ê¸°ì¤€ ê³¼ê±° nê±°ë˜ì¼ì˜ ì´ë™ ê²½ë¡œë¥¼ ì ì„ ìœ¼ë¡œ í‘œì‹œ")

def ann_vol(series, win):
    r = series.pct_change().dropna()
    if len(r) < max(5, int(win/3)): return np.nan
    r = r.tail(win);  return r.std() * np.sqrt(252.0)

def ann_cagr(series, win):
    s = series.dropna().tail(win+1)
    if len(s) < win+1: return np.nan
    start, end = s.iloc[-(win+1)], s.iloc[-1]
    if start <= 0 or end <= 0: return np.nan
    return (end/start)**(252.0/win) - 1.0

def scatter_points_for_date(df_prices, ref_loc, win):
    if ref_loc < 1: return pd.DataFrame()
    pts = {}
    for c in df_prices.columns:
        s = df_prices[c].iloc[:ref_loc+1]
        v = ann_vol(s, win); g = ann_cagr(s, win)
        pts[c] = (v, g)
    return pd.DataFrame(pts, index=["Vol","CAGR"]).T

plot_syms = list(mom_ranked.head(plot_n).index)
idx_all = prices_krw.index
today_loc = len(idx_all) - 1
yesterday_loc = max(0, today_loc - 1)
monthago_loc = max(0, today_loc - 21)

pts_today = scatter_points_for_date(prices_krw[plot_syms], today_loc, rv_window)
pts_yest  = scatter_points_for_date(prices_krw[plot_syms], yesterday_loc, rv_window)
pts_mago  = scatter_points_for_date(prices_krw[plot_syms], monthago_loc, rv_window)

# --- ê¼¬ë¦¬ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ìœ í‹¸(ì—°í•œâ†’ì§„í•œ)
def add_tail_segments(fig, sym, tail_len, color="rgba(0,0,0,1)"):
    if tail_len <= 0: return
    # loc: today - tail_len ... today
    prev_xy = None
    for k in range(tail_len, -1, -1):
        loc = max(0, today_loc - k)
        p = scatter_points_for_date(prices_krw[[sym]], loc, rv_window)
        if p.empty or p.isna().any().any(): 
            prev_xy = None
            continue
        x = float(p.iloc[0,0])*100.0  # Vol%
        y = float(p.iloc[0,1])*100.0  # CAGR%
        if prev_xy is not None:
            age = (tail_len - k + 1)  # ìµœê·¼ì¼ìˆ˜ë¡ ì‘ìŒ
            alpha = max(0.15, min(0.5, age/(tail_len+1)))  # 0.15~0.5
            fig.add_trace(go.Scatter(
                x=[prev_xy[0], x], y=[prev_xy[1], y],
                mode="lines", line=dict(width=2, dash="dot"),
                showlegend=False, hoverinfo="skip", opacity=alpha, name=f"{sym}-tail"
            ))
        prev_xy = (x, y)

# --- ì •ì (3ì  + ì´ë™ì„  + ê¼¬ë¦¬)
def make_static_scatter():
    fig = go.Figure()
    # ê¼¬ë¦¬: ì‹¬ë³¼ë³„ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
    for c in plot_syms:
        add_tail_segments(fig, c, tail_days)

    # ê¼¬ë¦¬ ê¸¸ì´ê°€ 0ì¼ ë•Œë§Œ ê³¼ê±° ì‹œì ë“¤ í‘œì‹œ
    if tail_days == 0:
        # 1M ago
        fig.add_trace(go.Scatter(
            x=pts_mago["Vol"]*100, y=pts_mago["CAGR"]*100, mode="markers",
            marker=dict(size=7, color="lightgray"),
            text=[display_name(s) for s in pts_mago.index],
            hovertemplate="%{text}<br>1M ago<br>Vol: %{x:.2f}% | CAGR: %{y:.2f}%<extra></extra>",
            name="1M ago", showlegend=True
        ))
        # Yesterday
        fig.add_trace(go.Scatter(
            x=pts_yest["Vol"]*100, y=pts_yest["CAGR"]*100, mode="markers",
            marker=dict(size=8, color="silver"),
            text=[display_name(s) for s in pts_yest.index],
            hovertemplate="%{text}<br>Yesterday<br>Vol: %{x:.2f}% | CAGR: %{y:.2f}%<extra></extra>",
            name="Yesterday", showlegend=True
        ))
    # Today
    fig.add_trace(go.Scatter(
        x=pts_today["Vol"]*100, y=pts_today["CAGR"]*100, mode="markers+text",
        marker=dict(size=9),
        text=[display_name(s) for s in pts_today.index],
        textposition="top center",
        hovertemplate="%{text}<br>Today<br>Vol: %{x:.2f}% | CAGR: %{y:.2f}%<extra></extra>",
        name="Today", showlegend=True
    ))
    # ê¼¬ë¦¬ ê¸¸ì´ê°€ 0ì¼ ë•Œë§Œ 1Mâ†’Yestâ†’Today ì—°ê²°ì„  í‘œì‹œ
    if tail_days == 0:
        for c in plot_syms:
            xs=[]; ys=[]
            for dfp in (pts_mago, pts_yest, pts_today):
                if c in dfp.index and not dfp.loc[c].isna().any():
                    xs.append(float(dfp.loc[c,"Vol"])*100)
                    ys.append(float(dfp.loc[c,"CAGR"])*100)
            if len(xs)>=2:
                fig.add_trace(go.Scatter(x=xs, y=ys, mode="lines",
                                         line=dict(width=1), opacity=0.35,
                                         name=f"path-{c}", showlegend=False, hoverinfo="skip"))
    fig.update_layout(
        height=520, margin=dict(l=10,r=10,t=10,b=10),
        xaxis_title="Volatility (ann, %)", yaxis_title="CAGR (ann, %)",
        hovermode="closest"
    )
    return fig

# --- ì• ë‹ˆë©”ì´ì…˜: í”„ë ˆì„ë§ˆë‹¤ í˜„ì¬ ìœ„ì¹˜ + ê° ì¢…ëª© ê¼¬ë¦¬ ë™ì‹œ ê°±ì‹ 
def make_motion_scatter(days):
    days = min(days, len(idx_all)-1)
    start_loc = max(0, today_loc - days)
    frames = []

    # ì´ˆê¸° í”„ë ˆì„ ë°ì´í„°
    p0 = scatter_points_for_date(prices_krw[plot_syms], start_loc, rv_window)
    traces = []

    # ê¼¬ë¦¬ëŠ” ì‹¬ë³¼ë³„ë¡œ ê°œë³„ traceë¥¼ ì‚¬ìš©(í”„ë ˆì„ë§ˆë‹¤ ì¬ê³„ì‚°)
    # ì´ˆê¸° ê¼¬ë¦¬
    tail_traces = []
    for c in plot_syms:
        # ë¹ˆ ê¼¬ë¦¬(ì´ˆê¸°)
        tail_traces.append(go.Scatter(x=[], y=[], mode="lines", line=dict(width=2, dash="dot"),
                                      showlegend=False, hoverinfo="skip", name=f"{c}-tail"))

    # ì´ˆê¸° í¬ì¸íŠ¸
    traces.extend(tail_traces)
    traces.append(go.Scatter(
        x=p0["Vol"]*100, y=p0["CAGR"]*100, mode="markers",
        marker=dict(size=9),
        text=[display_name(s) for s in p0.index],
        hovertemplate="%{text}<br>%{x:.2f}% / %{y:.2f}%<extra></extra>",
        name="Points", showlegend=False
    ))

    # í”„ë ˆì„ ìƒì„±
    for loc in range(start_loc, today_loc+1):
        p = scatter_points_for_date(prices_krw[plot_syms], loc, rv_window)
        frame_data = []

        # ê° ì¢…ëª© ê¼¬ë¦¬ ì¢Œí‘œ ê³„ì‚°
        for c in plot_syms:
            xs=[]; ys=[]
            for k in range(tail_days, -1, -1):
                loc_k = max(0, loc - k)
                pk = scatter_points_for_date(prices_krw[[c]], loc_k, rv_window)
                if pk.empty or pk.isna().any().any(): 
                    continue
                xs.append(float(pk.iloc[0,0])*100.0)
                ys.append(float(pk.iloc[0,1])*100.0)
            frame_data.append(go.Scatter(x=xs, y=ys, mode="lines", line=dict(width=2, dash="dot"),
                                         showlegend=False, hoverinfo="skip", name=f"{c}-tail"))
        # í¬ì¸íŠ¸
        frame_data.append(go.Scatter(
            x=p["Vol"]*100, y=p["CAGR"]*100, mode="markers",
            marker=dict(size=9),
            text=[display_name(s) for s in p.index],
            hovertemplate="%{text}<br>%{x:.2f}% / %{y:.2f}%<extra></extra>",
            name="Points", showlegend=False
        ))

        frames.append(go.Frame(data=frame_data, name=str(prices_krw.index[loc].date())))

    fig = go.Figure(data=traces, frames=frames)
    # ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œì— ë”°ë¥¸ ìë™ ì¬ìƒ ì„¤ì •
    auto_play = motion_mode != "ë„ê¸°"
    
    fig.update_layout(
        height=520, margin=dict(l=10,r=10,t=10,b=10),
        xaxis_title="Volatility (ann, %)", yaxis_title="CAGR (ann, %)",
        updatemenus=[{
            "type": "buttons", "showactive": False,
            "buttons": [
                {"label":"â–¶ Play","method":"animate",
                 "args":[None, {"frame":{"duration":300, "redraw":True}, "fromcurrent":True, "transition":{"duration":0}}]},
                {"label":"â¸ Pause","method":"animate","args":[[None], {"frame":{"duration":0}, "mode":"immediate"}]}
            ]
        }],
        sliders=[{
            "steps":[{"label":f.name, "method":"animate", "args":[[f.name], {"mode":"immediate","frame":{"duration":0,"redraw":True}}]} for f in frames],
            "currentvalue":{"prefix":"Date: "}
        }]
    )
    
    # ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œê°€ ì„ íƒë˜ë©´ ìë™ ì¬ìƒ
    if auto_play:
        fig.update_layout(
            updatemenus=[{
                "type": "buttons", "showactive": False,
                "buttons": [
                    {"label":"â–¶ Play","method":"animate",
                     "args":[None, {"frame":{"duration":300, "redraw":True}, "fromcurrent":True, "transition":{"duration":0}}]},
                    {"label":"â¸ Pause","method":"animate","args":[[None], {"frame":{"duration":0}, "mode":"immediate"}]}
                ]
            }]
        )
    return fig

# ë Œë”

if motion_mode == "ë„ê¸°":
    fig_mv = make_static_scatter()
else:
    days = 10 if "10" in motion_mode else 20
    fig_mv = make_motion_scatter(days)
    
    # ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œì¼ ë•Œ ìë™ ì¬ìƒì„ ìœ„í•œ JavaScript ì¶”ê°€
    if motion_mode != "ë„ê¸°":
        st.markdown("""
        <script>
        setTimeout(function() {
            var plotlyDiv = document.querySelector('[data-testid="stPlotlyChart"] iframe');
            if (plotlyDiv) {
                plotlyDiv.onload = function() {
                    var plotlyFrame = plotlyDiv.contentWindow;
                    if (plotlyFrame && plotlyFrame.Plotly) {
                        setTimeout(function() {
                            plotlyFrame.Plotly.animate(plotlyFrame.document.querySelector('.plotly-graph-div'), null, {
                                frame: {duration: 300, redraw: true},
                                fromcurrent: true,
                                transition: {duration: 0}
                            });
                        }, 1000);
                    }
                };
            }
        }, 500);
        </script>
        """, unsafe_allow_html=True)

st.plotly_chart(fig_mv, use_container_width=True)
st.caption("ì„¤ëª…: ê° ì ì€ ì„ íƒí•œ ì°½(ê¸°ë³¸ 21ê±°ë˜ì¼)ì˜ ì—°ìœ¨í™” ìˆ˜ìµë¥ (CAGR)Â·ì—°ìœ¨í™” ë³€ë™ì„±ì…ë‹ˆë‹¤. "
           "â€˜ê¼¬ë¦¬ ê¸¸ì´â€™ëŠ” ì˜¤ëŠ˜ ê¸°ì¤€ ê³¼ê±° nê±°ë˜ì¼ ë™ì•ˆ ì¢Œí‘œì˜ ì´ë™ ê²½ë¡œë¥¼ ì ì„ ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤. "
           "ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œì—ì„œëŠ” ë‚ ì§œê°€ ë°”ë€œì— ë”°ë¼ í˜„ì¬ ìœ„ì¹˜ì™€ ê¼¬ë¦¬ê°€ í•¨ê»˜ ê°±ì‹ ë©ë‹ˆë‹¤.")

# ------------------------------
# â‘£ ì„¸ë¶€ ë³´ê¸°
# ------------------------------
st.subheader("ì„¸ë¶€ ë³´ê¸°")
ordered_options = list(mom_ranked.index)
default_sym = (sel_syms[0] if sel_syms else ordered_options[0]) if ordered_options else prices_krw.columns[0]
detail_sym = st.selectbox("í‹°ì»¤ ì„ íƒ", options=ordered_options,
                          index=ordered_options.index(default_sym) if default_sym in ordered_options else 0,
                          format_func=lambda s: display_name(s))
s = prices_krw[detail_sym].dropna()
e20,e50,e200 = ema(s,20), ema(s,50), ema(s,200)
fig_det = go.Figure()
fig_det.add_trace(go.Scatter(x=s.index, y=s.values, mode="lines", name="KRW"))
fig_det.add_trace(go.Scatter(x=e20.index, y=e20.values, mode="lines", name="EMA20"))
fig_det.add_trace(go.Scatter(x=e50.index, y=e50.values, mode="lines", name="EMA50"))
fig_det.add_trace(go.Scatter(x=e200.index, y=e200.values, mode="lines", name="EMA200"))
fig_det.update_layout(
    height=420, 
    margin=dict(l=10,r=10,t=10,b=10), 
    yaxis_title="KRW",
    legend=dict(
        orientation="h",
        yanchor="bottom",
        y=-0.15,
        xanchor="center",
        x=0.5
    )
)
st.plotly_chart(fig_det, use_container_width=True, config={"displayModeBar": False})

roll_max = s.cummax()
dd = (s/roll_max - 1.0)*100.0
fig_dd = go.Figure([go.Scatter(x=dd.index, y=dd.values, mode="lines", name="Drawdown(%)")])
fig_dd.update_layout(height=180, margin=dict(l=10,r=10,t=10,b=10), yaxis_title="%")
st.plotly_chart(fig_dd, use_container_width=True, config={"displayModeBar": False})

row = mom.loc[detail_sym]
badges=[]
if row["R_1M"]>0: badges.append("1M +")
if row["AboveEMA50"]>0: badges.append("EMA50 ìƒíšŒ")

# FMS ì§€í‘œ í‘œì‹œ
if "R_3M" in row and row["R_3M"]>0: badges.append("3M +")

if row["Î”FMS_1D"]>0: badges.append("ê°€ì†(1D+)")
if row["Î”FMS_5D"]>0: badges.append("ê°€ì†(5D+)")
st.markdown(" ".join([f"<span class='badge'>{b}</span>" for b in badges]) or "<span class='small'>ìƒíƒœ ë°°ì§€ ì—†ìŒ</span>", unsafe_allow_html=True)

# ------------------------------
# â‘¤ í‘œ (ì»¬ëŸ¼ ìë™ ì¬êµ¬ì„±)
# ------------------------------
st.subheader("ëª¨ë©˜í…€ í…Œì´ë¸” (ê°€ì†/ì¶”ì„¸/ìˆ˜ìµë¥ )")
disp = mom.copy()

# FMS ì»¬ëŸ¼ í‘œì‹œ
for c in ["R_1W","R_1M","R_3M","R_6M","R_YTD","AboveEMA50"]:
    if c in disp: disp[c] = (disp[c]*100).round(2)

for c in ["FMS","Î”FMS_1D","Î”FMS_5D"]:
    if c in disp: disp[c] = disp[c].round(2)

# ì»¬ëŸ¼ ìë™ ì¬êµ¬ì„±: FMS ì „ëµì— ë§ì¶° ë™ì  ì»¬ëŸ¼ ìˆœì„œ ìƒì„±
def generate_dynamic_column_order(fms_formula, available_columns):
    """
    FMS ì „ëµì— ë§ì¶° ë™ì  ì»¬ëŸ¼ ìˆœì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        fms_formula (str): FMS ê³µì‹ ë¬¸ìì—´
        available_columns (list): ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ ëª©ë¡
    
    Returns:
        list: ì¬êµ¬ì„±ëœ ì»¬ëŸ¼ ìˆœì„œ
    """
    
    # 1. Symbol ì»¬ëŸ¼ (ê°€ì¥ ì™¼ìª½)
    column_order = []
    if 'Symbol' in available_columns:
        column_order.append('Symbol')
    
    # 2. FMS ì»¬ëŸ¼ (ë‘ ë²ˆì§¸)
    if 'FMS' in available_columns:
        column_order.append('FMS')
    
    # 3. FMS ê³µì‹ì—ì„œ ì‚¬ìš©ëœ ë³€ìˆ˜ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì¶”ì¶œ
    fms_variables = []
    
    # ê³µì‹ì—ì„œ ë³€ìˆ˜ëª… ì¶”ì¶œ (ì •ê·œì‹ ì‚¬ìš©)
    # ì˜ˆ: "0.4 * Z('1Mìˆ˜ìµë¥ ') + 0.3 * Z('3Mìˆ˜ìµë¥ ')" -> ['1Mìˆ˜ìµë¥ ', '3Mìˆ˜ìµë¥ ']
    variable_pattern = r"Z\('([^']+)'\)"
    matches = re.findall(variable_pattern, fms_formula)
    
    # ë³€ìˆ˜ëª…ì„ ì‹¤ì œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë§¤í•‘
    variable_mapping = {
        '1Mìˆ˜ìµë¥ ': 'R_1M',
        '3Mìˆ˜ìµë¥ ': 'R_3M', 
        'EMA50ìƒëŒ€ìœ„ì¹˜': 'AboveEMA50',
        '20ì¼ë³€ë™ì„±': 'Vol20(ann)'
    }
    
    for var_name in matches:
        if var_name in variable_mapping:
            col_name = variable_mapping[var_name]
            if col_name in available_columns and col_name not in column_order:
                fms_variables.append(col_name)
    
    # FMS ë³€ìˆ˜ë“¤ì„ ê³µì‹ì— ë‚˜íƒ€ë‚œ ìˆœì„œëŒ€ë¡œ ì¶”ê°€
    column_order.extend(fms_variables)
    
    # 4. ë‚˜ë¨¸ì§€ ë³´ì¡° ë³€ìˆ˜ë“¤ ì¶”ê°€
    remaining_columns = [col for col in available_columns if col not in column_order]
    
    # ë³´ì¡° ë³€ìˆ˜ë“¤ì„ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì •ë ¬
    priority_order = ['Î”FMS_1D', 'Î”FMS_5D', 'R_1W', 'R_6M', 'R_YTD']
    prioritized_remaining = []
    for priority_col in priority_order:
        if priority_col in remaining_columns:
            prioritized_remaining.append(priority_col)
            remaining_columns.remove(priority_col)
    
    # ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ë“¤ì„ ì•ŒíŒŒë²³ ìˆœìœ¼ë¡œ ì •ë ¬
    remaining_columns.sort()
    
    column_order.extend(prioritized_remaining)
    column_order.extend(remaining_columns)
    
    return column_order

# í˜„ì¬ FMS ì „ëµì˜ ê³µì‹ ê°€ì ¸ì˜¤ê¸°
current_fms_formula = FMS_FORMULA

# ë™ì  ì»¬ëŸ¼ ìˆœì„œ ìƒì„±
dynamic_column_order = generate_dynamic_column_order(current_fms_formula, list(disp.columns))

# ì»¬ëŸ¼ ìˆœì„œ ì ìš© (ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ)
final_column_order = [col for col in dynamic_column_order if col in disp.columns]

# ë°ì´í„°í”„ë ˆì„ ì¬êµ¬ì„±
disp_reordered = disp[final_column_order]

# ì •ë ¬ ì ìš©
disp_reordered = disp_reordered.sort_values(rank_col if rank_col in disp_reordered.columns else "FMS", ascending=False)

st.dataframe(disp_reordered, use_container_width=True)

# ------------------------------
# â‘¥ ë””ë²„ê·¸/ì§„ë‹¨
# ------------------------------
with st.expander("ë””ë²„ê·¸ ë¡œê·¸ / ì§„ë‹¨ (ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥)"):
    last_row = prices_krw.iloc[-1]
    usa_cols = [c for c in prices_krw.columns if classify(c)=="USA"]
    kor_cols = [c for c in prices_krw.columns if classify(c)=="KOR"]
    jpn_cols = [c for c in prices_krw.columns if classify(c)=="JPN"]
    diag = {
        "last_date": str(prices_krw.index[-1].date()),
        "cols_total": prices_krw.shape[1],
        "last_notna_total": int(last_row.notna().sum()),
        "last_notna_USA": int(last_row[usa_cols].notna().sum()),
        "last_notna_KOR": int(last_row[kor_cols].notna().sum()),
        "last_notna_JPN": int(last_row[jpn_cols].notna().sum()),
        "env_CURL_CFFI_DISABLE_CACHE": os.environ.get("CURL_CFFI_DISABLE_CACHE")
    }
    st.json(diag)
    st.text_area("LOG", value="\n".join(st.session_state["LOG"][-400:]), height=200)
