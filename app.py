# app.py
# -*- coding: utf-8 -*-
# KRW Momentum Radar - v2.9
# 
# ì£¼ìš” ê¸°ëŠ¥:
# - FMS(Fast Momentum Score) ê¸°ë°˜ ëª¨ë©˜í…€ ë¶„ì„
# - ë‹¤êµ­ê°€ ì‹œì¥ í†µí•© ë¶„ì„ (ë¯¸êµ­, í•œêµ­, ì¼ë³¸)
# - ìˆ˜ìµë¥ -ë³€ë™ì„± ì´ë™ë§µ (ì •ì /ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œ)
# - ì‹¤ì‹œê°„ ë°ì´í„° ì—…ë°ì´íŠ¸ ë° ì‹œê°í™”
# - ë™ì  ê´€ì‹¬ì¢…ëª© ê´€ë¦¬ ë° ì‹ ê·œ ì¢…ëª© íƒìƒ‰ ì—”ì§„
#
# v2.9 ê°œì„ ì‚¬í•­:
# - ì§„ì •í•œ ì „ì²´ ì‹œì¥ ìŠ¤ìº” (Finviz.com ê¸°ë°˜)
# - 2ë‹¨ê³„ ì¶”ì§„ ë¡œì¼“ ë°©ì‹ (ì‚¬ì „ í•„í„°ë§ + ì˜¨ë””ë§¨ë“œ FMS ìŠ¤ìº”)
# - ìœ ë‹ˆë²„ìŠ¤ ìŠ¤í¬ë¦¬ë‹ ìŠ¤í¬ë¦½íŠ¸ (update_universe.py)
# - ë™ì  ìŠ¤í¬ë¦¬ë‹ (8,000+ ì¢…ëª©ì—ì„œ ìœ ë§ì£¼ ë°œêµ´)

import os
os.environ.setdefault("CURL_CFFI_DISABLE_CACHE", "1")  # curl_cffi sqlite ìºì‹œ ë¹„í™œì„±í™”

import warnings
from datetime import datetime, timedelta
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import pytz
import streamlit as st
import yfinance as yf
from watchlist_utils import load_watchlist, save_watchlist, add_to_watchlist, remove_from_watchlist

warnings.filterwarnings("ignore", category=ResourceWarning)
KST = pytz.timezone("Asia/Seoul")

# ------------------------------
# ê¸°ë³¸ ìœ ë‹ˆë²„ìŠ¤ (ê´€ì‹¬ì¢…ëª© ì´ˆê¸°í™”ìš©)
# ------------------------------
DEFAULT_USD_SYMBOLS = [
    'JEPI','IAU','JEPQ','VOO','NLY','PAVE','ITA','INDA','MCHI','EWG','GREK','GOOGL',
    'URA','GDX','ENFR','MDST','VNM','FXU','SPY','DIA','QQQ','EWQ','EWU','EWJ','EWH',
    'EWA','EWZ','EIDO','TUR','VT','VEA','VWO','BND','BNDX','GLD','SLV','DBC','CPER',
    'VNQ','VNQI','DBA','CORN','WEAT','USO','UNG','QUAL','VLUE','MTUM','USMV','IJR',
    'VB','TIP','XLK','XLF','XLV','SOXX','EWC','EWT','EPOL','EWW','BOTZ','ICLN','IBB',
    'QYLD','XYLD','REM','MORT','AGNC','TLTW','ULTY','BIZD','BKLN','SRLN','FLOT',
    'NOBL','SCHD','KSA','EZA','EDEN','JETS','SRVR','REMX','UUP','IVOL','PFIX','AOR',
    'NVDA'
]
DEFAULT_KRW_SYMBOLS = [
    '005930.KS','102110.KS','474220.KS','441680.KS','289480.KS',
    '166400.KS','276970.KS','482730.KS','486290.KS','480020.KS'
]
DEFAULT_JPY_SYMBOLS = ['2563.T']



def classify(sym):
    # symì´ floatì´ë‚˜ ë‹¤ë¥¸ íƒ€ì…ì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ strë¡œ ë³€í™˜
    sym_str = str(sym)
    if sym_str.endswith(".KS"): return "KOR"
    if sym_str.endswith(".T"):  return "JPN"
    return "USA"

# ------------------------------
# í˜ì´ì§€/ìŠ¤íƒ€ì¼
# ------------------------------
st.set_page_config(page_title="KRW Momentum Radar v2.9", page_icon="âš¡", layout="wide")
st.markdown("""
<style>
.block-container {padding-top: 0.8rem;}
.badge {display:inline-block; padding:2px 8px; border-radius:999px; font-size:0.75rem; margin-right:6px; background:#f1f3f5;}
.kpi {border:1px solid #eee; border-radius:16px; padding:10px 14px; box-shadow:0 1px 6px rgba(0,0,0,0.06);}
.small {font-size:0.8rem; color:#555;}
</style>
""", unsafe_allow_html=True)

# ------------------------------
# ê´€ì‹¬ì¢…ëª© ì´ˆê¸°í™” (UIë³´ë‹¤ ë¨¼ì € ì‹¤í–‰)
# ------------------------------
if 'watchlist' not in st.session_state:
    default_symbols = DEFAULT_USD_SYMBOLS + DEFAULT_KRW_SYMBOLS + DEFAULT_JPY_SYMBOLS
    st.session_state.watchlist = load_watchlist(default_symbols)
    # ê´€ì‹¬ì¢…ëª© ì´ˆê¸°í™” ì™„ë£Œ

# í˜„ì¬ ê´€ì‹¬ì¢…ëª©ì„ ê¸°ì¡´ ë³€ìˆ˜ëª…ìœ¼ë¡œ ë§¤í•‘ (í•˜ìœ„ í˜¸í™˜ì„±)
USD_SYMBOLS = [str(s) for s in st.session_state.watchlist if classify(s) == "USA"]
KRW_SYMBOLS = [str(s) for s in st.session_state.watchlist if classify(s) == "KOR"]
JPY_SYMBOLS = [str(s) for s in st.session_state.watchlist if classify(s) == "JPN"]

# ------------------------------
# ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ------------------------------
def _extract_adj_close(df_chunk, tickers):
    if df_chunk is None or len(df_chunk)==0:
        return pd.DataFrame(columns=tickers, dtype=float)
    if isinstance(df_chunk.columns, pd.MultiIndex):
        if 'Adj Close' in df_chunk.columns.get_level_values(0):
            adj = df_chunk['Adj Close'].copy()
        elif 'Close' in df_chunk.columns.get_level_values(0):
            adj = df_chunk['Close'].copy()
        else:
            parts=[]
            for t in tickers:
                try:
                    if ('Adj Close', t) in df_chunk.columns:
                        s = df_chunk[('Adj Close', t)].rename(t)
                    elif ('Close', t) in df_chunk.columns:
                        s = df_chunk[('Close', t)].rename(t)
                    else:
                        s = pd.Series(dtype=float, name=t)
                except Exception:
                    s = pd.Series(dtype=float, name=t)
                parts.append(s)
            adj = pd.concat(parts, axis=1)
    else:
        cols = df_chunk.columns
        if 'Adj Close' in cols:
            adj = df_chunk[['Adj Close']].copy(); adj.columns = tickers[:1]
        elif 'Close' in cols:
            adj = df_chunk[['Close']].copy(); adj.columns = tickers[:1]
        else:
            adj = df_chunk.copy()
            keep = [c for c in adj.columns if c in tickers]
            adj = adj[keep] if keep else pd.DataFrame(columns=tickers, dtype=float)
    adj = adj.loc[:, ~adj.columns.duplicated()]
    return adj

@st.cache_data(ttl=60*60*6, show_spinner=False)
def download_prices(tickers, period_="2y", interval="1d", chunk=25):
    frames=[]; missing=[]
    tickers = list(dict.fromkeys(tickers))
    for i in range(0, len(tickers), chunk):
        part = tickers[i:i+chunk]
        try:
            raw = yf.download(part, period=period_, interval=interval, auto_adjust=False,
                              group_by='column', progress=False, threads=True)
            adj = _extract_adj_close(raw, part)
        except Exception as e:
            log(f"ERROR download chunk: {part[:3]}... -> {e}")
            adj = pd.DataFrame()
        if adj.empty or adj.isna().all().all():
            pframes=[]
            for t in part:
                try:
                    r = yf.download(t, period=period_, interval=interval, auto_adjust=False,
                                    group_by='column', progress=False, threads=False)
                    a = _extract_adj_close(r, [t])
                    pframes.append(a)
                except Exception as e:
                    log(f"ERROR download single: {t} -> {e}")
                    missing.append(t)
            if pframes:
                frames.append(pd.concat(pframes, axis=1))
        else:
            frames.append(adj)
    if not frames:
        return pd.DataFrame(), missing
    out = pd.concat(frames, axis=1)
    out = out.loc[:, ~out.columns.duplicated()].sort_index()
    all_nan = out.columns[out.isna().all()]
    if len(all_nan):
        log(f"DROP all-NaN columns: {list(all_nan)[:5]}{' ...' if len(all_nan)>5 else ''}")
    out = out.drop(columns=all_nan)
    return out, sorted(list(dict.fromkeys(list(missing)+list(all_nan))))

@st.cache_data(ttl=60*60*6, show_spinner=False)
def download_fx(period_="2y", interval="1d"):
    fx_krw, miss1 = download_prices(["KRW=X"], period_, interval)
    fx_jpy, miss2 = download_prices(["JPY=X"], period_, interval)
    usdkrw = fx_krw.iloc[:,0].rename("USDKRW") if not fx_krw.empty else pd.Series(dtype=float, name="USDKRW")
    usdjpy = fx_jpy.iloc[:,0].rename("USDJPY") if not fx_jpy.empty else pd.Series(dtype=float, name="USDJPY")
    if not usdkrw.empty and not usdjpy.empty:
        start=min(usdkrw.index.min(), usdjpy.index.min())
        end=max(usdkrw.index.max(), usdjpy.index.max())
        idx = pd.date_range(start, end, freq='B')
        usdkrw = usdkrw.reindex(idx).ffill()
        usdjpy = usdjpy.reindex(idx).ffill()
        jpykrw = (usdkrw/usdjpy).rename("JPYKRW")
    else:
        jpykrw = pd.Series(dtype=float, name="JPYKRW")
    return usdkrw, usdjpy, jpykrw, (miss1+miss2)

def harmonize_calendar(df, coverage=0.9):
    if df.empty: return df
    idx = pd.date_range(df.index.min(), df.index.max(), freq='B')
    df = df.reindex(idx).ffill()
    # coverage ì²´í¬
    valid_ratio = df.count().div(len(df))
    keep_cols = valid_ratio[valid_ratio >= coverage].index
    return df[keep_cols] if len(keep_cols) > 0 else pd.DataFrame()

def align_bday_ffill(df):
    if df is None or len(df)==0: return df
    idx = pd.date_range(df.index.min(), df.index.max(), freq='B')
    return df.reindex(idx).ffill()

# ------------------------------
# ë¡œê¹… í•¨ìˆ˜
# ------------------------------
if "LOG" not in st.session_state:
    st.session_state["LOG"] = []
def log(msg):
    ts = datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S")
    st.session_state["LOG"].append(f"[{ts}] {msg}")

# ------------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ------------------------------
def warn_to_log(fn, *args, **kwargs):
    with warnings.catch_warnings(record=True) as wlist:
        result = fn(*args, **kwargs)
        for w in wlist:
            st.session_state["LOG"].append(f"WARNING: {w.category.__name__}: {str(w.message)}")
        return result

# ------------------------------
# ì§€í‘œ/ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜ë“¤
# ------------------------------
def ema(s, span): return s.ewm(span=span, adjust=False).mean()

def returns_pct(df, n):
    if df.shape[0] <= n: 
        return pd.Series(index=df.columns, dtype=float)
    dff = df.ffill()
    r = warn_to_log(dff.pct_change, periods=n, fill_method=None).iloc[-1]
    return r

def ytd_return(df):
    if df.empty: return pd.Series(dtype=float)
    dff = df.ffill()
    last = dff.index[-1]
    y0 = pd.Timestamp(datetime(last.year, 1, 1))
    start_idx = dff.index.get_indexer([y0], method='nearest')[0]
    return dff.iloc[-1] / dff.iloc[start_idx] - 1.0

def log_slope_annualized(s, window=30):
    s = s.dropna().tail(window)
    if len(s) < 3: return np.nan
    y = np.log(s.values); x = np.arange(len(y))
    slope = np.polyfit(x, y, 1)[0]
    return slope * 252.0

def last_vol_annualized(df, window=20):
    rets = warn_to_log(df.ffill().pct_change, fill_method=None).dropna()
    if rets.empty: return pd.Series(index=df.columns, dtype=float)
    vol = rets.rolling(window).std().iloc[-1] * np.sqrt(252.0)
    return vol

def rolling_max(s, window): return s.rolling(window).max()

def _mom_snapshot(prices_krw):
    r_1m = returns_pct(prices_krw, 21)
    slope30 = {}
    above_ema50 = {}
    breakout120 = {}
    for c in prices_krw.columns:
        s = prices_krw[c].dropna()
        if s.empty:
            slope30[c]=np.nan; above_ema50[c]=np.nan; breakout120[c]=np.nan; continue
        slope30[c] = log_slope_annualized(s, 30)
        e50 = ema(s, 50)
        above_ema50[c] = (s.iloc[-1]/e50.iloc[-1]-1.0) if e50.iloc[-1] > 0 else np.nan
        hi120 = rolling_max(s, 120).iloc[-1]
        breakout120[c] = (s.iloc[-1]/hi120-1.0) if hi120 and hi120>0 else np.nan
    slope30 = pd.Series(slope30, name="Slope30(ann)")
    above_ema50 = pd.Series(above_ema50, name="AboveEMA50")
    breakout120 = pd.Series(breakout120, name="Breakout120")
    vol20 = last_vol_annualized(prices_krw, 20).rename("Vol20(ann)")

    def z(x):
        x = x.astype(float)
        m = np.nanmean(x); sd = np.nanstd(x)
        return (x-m)/sd if sd and not np.isnan(sd) else x*0.0

    FMS = (0.5*z(r_1m) + 0.3*z(slope30) + 0.2*z(above_ema50) + 0.1*z(breakout120)
           - 0.1*z(vol20.fillna(vol20.median())))
    snap = pd.concat([r_1m.rename("R_1M"), above_ema50, breakout120, slope30, vol20, FMS.rename("FMS")], axis=1)
    return snap

def momentum_now_and_delta(prices_krw):
    now = _mom_snapshot(prices_krw)
    d1 = _mom_snapshot(prices_krw.iloc[:-1]) if len(prices_krw)>1 else now*np.nan
    d5 = _mom_snapshot(prices_krw.iloc[:-5]) if len(prices_krw)>5 else now*np.nan
    df = now.copy()
    df["Î”FMS_1D"] = df["FMS"] - d1["FMS"]
    df["Î”FMS_5D"] = df["FMS"] - d5["FMS"]
    df["R_1W"] = returns_pct(prices_krw, 5)
    df["R_3M"] = returns_pct(prices_krw, 63)
    df["R_6M"] = returns_pct(prices_krw, 126)
    df["R_YTD"] = ytd_return(prices_krw)
    return df.sort_values("FMS", ascending=False)

# ------------------------------
# ì‹ ê·œ ì¢…ëª© íƒìƒ‰ ì—”ì§„ í•¨ìˆ˜ë“¤
# ------------------------------
@st.cache_data(ttl=60*60*2, show_spinner=False)  # 2ì‹œê°„ ìºì‹œ
def calculate_fms_for_batch(symbols_batch, period_="1y", interval="1d"):
    """
    ë°°ì¹˜ ë‹¨ìœ„ë¡œ FMSë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        symbols_batch (list): ê³„ì‚°í•  ì‹¬ë³¼ ëª©ë¡
        period_ (str): ë°ì´í„° ê¸°ê°„
        interval (str): ë°ì´í„° ê°„ê²©
        
    Returns:
        pd.DataFrame: FMS ê³„ì‚° ê²°ê³¼
    """
    if not symbols_batch:
        return pd.DataFrame()
    
    try:
        # ê°€ê²© ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        prices, missing = download_prices(symbols_batch, period_, interval)
        if prices.empty:
            return pd.DataFrame()
        
        # KRW í™˜ì‚°ì„ ìœ„í•œ FX ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        usd_symbols = [str(s) for s in symbols_batch if classify(s) == "USA"]
        if usd_symbols:
            usdkrw, _, _, _ = download_fx(period_, interval)
            if not usdkrw.empty:
                usdkrw_matched = usdkrw.reindex(prices.index).ffill()
                usd_prices = prices[[s for s in usd_symbols if s in prices.columns]]
                if not usd_prices.empty:
                    prices[usd_prices.columns] = usd_prices.mul(usdkrw_matched, axis=0)
        
        # JPY ì‹¬ë³¼ ì²˜ë¦¬
        jpy_symbols = [str(s) for s in symbols_batch if classify(s) == "JPN"]
        if jpy_symbols:
            _, _, jpykrw, _ = download_fx(period_, interval)
            if not jpykrw.empty:
                jpykrw_matched = jpykrw.reindex(prices.index).ffill()
                jpy_prices = prices[[s for s in jpy_symbols if s in prices.columns]]
                if not jpy_prices.empty:
                    prices[jpy_prices.columns] = jpy_prices.mul(jpykrw_matched, axis=0)
        
        # ìº˜ë¦°ë” ì •ê·œí™”
        prices_krw = harmonize_calendar(prices, coverage=0.8)
        if prices_krw.empty:
            return pd.DataFrame()
        
        # FMS ê³„ì‚°
        df = momentum_now_and_delta(prices_krw)
        return df.sort_values("FMS", ascending=False)
        
    except Exception as e:
        st.error(f"FMS ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return pd.DataFrame()

@st.cache_data(ttl=3600)  # 1ì‹œê°„ ìºì‹œí•˜ì—¬ ë°˜ë³µì ì¸ íŒŒì¼ I/O ë° ê³„ì‚° ë°©ì§€
def scan_market_for_new_opportunities():
    """
    ì‚¬ì „ ìŠ¤í¬ë¦¬ë‹ëœ ìœ ë§ì£¼ ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ì„ ì½ì–´ FMS ìŠ¤ì½”ì–´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Returns:
        tuple: (top_performers_df, message)
    """
    try:
        # ë³€ê²½ì  1: ìŠ¤í¬ë¦¬ë‹ëœ ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ ë¡œë“œ
        universe_df = pd.read_csv('screened_universe.csv')
        master_list = universe_df['Symbol'].tolist()
        
        log(f"ìŠ¤í¬ë¦¬ë‹ëœ ìœ ë‹ˆë²„ìŠ¤ ë¡œë“œ: {len(master_list)}ê°œ ì¢…ëª©")
        
    except FileNotFoundError:
        # ë³€ê²½ì  2: íŒŒì¼ì´ ì—†ì„ ê²½ìš° ì‚¬ìš©ìì—ê²Œ ì•ˆë‚´
        error_msg = "ì˜¤ë¥˜: 'screened_universe.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € `update_universe.py` ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ìœ ë§ì£¼ ëª©ë¡ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤."
        log(error_msg)
        return pd.DataFrame(), error_msg
    except Exception as e:
        error_msg = f"ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        log(error_msg)
        return pd.DataFrame(), error_msg

    # ê¸°ì¡´ ê´€ì‹¬ì¢…ëª© ì œì™¸ ë¡œì§ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
    current_watchlist = st.session_state.get('watchlist', [])
    scan_targets = [s for s in master_list if s not in current_watchlist]
    
    if not scan_targets:
        return pd.DataFrame(), "ì•Œë¦¼: í˜„ì¬ ìœ ë§ì£¼ ëª©ë¡ì˜ ëª¨ë“  ì¢…ëª©ì´ ì´ë¯¸ ê´€ì‹¬ì¢…ëª©ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."

    log(f"ì´ {len(scan_targets)}ê°œ ì‹ ê·œ ì¢…ëª©ì„ ìŠ¤ìº”í•©ë‹ˆë‹¤...")
    
    # ë°°ì¹˜ ì²˜ë¦¬ ë° FMS ê³„ì‚° ë¡œì§ì€ ê¸°ì¡´ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ í™œìš©
    batch_size = 25  # ë°°ì¹˜ ì‚¬ì´ì¦ˆëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ê±°ë‚˜ ì¡°ì • ê°€ëŠ¥
    all_results = []
    
    for i in range(0, len(scan_targets), batch_size):
        batch = scan_targets[i:i+batch_size]
        log(f"ë°°ì¹˜ {i//batch_size + 1}/{(len(scan_targets)-1)//batch_size + 1} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ ì¢…ëª©)")
        
        batch_results = calculate_fms_for_batch(batch)
        if not batch_results.empty:
            all_results.append(batch_results)

    if not all_results:
        return pd.DataFrame(), "ì•Œë¦¼: ìŠ¤ìº” ëŒ€ìƒ ì¢…ëª©ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
    # ëª¨ë“  ê²°ê³¼ í•©ì¹˜ê¸° (ì¸ë±ìŠ¤ ìœ ì§€)
    combined_results = pd.concat(all_results)
    
    # ìƒìœ„ 30ê°œ ì„ íƒ
    top_performers = combined_results.head(30)
    
    scan_message = f"âœ… {len(scan_targets)}ê°œ ìœ ë§ í›„ë³´ ì¢…ëª© ìŠ¤ìº” ì™„ë£Œ! ìƒìœ„ {len(top_performers)}ê°œ ì¢…ëª© ë°œê²¬"
    log(scan_message)
    
    return top_performers, scan_message

# ------------------------------
# ì¢Œì¸¡ ì œì–´
# ------------------------------
st.sidebar.header("âš¡ KRW Momentum Radar v2.9")

# ìì£¼ ì‚¬ìš©í•˜ëŠ” ì„¤ì • (ìƒë‹¨)
st.sidebar.subheader("âš™ï¸ ë¶„ì„ ì„¤ì •")
period = st.sidebar.selectbox("ì°¨íŠ¸ ê¸°ê°„", ["3M","6M","1Y","2Y","5Y"], index=0)
rank_by = st.sidebar.selectbox("ì •ë ¬ ê¸°ì¤€", ["Î”FMS(1D)","Î”FMS(5D)","FMS(í˜„ì¬)","1M ìˆ˜ìµë¥ "], index=2)  # ê¸°ë³¸ FMS
TOP_N = st.sidebar.slider("Top N", 5, 60, 20, step=5)
use_log_scale = st.sidebar.checkbox("ë¹„êµì°¨íŠ¸ ë¡œê·¸ ìŠ¤ì¼€ì¼", True)

# ê´€ì‹¬ì¢…ëª© ê´€ë¦¬ ì„¹ì…˜ (í•˜ë‹¨)
st.sidebar.subheader("ğŸ“‹ ê´€ì‹¬ì¢…ëª© ê´€ë¦¬")
st.sidebar.info(f"í˜„ì¬ ê´€ì‹¬ì¢…ëª©: **{len(st.session_state.watchlist)}ê°œ**")

# ì‹ ê·œ ì¢…ëª© íƒìƒ‰
with st.sidebar.expander("ğŸš€ ì‹ ê·œ ëª¨ë©˜í…€ ì¢…ëª© íƒìƒ‰", expanded=False):
    if st.button('ğŸ” ìœ ë§ì£¼ ìœ ë‹ˆë²„ìŠ¤ ìŠ¤ìº” ì‹¤í–‰', type="primary", help="ì‚¬ì „ ìŠ¤í¬ë¦¬ë‹ëœ ëª©ë¡ì—ì„œ FMS ìƒìœ„ ì¢…ëª©ì„ íƒìƒ‰í•©ë‹ˆë‹¤."):
        with st.spinner("ì „ì²´ ì‹œì¥ì„ ìŠ¤ìº” ì¤‘ì…ë‹ˆë‹¤..."):
            scan_results, scan_message = scan_market_for_new_opportunities()
            
            if not scan_results.empty:
                st.success(scan_message)
                
                # ìƒìœ„ 10ê°œë§Œ í‘œì‹œí•˜ê³  ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                top_results = scan_results.head(10)
                st.session_state['scan_results'] = top_results
            else:
                st.error("ìŠ¤ìº” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.session_state['scan_results'] = None
    
    # ìŠ¤ìº” ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
    if 'scan_results' in st.session_state and st.session_state['scan_results'] is not None:
        top_results = st.session_state['scan_results']
        st.markdown("**ğŸ“‹ ë°œê²¬ëœ ì¢…ëª©:**")
        
        for idx, (symbol, row) in enumerate(top_results.iterrows()):
            col1, col2 = st.columns([3, 1])
            with col1:
                st.write(f"**{symbol}** (FMS: {row['FMS']:.1f})")
            with col2:
                if st.button("â•", key=f"add_{symbol}"):
                    if symbol not in st.session_state.watchlist:
                        st.session_state.watchlist = add_to_watchlist(st.session_state.watchlist, [symbol])
                        # ìŠ¤ìº” ê²°ê³¼ì—ì„œë„ ì œê±°
                        if 'scan_results' in st.session_state:
                            st.session_state['scan_results'] = None
                        # ìºì‹œ ë¬´íš¨í™” ë° í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                        st.cache_data.clear()
                        st.rerun()
                    else:
                        st.warning(f"'{symbol}'ëŠ” ì´ë¯¸ ê´€ì‹¬ì¢…ëª©ì— ìˆìŠµë‹ˆë‹¤.")
    
    # ë³€ê²½ì  2: ì•ˆë‚´ ë¬¸êµ¬ ì¶”ê°€
    st.caption("ğŸ’¡ ë§¤ì¼ ì—…ë°ì´íŠ¸ë˜ëŠ” ìœ ë§ì£¼ ëª©ë¡(1ê°œì›” ìˆ˜ìµë¥  > 0%, ê±°ë˜ëŸ‰ > 200k ë“±) ë‚´ì—ì„œ FMS ìƒìœ„ ì¢…ëª©ì„ íƒìƒ‰í•©ë‹ˆë‹¤.")

# ê´€ì‹¬ì¢…ëª© ì¬í‰ê°€
with st.sidebar.expander("ğŸ”„ ê´€ì‹¬ì¢…ëª© ì¬í‰ê°€", expanded=False):
    if st.button("ğŸ“Š FMS ê¸°ë°˜ ì¬í‰ê°€ ì‹¤í–‰"):
        with st.spinner("ê´€ì‹¬ì¢…ëª©ì„ ì¬í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):
            # ê´€ì‹¬ì¢…ëª© FMS ê³„ì‚°
            watchlist_fms = calculate_fms_for_batch(st.session_state.watchlist, period_="1y")
            
            if not watchlist_fms.empty:
                # FMS í•˜ìœ„ 25% ì‹ë³„
                fms_25th = watchlist_fms['FMS'].quantile(0.25)
                stale_candidates = watchlist_fms[watchlist_fms['FMS'] < fms_25th].sort_values('FMS')
                
                if not stale_candidates.empty:
                    st.warning(f"FMS í•˜ìœ„ 25% ì¢…ëª© ({len(stale_candidates)}ê°œ) ë°œê²¬")
                    
                    # ì„¸ì…˜ ìƒíƒœì— ì¬í‰ê°€ ê²°ê³¼ ì €ì¥
                    st.session_state['reassessment_results'] = stale_candidates
                else:
                    st.success("ëª¨ë“  ê´€ì‹¬ì¢…ëª©ì´ ì–‘í˜¸í•œ ìƒíƒœì…ë‹ˆë‹¤!")
                    st.session_state['reassessment_results'] = None
            else:
                st.error("ì¬í‰ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.session_state['reassessment_results'] = None
    
    # ì¬í‰ê°€ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
    if 'reassessment_results' in st.session_state and st.session_state['reassessment_results'] is not None:
        stale_candidates = st.session_state['reassessment_results']
        st.markdown("**ğŸ“‹ ì œê±° ì œì•ˆ ì¢…ëª©:**")
        
        for symbol in stale_candidates.index[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
            col1, col2 = st.columns([3, 1])
            with col1:
                st.write(f"**{symbol}** (FMS: {stale_candidates.loc[symbol, 'FMS']:.1f})")
            with col2:
                if st.button("ğŸ—‘ï¸", key=f"remove_{symbol}"):
                    st.session_state.watchlist = remove_from_watchlist(st.session_state.watchlist, [symbol])
                    # ì¬í‰ê°€ ê²°ê³¼ì—ì„œë„ ì œê±°
                    if 'reassessment_results' in st.session_state:
                        st.session_state['reassessment_results'] = None
                    # ìºì‹œ ë¬´íš¨í™” ë° í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                    st.cache_data.clear()
                    st.rerun()

# ìˆ˜ë™ í‹°ì»¤ ì¶”ê°€/ì‚­ì œ
st.sidebar.markdown("**ìˆ˜ë™ ê´€ë¦¬**")

# í‹°ì»¤ ì¶”ê°€
new_ticker = st.sidebar.text_input("í‹°ì»¤ ì¶”ê°€ (ì˜ˆ: AAPL)", "").upper().strip()
if st.sidebar.button("â• ì¶”ê°€"):
    if new_ticker and new_ticker not in st.session_state.watchlist:
        st.session_state.watchlist = add_to_watchlist(st.session_state.watchlist, [new_ticker])
        # ìºì‹œ ë¬´íš¨í™” ë° í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        st.cache_data.clear()
        st.rerun()
    elif new_ticker in st.session_state.watchlist:
        st.sidebar.warning(f"'{new_ticker}'ëŠ” ì´ë¯¸ ê´€ì‹¬ì¢…ëª©ì— ìˆìŠµë‹ˆë‹¤.")
    else:
        st.sidebar.error("ìœ íš¨í•œ í‹°ì»¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# í‹°ì»¤ ì‚­ì œ
if st.session_state.watchlist:
    tickers_to_remove = st.sidebar.multiselect(
        "ì‚­ì œí•  í‹°ì»¤ ì„ íƒ",
        options=st.session_state.watchlist,
        key="remove_tickers"
    )
    if st.sidebar.button("ğŸ—‘ï¸ ì„ íƒ ì‚­ì œ"):
        if tickers_to_remove:
            st.session_state.watchlist = remove_from_watchlist(st.session_state.watchlist, tickers_to_remove)
            # ìºì‹œ ë¬´íš¨í™” ë° í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
            st.cache_data.clear()
            st.rerun()
        else:
            st.sidebar.error("ì‚­ì œí•  ì¢…ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

with st.sidebar.expander("ğŸ”§ ë„êµ¬ ë° ë„ì›€ë§", expanded=False):
    # FMS ì„¤ëª…
    st.markdown("**ğŸ“Š FMS (Fast Momentum Score)**")
    st.markdown("""
    ë‹¤ì°¨ì› ëª¨ë©˜í…€ ì§€í‘œ ì¢…í•© ì ìˆ˜:
    
    **FMS = 0.5Ã—Z(1Mìˆ˜ìµë¥ ) + 0.3Ã—Z(30ì¼ê¸°ìš¸ê¸°) + 0.2Ã—Z(EMA50ìƒëŒ€ìœ„ì¹˜) + 0.1Ã—Z(120ì¼ëŒíŒŒ) - 0.1Ã—Z(20ì¼ë³€ë™ì„±)**
    
    â€¢ **Z()**: Z-score ì •ê·œí™” (í‰ê·  0, í‘œì¤€í¸ì°¨ 1)  
    â€¢ **ê°€ì¤‘ì¹˜**: ìˆ˜ìµë¥ (50%) > ê¸°ìš¸ê¸°(30%) > EMA50ìœ„ì¹˜(20%) > ëŒíŒŒ(10%) > ë³€ë™ì„±(-10%)  
    â€¢ **ë†’ì€ FMS**: ê°•í•œ ìƒìŠ¹ ëª¨ë©˜í…€ê³¼ ë‚®ì€ ë³€ë™ì„±
    """)
    
    st.markdown("---")
    
    # ë„êµ¬ ë²„íŠ¼ë“¤
    if st.button("ğŸ—‚ï¸ ë°ì´í„° ìºì‹œ ì´ˆê¸°í™”"):
        st.cache_data.clear()
        st.success("ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ â†’ ìƒë‹¨ Rerun í´ë¦­")
    
    if st.button("ğŸ”„ ê´€ì‹¬ì¢…ëª© ì´ˆê¸°í™”"):
        default_symbols = DEFAULT_USD_SYMBOLS + DEFAULT_KRW_SYMBOLS + DEFAULT_JPY_SYMBOLS
        st.session_state.watchlist = default_symbols
        save_watchlist(default_symbols)
        st.success("ê´€ì‹¬ì¢…ëª©ì´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.rerun()



@st.cache_data(ttl=60*60*6, show_spinner=True)
def build_prices_krw(period_key="6M", watchlist_symbols=None):
    period_map = {"3M":"6mo","6M":"1y","1Y":"2y","2Y":"5y","5Y":"10y"}
    yf_period = period_map.get(period_key, "1y")
    interval = "1d"

    # ê´€ì‹¬ì¢…ëª© ëª©ë¡ì„ ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ì•„ì„œ ìºì‹œ í‚¤ì— í¬í•¨
    if watchlist_symbols is None:
        watchlist_symbols = st.session_state.watchlist

    # í˜„ì¬ ê´€ì‹¬ì¢…ëª©ì—ì„œ êµ­ê°€ë³„ë¡œ ë¶„ë¥˜
    usd_symbols = [str(s) for s in watchlist_symbols if classify(s) == "USA"]
    krw_symbols = [str(s) for s in watchlist_symbols if classify(s) == "KOR"]
    jpy_symbols = [str(s) for s in watchlist_symbols if classify(s) == "JPN"]

    usdkrw, usdjpy, jpykrw, fx_missing = download_fx(yf_period, interval)
    usd_df, miss_us = download_prices(usd_symbols, yf_period, interval)
    krw_df, miss_kr = download_prices(krw_symbols, yf_period, interval)
    jpy_df, miss_jp = download_prices(jpy_symbols, yf_period, interval)

    usd_df = align_bday_ffill(usd_df)
    krw_df = align_bday_ffill(krw_df)
    jpy_df = align_bday_ffill(jpy_df)
    usdkrw = align_bday_ffill(usdkrw.to_frame()).iloc[:,0] if not usdkrw.empty else usdkrw
    jpykrw = align_bday_ffill(jpykrw.to_frame()).iloc[:,0] if not jpykrw.empty else jpykrw

    frames=[]
    if not usd_df.empty and not usdkrw.empty:
        usdkrw_matched = usdkrw.reindex(usd_df.index).ffill()
        frames.append(usd_df.mul(usdkrw_matched, axis=0))
    if not krw_df.empty:
        frames.append(krw_df)
    if not jpy_df.empty and not jpykrw.empty:
        jpykrw_matched = jpykrw.reindex(jpy_df.index).ffill()
        frames.append(jpy_df.mul(jpykrw_matched, axis=0))

    if not frames:
        return pd.DataFrame(), {"fx_missing": fx_missing, "price_missing": miss_us+miss_kr+miss_jp}

    prices_krw = pd.concat(frames, axis=1).sort_index()
    prices_krw = prices_krw.loc[:, ~prices_krw.columns.duplicated()]
    prices_krw = harmonize_calendar(prices_krw, coverage=0.9)

    miss_dict = {
        "fx_missing": fx_missing,
        "price_missing": sorted(list(set(miss_us+miss_kr+miss_jp)))
    }
    last_row = prices_krw.iloc[-1]
    usa_cols = [c for c in prices_krw.columns if classify(c)=="USA"]
    na_usa = last_row[usa_cols].isna().sum()
    log(f"Final DF shape: {prices_krw.shape}; last row USA NaNs: {na_usa}/{len(usa_cols)}")
    return prices_krw, miss_dict

# ------------------------------
# ì´ë¦„ ìºì‹œ
# ------------------------------
@st.cache_data(ttl=60*60*24, show_spinner=False)
def fetch_long_names(symbols):
    out = {}
    for s in symbols:
        name = None
        try:
            info = yf.Ticker(s).get_info()
            name = info.get("longName") or info.get("shortName")
        except Exception as e:
            log(f"INFO name fetch fail: {s} -> {e}")
        out[s] = name if name else s
    return out





# ------------------------------
# ë°ì´í„° ë¡œë“œ ë° ì´ë¦„
# ------------------------------
with st.spinner("ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
    prices_krw, miss = build_prices_krw(period, st.session_state.watchlist)
if prices_krw.empty:
    st.error("ê°€ê²© ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

with st.spinner("ì¢…ëª©ëª…(í’€ë„¤ì„) ë¡œë”© ì¤‘â€¦(ìµœì´ˆ 1íšŒë§Œ ë‹¤ì†Œ ì§€ì—°)"):
    NAME_MAP = fetch_long_names(list(prices_krw.columns))

def display_name(sym):
    nm = NAME_MAP.get(sym, sym)
    return f"{nm} ({sym})" if nm and nm != sym else sym
def only_name(sym):
    nm = NAME_MAP.get(sym, sym)
    return nm if nm else sym

st.title("âš¡ KRW Momentum Radar v2.9")



# ------------------------------
# ëª¨ë©˜í…€/ê°€ì† ê³„ì‚°
# ------------------------------
with st.spinner("ëª¨ë©˜í…€/ê°€ì† ê³„ì‚° ì¤‘â€¦"):
    mom = momentum_now_and_delta(prices_krw)
rank_col = {"Î”FMS(1D)":"Î”FMS_1D","Î”FMS(5D)":"Î”FMS_5D","FMS(í˜„ì¬)":"FMS","1M ìˆ˜ìµë¥ ":"R_1M"}[rank_by]
mom_ranked = mom.sort_values(rank_col, ascending=False)

# ------------------------------
# â‘  ê°€ì† ë³´ë“œ
# ------------------------------
st.subheader("ê°€ì† ë³´ë“œ")
topN = mom_ranked.head(TOP_N)
bar = go.Figure([go.Bar(
    x=topN.index, y=topN[rank_col],
    customdata=np.array([only_name(s) for s in topN.index]),
    hovertemplate="%{customdata} (%{x})<br>"+rank_col+": %{y:.2f}<extra></extra>"
)])
bar.update_layout(height=320, margin=dict(l=10,r=10,t=10,b=10), xaxis_tickangle=-45, yaxis_title=rank_col)
st.plotly_chart(bar, use_container_width=True, config={"displayModeBar": False})

# ------------------------------
# â‘¡ ë¹„êµ ì°¨íŠ¸ â€” Top N
# ------------------------------
st.subheader(f"ë¹„êµ ì°¨íŠ¸ â€” ìƒìœ„ {TOP_N} (ê¸°ì¤€: {rank_col})")
sel_syms = list(topN.index)
df_view = prices_krw[sel_syms].dropna(how="all")
win_map={"3M":63,"6M":126,"1Y":252,"2Y":504,"5Y":1260}
win = win_map.get(period,126)
if df_view.shape[0]>win: df_view = df_view.iloc[-win:]
df_base = df_view/df_view.iloc[0]*100.0
fig_comp = go.Figure()
for c in df_base.columns:
    nm_only = only_name(c)
    fig_comp.add_trace(go.Scatter(
        x=df_base.index, y=df_base[c], mode="lines", name=c,
        customdata=np.array([nm_only]*len(df_base)),
        hovertemplate="%{customdata} ("+c+")<br>%{x|%Y-%m-%d}<br>Index:%{y:.2f}<extra></extra>"
    ))
fig_comp.update_layout(
    height=420, margin=dict(l=10,r=10,t=10,b=10),
    yaxis=dict(type="log" if use_log_scale else "linear", title="Rebased 100"),
    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
)
st.plotly_chart(fig_comp, use_container_width=True)

# ==============================
# â‘¢ ìˆ˜ìµë¥ â€“ë³€ë™ì„± ì´ë™ë§µ
# ==============================
st.subheader("ìˆ˜ìµë¥ â€“ë³€ë™ì„± ì´ë™ë§µ (ìµœê·¼ ìƒíƒœ â†’ ì–´ë””ì„œ ì™”ëŠ”ê°€)")

cc1, cc2, cc3, cc4 = st.columns([1.2,1.2,1.2,1.6])
with cc1:
    rv_window = st.selectbox("ìˆ˜ìµë¥ /ë³€ë™ì„± ì°½(ê±°ë˜ì¼)", [21, 42, 63], index=0, help="ì—°ìœ¨í™”: 252 ê¸°ì¤€")
with cc2:
    plot_n = st.selectbox("í‘œì‹œ ì¢…ëª© ìˆ˜", [10, 15, 20, 25, 30], index=2, help="ìƒìœ„ ë­í‚¹ ê¸°ì¤€ìœ¼ë¡œ ì œí•œí•´ ê³¼ë°€ë„ ì™„í™”")
with cc4:
    motion_mode = st.selectbox("ëª¨ì…˜(ì• ë‹ˆë©”ì´ì…˜)", ["ë„ê¸°", "ìµœê·¼ 10ì¼", "ìµœê·¼ 20ì¼"], index=0,
                               help="í”„ë ˆì„ë§ˆë‹¤ í˜„ì¬ ìœ„ì¹˜ì™€ ê¼¬ë¦¬ë¥¼ ë™ì‹œì— ê°±ì‹ ")
with cc3:
    # ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œê°€ ì„ íƒë˜ë©´ ê¼¬ë¦¬ ê¸¸ì´ë¥¼ 5ë¡œ ìë™ ì„¤ì •
    if motion_mode != "ë„ê¸°":
        tail_days = st.selectbox("ê¼¬ë¦¬ ê¸¸ì´(ìµœê·¼ nì¼ ê²½ë¡œ)", [0, 3, 5, 10], index=2, help="ì˜¤ëŠ˜ ê¸°ì¤€ ê³¼ê±° nê±°ë˜ì¼ì˜ ì´ë™ ê²½ë¡œë¥¼ ì ì„ ìœ¼ë¡œ í‘œì‹œ")
    else:
        tail_days = st.selectbox("ê¼¬ë¦¬ ê¸¸ì´(ìµœê·¼ nì¼ ê²½ë¡œ)", [0, 3, 5, 10], index=0, help="ì˜¤ëŠ˜ ê¸°ì¤€ ê³¼ê±° nê±°ë˜ì¼ì˜ ì´ë™ ê²½ë¡œë¥¼ ì ì„ ìœ¼ë¡œ í‘œì‹œ")

def ann_vol(series, win):
    r = series.pct_change().dropna()
    if len(r) < max(5, int(win/3)): return np.nan
    r = r.tail(win);  return r.std() * np.sqrt(252.0)

def ann_cagr(series, win):
    s = series.dropna().tail(win+1)
    if len(s) < win+1: return np.nan
    start, end = s.iloc[-(win+1)], s.iloc[-1]
    if start <= 0 or end <= 0: return np.nan
    return (end/start)**(252.0/win) - 1.0

def scatter_points_for_date(df_prices, ref_loc, win):
    if ref_loc < 1: return pd.DataFrame()
    pts = {}
    for c in df_prices.columns:
        s = df_prices[c].iloc[:ref_loc+1]
        v = ann_vol(s, win); g = ann_cagr(s, win)
        pts[c] = (v, g)
    return pd.DataFrame(pts, index=["Vol","CAGR"]).T

plot_syms = list(mom_ranked.head(plot_n).index)
idx_all = prices_krw.index
today_loc = len(idx_all) - 1
yesterday_loc = max(0, today_loc - 1)
monthago_loc = max(0, today_loc - 21)

pts_today = scatter_points_for_date(prices_krw[plot_syms], today_loc, rv_window)
pts_yest  = scatter_points_for_date(prices_krw[plot_syms], yesterday_loc, rv_window)
pts_mago  = scatter_points_for_date(prices_krw[plot_syms], monthago_loc, rv_window)

# --- ê¼¬ë¦¬ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ìœ í‹¸(ì—°í•œâ†’ì§„í•œ)
def add_tail_segments(fig, sym, tail_len, color="rgba(0,0,0,1)"):
    if tail_len <= 0: return
    # loc: today - tail_len ... today
    prev_xy = None
    for k in range(tail_len, -1, -1):
        loc = max(0, today_loc - k)
        p = scatter_points_for_date(prices_krw[[sym]], loc, rv_window)
        if p.empty or p.isna().any().any(): 
            prev_xy = None
            continue
        x = float(p.iloc[0,0])*100.0  # Vol%
        y = float(p.iloc[0,1])*100.0  # CAGR%
        if prev_xy is not None:
            age = (tail_len - k + 1)  # ìµœê·¼ì¼ìˆ˜ë¡ ì‘ìŒ
            alpha = max(0.15, min(0.5, age/(tail_len+1)))  # 0.15~0.5
            fig.add_trace(go.Scatter(
                x=[prev_xy[0], x], y=[prev_xy[1], y],
                mode="lines", line=dict(width=2, dash="dot"),
                showlegend=False, hoverinfo="skip", opacity=alpha, name=f"{sym}-tail"
            ))
        prev_xy = (x, y)

# --- ì •ì (3ì  + ì´ë™ì„  + ê¼¬ë¦¬)
def make_static_scatter():
    fig = go.Figure()
    # ê¼¬ë¦¬: ì‹¬ë³¼ë³„ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
    for c in plot_syms:
        add_tail_segments(fig, c, tail_days)

    # ê¼¬ë¦¬ ê¸¸ì´ê°€ 0ì¼ ë•Œë§Œ ê³¼ê±° ì‹œì ë“¤ í‘œì‹œ
    if tail_days == 0:
        # 1M ago
        fig.add_trace(go.Scatter(
            x=pts_mago["Vol"]*100, y=pts_mago["CAGR"]*100, mode="markers",
            marker=dict(size=7, color="lightgray"),
            text=[display_name(s) for s in pts_mago.index],
            hovertemplate="%{text}<br>1M ago<br>Vol: %{x:.2f}% | CAGR: %{y:.2f}%<extra></extra>",
            name="1M ago", showlegend=True
        ))
        # Yesterday
        fig.add_trace(go.Scatter(
            x=pts_yest["Vol"]*100, y=pts_yest["CAGR"]*100, mode="markers",
            marker=dict(size=8, color="silver"),
            text=[display_name(s) for s in pts_yest.index],
            hovertemplate="%{text}<br>Yesterday<br>Vol: %{x:.2f}% | CAGR: %{y:.2f}%<extra></extra>",
            name="Yesterday", showlegend=True
        ))
    # Today
    fig.add_trace(go.Scatter(
        x=pts_today["Vol"]*100, y=pts_today["CAGR"]*100, mode="markers+text",
        marker=dict(size=9),
        text=[display_name(s) for s in pts_today.index],
        textposition="top center",
        hovertemplate="%{text}<br>Today<br>Vol: %{x:.2f}% | CAGR: %{y:.2f}%<extra></extra>",
        name="Today", showlegend=True
    ))
    # ê¼¬ë¦¬ ê¸¸ì´ê°€ 0ì¼ ë•Œë§Œ 1Mâ†’Yestâ†’Today ì—°ê²°ì„  í‘œì‹œ
    if tail_days == 0:
        for c in plot_syms:
            xs=[]; ys=[]
            for dfp in (pts_mago, pts_yest, pts_today):
                if c in dfp.index and not dfp.loc[c].isna().any():
                    xs.append(float(dfp.loc[c,"Vol"])*100)
                    ys.append(float(dfp.loc[c,"CAGR"])*100)
            if len(xs)>=2:
                fig.add_trace(go.Scatter(x=xs, y=ys, mode="lines",
                                         line=dict(width=1), opacity=0.35,
                                         name=f"path-{c}", showlegend=False, hoverinfo="skip"))
    fig.update_layout(
        height=520, margin=dict(l=10,r=10,t=10,b=10),
        xaxis_title="Volatility (ann, %)", yaxis_title="CAGR (ann, %)",
        hovermode="closest"
    )
    return fig

# --- ì• ë‹ˆë©”ì´ì…˜: í”„ë ˆì„ë§ˆë‹¤ í˜„ì¬ ìœ„ì¹˜ + ê° ì¢…ëª© ê¼¬ë¦¬ ë™ì‹œ ê°±ì‹ 
def make_motion_scatter(days):
    days = min(days, len(idx_all)-1)
    start_loc = max(0, today_loc - days)
    frames = []

    # ì´ˆê¸° í”„ë ˆì„ ë°ì´í„°
    p0 = scatter_points_for_date(prices_krw[plot_syms], start_loc, rv_window)
    traces = []

    # ê¼¬ë¦¬ëŠ” ì‹¬ë³¼ë³„ë¡œ ê°œë³„ traceë¥¼ ì‚¬ìš©(í”„ë ˆì„ë§ˆë‹¤ ì¬ê³„ì‚°)
    # ì´ˆê¸° ê¼¬ë¦¬
    tail_traces = []
    for c in plot_syms:
        # ë¹ˆ ê¼¬ë¦¬(ì´ˆê¸°)
        tail_traces.append(go.Scatter(x=[], y=[], mode="lines", line=dict(width=2, dash="dot"),
                                      showlegend=False, hoverinfo="skip", name=f"{c}-tail"))

    # ì´ˆê¸° í¬ì¸íŠ¸
    traces.extend(tail_traces)
    traces.append(go.Scatter(
        x=p0["Vol"]*100, y=p0["CAGR"]*100, mode="markers",
        marker=dict(size=9),
        text=[display_name(s) for s in p0.index],
        hovertemplate="%{text}<br>%{x:.2f}% / %{y:.2f}%<extra></extra>",
        name="Points", showlegend=False
    ))

    # í”„ë ˆì„ ìƒì„±
    for loc in range(start_loc, today_loc+1):
        p = scatter_points_for_date(prices_krw[plot_syms], loc, rv_window)
        frame_data = []

        # ê° ì¢…ëª© ê¼¬ë¦¬ ì¢Œí‘œ ê³„ì‚°
        for c in plot_syms:
            xs=[]; ys=[]
            for k in range(tail_days, -1, -1):
                loc_k = max(0, loc - k)
                pk = scatter_points_for_date(prices_krw[[c]], loc_k, rv_window)
                if pk.empty or pk.isna().any().any(): 
                    continue
                xs.append(float(pk.iloc[0,0])*100.0)
                ys.append(float(pk.iloc[0,1])*100.0)
            frame_data.append(go.Scatter(x=xs, y=ys, mode="lines", line=dict(width=2, dash="dot"),
                                         showlegend=False, hoverinfo="skip", name=f"{c}-tail"))
        # í¬ì¸íŠ¸
        frame_data.append(go.Scatter(
            x=p["Vol"]*100, y=p["CAGR"]*100, mode="markers",
            marker=dict(size=9),
            text=[display_name(s) for s in p.index],
            hovertemplate="%{text}<br>%{x:.2f}% / %{y:.2f}%<extra></extra>",
            name="Points", showlegend=False
        ))

        frames.append(go.Frame(data=frame_data, name=str(prices_krw.index[loc].date())))

    fig = go.Figure(data=traces, frames=frames)
    # ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œì— ë”°ë¥¸ ìë™ ì¬ìƒ ì„¤ì •
    auto_play = motion_mode != "ë„ê¸°"
    
    fig.update_layout(
        height=520, margin=dict(l=10,r=10,t=10,b=10),
        xaxis_title="Volatility (ann, %)", yaxis_title="CAGR (ann, %)",
        updatemenus=[{
            "type": "buttons", "showactive": False,
            "buttons": [
                {"label":"â–¶ Play","method":"animate",
                 "args":[None, {"frame":{"duration":300, "redraw":True}, "fromcurrent":True, "transition":{"duration":0}}]},
                {"label":"â¸ Pause","method":"animate","args":[[None], {"frame":{"duration":0}, "mode":"immediate"}]}
            ]
        }],
        sliders=[{
            "steps":[{"label":f.name, "method":"animate", "args":[[f.name], {"mode":"immediate","frame":{"duration":0,"redraw":True}}]} for f in frames],
            "currentvalue":{"prefix":"Date: "}
        }]
    )
    
    # ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œê°€ ì„ íƒë˜ë©´ ìë™ ì¬ìƒ
    if auto_play:
        fig.update_layout(
            updatemenus=[{
                "type": "buttons", "showactive": False,
                "buttons": [
                    {"label":"â–¶ Play","method":"animate",
                     "args":[None, {"frame":{"duration":300, "redraw":True}, "fromcurrent":True, "transition":{"duration":0}}]},
                    {"label":"â¸ Pause","method":"animate","args":[[None], {"frame":{"duration":0}, "mode":"immediate"}]}
                ]
            }]
        )
    return fig

# ë Œë”

if motion_mode == "ë„ê¸°":
    fig_mv = make_static_scatter()
else:
    days = 10 if "10" in motion_mode else 20
    fig_mv = make_motion_scatter(days)
    
    # ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œì¼ ë•Œ ìë™ ì¬ìƒì„ ìœ„í•œ JavaScript ì¶”ê°€
    if motion_mode != "ë„ê¸°":
        st.markdown("""
        <script>
        setTimeout(function() {
            var plotlyDiv = document.querySelector('[data-testid="stPlotlyChart"] iframe');
            if (plotlyDiv) {
                plotlyDiv.onload = function() {
                    var plotlyFrame = plotlyDiv.contentWindow;
                    if (plotlyFrame && plotlyFrame.Plotly) {
                        setTimeout(function() {
                            plotlyFrame.Plotly.animate(plotlyFrame.document.querySelector('.plotly-graph-div'), null, {
                                frame: {duration: 300, redraw: true},
                                fromcurrent: true,
                                transition: {duration: 0}
                            });
                        }, 1000);
                    }
                };
            }
        }, 500);
        </script>
        """, unsafe_allow_html=True)

st.plotly_chart(fig_mv, use_container_width=True)
st.caption("ì„¤ëª…: ê° ì ì€ ì„ íƒí•œ ì°½(ê¸°ë³¸ 21ê±°ë˜ì¼)ì˜ ì—°ìœ¨í™” ìˆ˜ìµë¥ (CAGR)Â·ì—°ìœ¨í™” ë³€ë™ì„±ì…ë‹ˆë‹¤. "
           "â€˜ê¼¬ë¦¬ ê¸¸ì´â€™ëŠ” ì˜¤ëŠ˜ ê¸°ì¤€ ê³¼ê±° nê±°ë˜ì¼ ë™ì•ˆ ì¢Œí‘œì˜ ì´ë™ ê²½ë¡œë¥¼ ì ì„ ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤. "
           "ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œì—ì„œëŠ” ë‚ ì§œê°€ ë°”ë€œì— ë”°ë¼ í˜„ì¬ ìœ„ì¹˜ì™€ ê¼¬ë¦¬ê°€ í•¨ê»˜ ê°±ì‹ ë©ë‹ˆë‹¤.")

# ------------------------------
# â‘£ ì„¸ë¶€ ë³´ê¸°
# ------------------------------
st.subheader("ì„¸ë¶€ ë³´ê¸°")
ordered_options = list(mom_ranked.index)
default_sym = (sel_syms[0] if sel_syms else ordered_options[0]) if ordered_options else prices_krw.columns[0]
detail_sym = st.selectbox("í‹°ì»¤ ì„ íƒ", options=ordered_options,
                          index=ordered_options.index(default_sym) if default_sym in ordered_options else 0,
                          format_func=lambda s: display_name(s))
s = prices_krw[detail_sym].dropna()
e20,e50,e200 = ema(s,20), ema(s,50), ema(s,200)
fig_det = go.Figure()
fig_det.add_trace(go.Scatter(x=s.index, y=s.values, mode="lines", name="KRW"))
fig_det.add_trace(go.Scatter(x=e20.index, y=e20.values, mode="lines", name="EMA20"))
fig_det.add_trace(go.Scatter(x=e50.index, y=e50.values, mode="lines", name="EMA50"))
fig_det.add_trace(go.Scatter(x=e200.index, y=e200.values, mode="lines", name="EMA200"))
fig_det.update_layout(
    height=420, 
    margin=dict(l=10,r=10,t=10,b=10), 
    yaxis_title="KRW",
    legend=dict(
        orientation="h",
        yanchor="bottom",
        y=-0.15,
        xanchor="center",
        x=0.5
    )
)
st.plotly_chart(fig_det, use_container_width=True, config={"displayModeBar": False})

roll_max = s.cummax()
dd = (s/roll_max - 1.0)*100.0
fig_dd = go.Figure([go.Scatter(x=dd.index, y=dd.values, mode="lines", name="Drawdown(%)")])
fig_dd.update_layout(height=180, margin=dict(l=10,r=10,t=10,b=10), yaxis_title="%")
st.plotly_chart(fig_dd, use_container_width=True, config={"displayModeBar": False})

row = mom.loc[detail_sym]
badges=[]
if row["R_1M"]>0: badges.append("1M +")
if row["AboveEMA50"]>0: badges.append("EMA50 ìƒíšŒ")
if row["Breakout120"]>=-0.01: badges.append("120D ì‹ ê³ ê°€ ê·¼ì ‘")
if row["Î”FMS_1D"]>0: badges.append("ê°€ì†(1D+)")
if row["Î”FMS_5D"]>0: badges.append("ê°€ì†(5D+)")
st.markdown(" ".join([f"<span class='badge'>{b}</span>" for b in badges]) or "<span class='small'>ìƒíƒœ ë°°ì§€ ì—†ìŒ</span>", unsafe_allow_html=True)

# ------------------------------
# â‘¤ í‘œ
# ------------------------------
st.subheader("ëª¨ë©˜í…€ í…Œì´ë¸” (ê°€ì†/ì¶”ì„¸/ìˆ˜ìµë¥ )")
disp = mom.copy()
for c in ["R_1W","R_1M","R_3M","R_6M","R_YTD","AboveEMA50","Breakout120"]:
    if c in disp: disp[c] = (disp[c]*100).round(2)
if "Slope30(ann)" in disp: disp["Slope30(ann)"] = disp["Slope30(ann)"].round(3)
for c in ["FMS","Î”FMS_1D","Î”FMS_5D"]:
    if c in disp: disp[c] = disp[c].round(2)
disp = disp.sort_values(rank_col if rank_col in disp.columns else "FMS", ascending=False)
st.dataframe(disp, use_container_width=True)

# ------------------------------
# â‘¥ ë””ë²„ê·¸/ì§„ë‹¨
# ------------------------------
with st.expander("ë””ë²„ê·¸ ë¡œê·¸ / ì§„ë‹¨ (ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥)"):
    last_row = prices_krw.iloc[-1]
    usa_cols = [c for c in prices_krw.columns if classify(c)=="USA"]
    kor_cols = [c for c in prices_krw.columns if classify(c)=="KOR"]
    jpn_cols = [c for c in prices_krw.columns if classify(c)=="JPN"]
    diag = {
        "last_date": str(prices_krw.index[-1].date()),
        "cols_total": prices_krw.shape[1],
        "last_notna_total": int(last_row.notna().sum()),
        "last_notna_USA": int(last_row[usa_cols].notna().sum()),
        "last_notna_KOR": int(last_row[kor_cols].notna().sum()),
        "last_notna_JPN": int(last_row[jpn_cols].notna().sum()),
        "env_CURL_CFFI_DISABLE_CACHE": os.environ.get("CURL_CFFI_DISABLE_CACHE")
    }
    st.json(diag)
    st.text_area("LOG", value="\n".join(st.session_state["LOG"][-400:]), height=200)
