# app.py
# -*- coding: utf-8 -*-
# KRW Momentum Radar - v3.6.0
# 
# ì£¼ìš” ê¸°ëŠ¥:
# - FMS(Fast Momentum Score) ê¸°ë°˜ ëª¨ë©˜í…€ ë¶„ì„
# - ë‹¤êµ­ê°€ ì‹œì¥ í†µí•© ë¶„ì„ (ë¯¸êµ­, í•œêµ­, ì¼ë³¸)
# - ìˆ˜ìµë¥ -ë³€ë™ì„± ì´ë™ë§µ (ì •ì /ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œ)
# - ì‹¤ì‹œê°„ ë°ì´í„° ì—…ë°ì´íŠ¸ ë° ì‹œê°í™”
# - ë™ì  ê´€ì‹¬ì¢…ëª© ê´€ë¦¬ ë° ë°°ì¹˜ ìŠ¤ìº” ê²°ê³¼ í™•ì¸
# - True Range ê¸°ë°˜ ê±°ë˜ ì í•©ì„± í•„í„°

import os
os.environ.setdefault("CURL_CFFI_DISABLE_CACHE", "1")  # curl_cffi sqlite ìºì‹œ ë¹„í™œì„±í™”

import warnings
from datetime import datetime
import json
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import pytz
import re
import streamlit as st
import yfinance as yf
from watchlist_utils import load_watchlist, save_watchlist, add_to_watchlist, remove_from_watchlist, export_watchlist_to_csv, import_watchlist_from_csv
from config import FMS_FORMULA
from analysis_utils import (
    calculate_tradeability_filters as _au_trade_filters,
    momentum_now_and_delta as _au_momentum_now_and_delta,
    calculate_fms_for_batch as _au_calculate_fms_for_batch,
)

warnings.filterwarnings("ignore", category=ResourceWarning)
KST = pytz.timezone("Asia/Seoul")

# ------------------------------
# ê¸°ë³¸ ìœ ë‹ˆë²„ìŠ¤ (ê´€ì‹¬ì¢…ëª© ì´ˆê¸°í™”ìš©)
# ------------------------------
DEFAULT_USD_SYMBOLS = [
    'AAPL','ABBV','AMZN','ARKK','AVGO','BND','BRK-B','CAT','COST','CRM','CVX','DIA',
    'DIS','EEM','EFA','EWJ','GLD','GOOGL','HD','ICLN','INDA','IWM','IYT','JNJ','JPM',
    'KO','LLY','META','MRK','MSFT','NFLX','NVDA','PFE','PG','QQQ','SLV','SMH','SOXX',
    'SPY','T','TSLA','UNH','URA','V','VNQ','WMT','XLE','XLF','XLI','XLK','XLP','XLV','XLY'
]
DEFAULT_KRW_SYMBOLS = [
    '000660.KS','005930.KS'
]
DEFAULT_JPY_SYMBOLS = ['7203.T']



def classify(sym):
    # symì´ floatì´ë‚˜ ë‹¤ë¥¸ íƒ€ì…ì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ strë¡œ ë³€í™˜
    sym_str = str(sym)
    if sym_str.endswith(".KS"): return "KOR"
    if sym_str.endswith(".T"):  return "JPN"
    return "USA"

# ------------------------------
# í˜ì´ì§€/ìŠ¤íƒ€ì¼
# ------------------------------
st.set_page_config(page_title="KRW Momentum Radar v3.6.0", page_icon="âš¡", layout="wide")
st.markdown("""
<style>
.block-container {padding-top: 0.8rem;}
.badge {display:inline-block; padding:2px 8px; border-radius:999px; font-size:0.75rem; margin-right:6px; background:#f1f3f5;}
.kpi {border:1px solid #eee; border-radius:16px; padding:10px 14px; box-shadow:0 1px 6px rgba(0,0,0,0.06);}
.small {font-size:0.8rem; color:#555;}
</style>
""", unsafe_allow_html=True)

# ------------------------------
# ê´€ì‹¬ì¢…ëª© ì´ˆê¸°í™” (UIë³´ë‹¤ ë¨¼ì € ì‹¤í–‰)
# ------------------------------
if 'watchlist' not in st.session_state:
    default_symbols = DEFAULT_USD_SYMBOLS + DEFAULT_KRW_SYMBOLS + DEFAULT_JPY_SYMBOLS
    st.session_state.watchlist = load_watchlist(default_symbols)
    # ê´€ì‹¬ì¢…ëª© ì´ˆê¸°í™” ì™„ë£Œ

# í˜„ì¬ ê´€ì‹¬ì¢…ëª©ì„ ê¸°ì¡´ ë³€ìˆ˜ëª…ìœ¼ë¡œ ë§¤í•‘ (í•˜ìœ„ í˜¸í™˜ì„±)
USD_SYMBOLS = [str(s) for s in st.session_state.watchlist if classify(s) == "USA"]
KRW_SYMBOLS = [str(s) for s in st.session_state.watchlist if classify(s) == "KOR"]
JPY_SYMBOLS = [str(s) for s in st.session_state.watchlist if classify(s) == "JPN"]

# ------------------------------
# ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ------------------------------
def _extract_adj_close(df_chunk, tickers):
    if df_chunk is None or len(df_chunk)==0:
        return pd.DataFrame(columns=tickers, dtype=float)
    if isinstance(df_chunk.columns, pd.MultiIndex):
        if 'Adj Close' in df_chunk.columns.get_level_values(0):
            adj = df_chunk['Adj Close'].copy()
        elif 'Close' in df_chunk.columns.get_level_values(0):
            adj = df_chunk['Close'].copy()
        else:
            parts=[]
            for t in tickers:
                try:
                    if ('Adj Close', t) in df_chunk.columns:
                        s = df_chunk[('Adj Close', t)].rename(t)
                    elif ('Close', t) in df_chunk.columns:
                        s = df_chunk[('Close', t)].rename(t)
                    else:
                        s = pd.Series(dtype=float, name=t)
                except Exception:
                    s = pd.Series(dtype=float, name=t)
                parts.append(s)
            adj = pd.concat(parts, axis=1)
    else:
        cols = df_chunk.columns
        if 'Adj Close' in cols:
            adj = df_chunk[['Adj Close']].copy(); adj.columns = tickers[:1]
        elif 'Close' in cols:
            adj = df_chunk[['Close']].copy(); adj.columns = tickers[:1]
        else:
            adj = df_chunk.copy()
            keep = [c for c in adj.columns if c in tickers]
            adj = adj[keep] if keep else pd.DataFrame(columns=tickers, dtype=float)
    adj = adj.loc[:, ~adj.columns.duplicated()]
    return adj

@st.cache_data(ttl=60*60*6, show_spinner=False)
def download_prices(tickers, period_="2y", interval="1d", chunk=25):
    frames=[]; missing=[]
    tickers = list(dict.fromkeys(tickers))
    for i in range(0, len(tickers), chunk):
        part = tickers[i:i+chunk]
        try:
            raw = yf.download(part, period=period_, interval=interval, auto_adjust=False,
                              group_by='column', progress=False, threads=True)
            adj = _extract_adj_close(raw, part)
        except Exception as e:
            log(f"ERROR download chunk: {part[:3]}... -> {e}")
            adj = pd.DataFrame()
        if adj.empty or adj.isna().all().all():
            pframes=[]
            for t in part:
                try:
                    r = yf.download(t, period=period_, interval=interval, auto_adjust=False,
                                    group_by='column', progress=False, threads=False)
                    a = _extract_adj_close(r, [t])
                    pframes.append(a)
                except Exception as e:
                    log(f"ERROR download single: {t} -> {e}")
                    missing.append(t)
            if pframes:
                frames.append(pd.concat(pframes, axis=1))
        else:
            frames.append(adj)
    if not frames:
        return pd.DataFrame(), missing
    out = pd.concat(frames, axis=1)
    out = out.loc[:, ~out.columns.duplicated()].sort_index()
    all_nan = out.columns[out.isna().all()]
    if len(all_nan):
        log(f"DROP all-NaN columns: {list(all_nan)[:5]}{' ...' if len(all_nan)>5 else ''}")
    out = out.drop(columns=all_nan)
    return out, sorted(list(dict.fromkeys(list(missing)+list(all_nan))))

@st.cache_data(ttl=60*60*6, show_spinner=False)
def download_ohlc_prices(tickers, period_="2y", interval="1d", chunk=25):
    """
    ê±°ë˜ ì í•©ì„± í•„í„°ë¥¼ ìœ„í•œ OHLC ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        tickers (list): ë‹¤ìš´ë¡œë“œí•  í‹°ì»¤ ëª©ë¡
        period_ (str): ë°ì´í„° ê¸°ê°„
        interval (str): ë°ì´í„° ê°„ê²©
        chunk (int): ë°°ì¹˜ í¬ê¸°
    
    Returns:
        tuple: (ohlc_data, missing_tickers)
    """
    frames=[]; missing=[]
    tickers = list(dict.fromkeys(tickers))
    
    for i in range(0, len(tickers), chunk):
        part = tickers[i:i+chunk]
        try:
            raw = yf.download(part, period=period_, interval=interval, auto_adjust=False,
                              group_by='column', progress=False, threads=True)
            
            if raw.empty:
                missing.extend(part)
                continue
                
            # OHLC ë°ì´í„° ì¶”ì¶œ
            if isinstance(raw.columns, pd.MultiIndex):
                ohlc_data = {}
                for t in part:
                    if ('High', t) in raw.columns and ('Low', t) in raw.columns and ('Close', t) in raw.columns:
                        ohlc_data[t] = pd.DataFrame({
                            'High': raw[('High', t)],
                            'Low': raw[('Low', t)],
                            'Close': raw[('Close', t)]
                        })
                    else:
                        missing.append(t)
            else:
                # ë‹¨ì¼ í‹°ì»¤ì¸ ê²½ìš°
                if len(part) == 1 and 'High' in raw.columns and 'Low' in raw.columns and 'Close' in raw.columns:
                    t = part[0]
                    ohlc_data[t] = pd.DataFrame({
                        'High': raw['High'],
                        'Low': raw['Low'],
                        'Close': raw['Close']
                    })
                else:
                    missing.extend(part)
                    continue
            
            if ohlc_data:
                frames.append(pd.concat(ohlc_data, axis=1))
                
        except Exception as e:
            log(f"ERROR download OHLC chunk: {part[:3]}... -> {e}")
            missing.extend(part)
    
    if not frames:
        return pd.DataFrame(), missing
    
    # ëª¨ë“  OHLC ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í•©ì¹˜ê¸°
    all_ohlc = pd.concat(frames, axis=1)
    all_ohlc = all_ohlc.loc[:, ~all_ohlc.columns.duplicated()].sort_index()
    
    return all_ohlc, sorted(list(dict.fromkeys(missing)))

@st.cache_data(ttl=60*60*6, show_spinner=False)
def download_fx(period_="2y", interval="1d"):
    fx_krw, miss1 = download_prices(["KRW=X"], period_, interval)
    fx_jpy, miss2 = download_prices(["JPY=X"], period_, interval)
    usdkrw = fx_krw.iloc[:,0].rename("USDKRW") if not fx_krw.empty else pd.Series(dtype=float, name="USDKRW")
    usdjpy = fx_jpy.iloc[:,0].rename("USDJPY") if not fx_jpy.empty else pd.Series(dtype=float, name="USDJPY")
    if not usdkrw.empty and not usdjpy.empty:
        start=min(usdkrw.index.min(), usdjpy.index.min())
        end=max(usdkrw.index.max(), usdjpy.index.max())
        idx = pd.date_range(start, end, freq='B')
        usdkrw = usdkrw.reindex(idx).ffill()
        usdjpy = usdjpy.reindex(idx).ffill()
        jpykrw = (usdkrw/usdjpy).rename("JPYKRW")
    else:
        jpykrw = pd.Series(dtype=float, name="JPYKRW")
    return usdkrw, usdjpy, jpykrw, (miss1+miss2)

def harmonize_calendar(df, coverage=0.9):
    if df.empty: return df
    idx = pd.date_range(df.index.min(), df.index.max(), freq='B')
    df = df.reindex(idx).ffill()
    # coverage ì²´í¬
    valid_ratio = df.count().div(len(df))
    keep_cols = valid_ratio[valid_ratio >= coverage].index
    return df[keep_cols] if len(keep_cols) > 0 else pd.DataFrame()

def align_bday_ffill(df):
    if df is None or len(df)==0: return df
    idx = pd.date_range(df.index.min(), df.index.max(), freq='B')
    return df.reindex(idx).ffill()

# ------------------------------
# ë¡œê¹… í•¨ìˆ˜
# ------------------------------
if "LOG" not in st.session_state:
    st.session_state["LOG"] = []
def log(msg):
    ts = datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S")
    st.session_state["LOG"].append(f"[{ts}] {msg}")

# ------------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ------------------------------
def warn_to_log(fn, *args, **kwargs):
    with warnings.catch_warnings(record=True) as wlist:
        result = fn(*args, **kwargs)
        for w in wlist:
            st.session_state["LOG"].append(f"WARNING: {w.category.__name__}: {str(w.message)}")
        return result

# ------------------------------
# ì§€í‘œ/ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜ë“¤
# ------------------------------
def ema(s, span): return s.ewm(span=span, adjust=False).mean()

def returns_pct(df, n):
    if df.shape[0] <= n: 
        return pd.Series(index=df.columns, dtype=float)
    dff = df.ffill()
    r = warn_to_log(dff.pct_change, periods=n, fill_method=None).iloc[-1]
    return r

def ytd_return(df):
    if df.empty: return pd.Series(dtype=float)
    dff = df.ffill()
    last = dff.index[-1]
    y0 = pd.Timestamp(datetime(last.year, 1, 1))
    start_idx = dff.index.get_indexer([y0], method='nearest')[0]
    return dff.iloc[-1] / dff.iloc[start_idx] - 1.0

def last_vol_annualized(df, window=20):
    rets = warn_to_log(df.ffill().pct_change, fill_method=None).dropna()
    if rets.empty: return pd.Series(index=df.columns, dtype=float)
    vol = rets.rolling(window).std().iloc[-1] * np.sqrt(252.0)
    return vol

# ------------------------------
# ì¤‘ì•™í™”ëœ FMS/í•„í„° ë¡œì§ìœ¼ë¡œ ì˜¤ë²„ë¼ì´ë“œ
# ------------------------------
calculate_tradeability_filters = _au_trade_filters
momentum_now_and_delta = _au_momentum_now_and_delta

def calculate_fms_for_batch(symbols_batch, period_="1y", interval="1d", reference_prices_krw=None):
    return _au_calculate_fms_for_batch(symbols_batch, period_, interval, reference_prices_krw)

# ------------------------------
# UI ê´€ë ¨ í•¨ìˆ˜ë“¤
# ------------------------------
def get_button_states():
    """
    ë²„íŠ¼ ë¹„í™œì„±í™” ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        tuple: (is_scanning, is_reassessing, button_disabled)
            - is_scanning (bool): ìœ ë‹ˆë²„ìŠ¤ ìŠ¤ìº” ì§„í–‰ ì¤‘ ì—¬ë¶€
            - is_reassessing (bool): ì¬í‰ê°€ ì§„í–‰ ì¤‘ ì—¬ë¶€
            - button_disabled (bool): ë²„íŠ¼ ë¹„í™œì„±í™” ì—¬ë¶€
    """
    is_scanning = False  # ë°°ì¹˜ ìŠ¤ìº”ì€ ë³„ë„ í”„ë¡œì„¸ìŠ¤ë¡œ ì‹¤í–‰ë¨
    is_reassessing = 'reassessing' in st.session_state and st.session_state.reassessing
    return is_scanning, is_reassessing, is_scanning or is_reassessing
def display_name(sym):
    """ì‹¬ë³¼ì„ í‘œì‹œìš© ì´ë¦„ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if 'NAME_MAP' not in globals():
        return sym
    nm = NAME_MAP.get(sym, sym)
    return f"{nm} ({sym})" if nm and nm != sym else sym

def only_name(sym):
    """ì‹¬ë³¼ì˜ ì´ë¦„ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if 'NAME_MAP' not in globals():
        return sym
    nm = NAME_MAP.get(sym, sym)
    return nm if nm else sym

# ------------------------------
# ì¢Œì¸¡ ì œì–´ - ê¹”ë”í•˜ê²Œ ì •ë¦¬ëœ ë©”ë‰´ êµ¬ì¡°
# ------------------------------

# 1. ë¶„ì„ ì„¤ì •
with st.sidebar.expander("ğŸ“Š ë¶„ì„ ì„¤ì •", expanded=True):
    period = st.selectbox("ì°¨íŠ¸ ê¸°ê°„", ["3M","6M","1Y","2Y","5Y"], index=0)
    
    rank_by = st.selectbox("ì •ë ¬ ê¸°ì¤€", ["Î”FMS(1D)","Î”FMS(5D)","FMS(í˜„ì¬)","1M ìˆ˜ìµë¥ "], index=2)
    TOP_N = st.slider("Top N", 5, 60, 20, step=5)
    use_log_scale = st.checkbox("ë¹„êµì°¨íŠ¸ ë¡œê·¸ ìŠ¤ì¼€ì¼", True)

# 2. ê´€ì‹¬ì¢…ëª© ê´€ë¦¬
with st.sidebar.expander("ğŸ“‹ ê´€ì‹¬ì¢…ëª© ê´€ë¦¬", expanded=False):
    # í˜„ì¬ ê´€ì‹¬ì¢…ëª© ì •ë³´
    st.info(f"í˜„ì¬ ê´€ì‹¬ì¢…ëª©: **{len(st.session_state.watchlist)}ê°œ**")
    
    # íŒŒì¼ ê´€ë¦¬
    st.markdown("**ğŸ“ íŒŒì¼ ê´€ë¦¬**")
    
    # ë‹¤ìš´ë¡œë“œ
    if st.button("ğŸ’¾ ê´€ì‹¬ì¢…ëª© ë‹¤ìš´ë¡œë“œ", help="í˜„ì¬ ê´€ì‹¬ì¢…ëª©ì„ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."):
        csv_data = export_watchlist_to_csv(
            st.session_state.watchlist, 
            country_classifier=classify, 
            name_display=display_name
        )
        
        if csv_data:
            st.download_button(
                label="ğŸ“¥ CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=csv_data,
                file_name=f"watchlist_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
        else:
            st.error("âŒ ë‹¤ìš´ë¡œë“œ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    # ì—…ë¡œë“œ
    uploaded_watchlist = st.file_uploader(
        "ğŸ“¤ ê´€ì‹¬ì¢…ëª© ì—…ë¡œë“œ", 
        type=['csv'],
        help="CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ê´€ì‹¬ì¢…ëª©ì„ êµì²´í•©ë‹ˆë‹¤.",
        key="watchlist_uploader"
    )
    
    if uploaded_watchlist is not None and not st.session_state.get('upload_processed', False):
        try:
            csv_data = uploaded_watchlist.read().decode('utf-8-sig')
            new_symbols, message = import_watchlist_from_csv(csv_data)
            
            if new_symbols:
                st.session_state.watchlist = new_symbols
                st.cache_data.clear()
                st.success(message)
                st.session_state.upload_processed = True
                st.rerun()
            else:
                st.error(message)
                
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # ì—…ë¡œë“œ ì²˜ë¦¬ ì™„ë£Œ í›„ í”Œë˜ê·¸ ë¦¬ì…‹
    if st.session_state.get('upload_processed', False):
        st.session_state.upload_processed = False
    
    # êµ¬ë¶„ì„ 
    st.divider()
    
    # ì¬í‰ê°€ ê¸°ëŠ¥
    st.markdown("**ğŸ”„ ì¬í‰ê°€**")
    is_scanning, is_reassessing, button_disabled = get_button_states()
    button_text = 'â³ ì¬í‰ê°€ ì¤‘...' if is_reassessing else 'ğŸ“Š ì¬í‰ê°€ ì‹¤í–‰'
    
    if st.button(button_text, disabled=button_disabled, help="í˜„ì¬ ê´€ì‹¬ì¢…ëª©ì˜ FMSë¥¼ ì¬ê³„ì‚°í•˜ì—¬ ì €ì„±ê³¼ ì¢…ëª©ì„ ì‹ë³„í•©ë‹ˆë‹¤."):
        # ì¬í‰ê°€ ìƒíƒœ ì„¤ì •
        st.session_state.reassessing = True
        
        with st.spinner("ê´€ì‹¬ì¢…ëª©ì„ ì¬í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):
            watchlist_fms = calculate_fms_for_batch(st.session_state.watchlist, period_="1y")
            
            if not watchlist_fms.empty:
                fms_25th = watchlist_fms['FMS'].quantile(0.25)
                stale_candidates = watchlist_fms[watchlist_fms['FMS'] < fms_25th].sort_values('FMS')
                
                if not stale_candidates.empty:
                    st.warning(f"FMS í•˜ìœ„ 25% ì¢…ëª© ({len(stale_candidates)}ê°œ) ë°œê²¬")
                    st.session_state['reassessment_results'] = stale_candidates
                else:
                    st.success("ëª¨ë“  ê´€ì‹¬ì¢…ëª©ì´ ì–‘í˜¸í•œ ìƒíƒœì…ë‹ˆë‹¤!")
                    st.session_state['reassessment_results'] = None
            else:
                st.error("ì¬í‰ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.session_state['reassessment_results'] = None
        
        # ì¬í‰ê°€ ì™„ë£Œ
        st.session_state.reassessing = False
    
    # ì¬í‰ê°€ ê²°ê³¼ í‘œì‹œ
    if 'reassessment_results' in st.session_state and st.session_state['reassessment_results'] is not None:
        st.markdown("**ğŸ“‹ ì œê±° ì œì•ˆ ì¢…ëª©:**")
        stale_candidates = st.session_state['reassessment_results']
        
        for symbol in stale_candidates.index[:5]:
            col1, col2 = st.columns([3, 1])
            with col1:
                fms_score = stale_candidates.loc[symbol, 'FMS']
                st.write(f"**{symbol}** (FMS: {fms_score:.1f})")
            with col2:
                if st.button("ğŸ—‘ï¸", key=f"remove_{symbol}"):
                    # ê´€ì‹¬ì¢…ëª©ì—ì„œ ì œê±°
                    st.session_state.watchlist = remove_from_watchlist(st.session_state.watchlist, [symbol])
                    
                    # ì¬í‰ê°€ ê²°ê³¼ì—ì„œë„ ì œê±°
                    if 'reassessment_results' in st.session_state and st.session_state['reassessment_results'] is not None:
                        if symbol in st.session_state['reassessment_results'].index:
                            st.session_state['reassessment_results'] = st.session_state['reassessment_results'].drop(symbol)
                    
                    st.cache_data.clear()
                    st.rerun()

# 3. ì‹ ê·œ ì¢…ëª© íƒìƒ‰
with st.sidebar.expander("ğŸš€ ì‹ ê·œ ì¢…ëª© íƒìƒ‰", expanded=False):
    # --- [ì‹ ê·œ] ë°°ì¹˜ ìŠ¤ìº” ê´€ë¦¬ ---
    st.markdown("**ğŸ“¦ ë°°ì¹˜ ìŠ¤ìº” ê´€ë¦¬**")
    import subprocess
    import psutil
    import os as _os
    from datetime import datetime as _dt

    latest_scan_file = "scan_results/latest_scan_results.csv"
    status_text = "ë°°ì¹˜ ìŠ¤ìº” ë‚´ì—­ ì—†ìŒ"
    if _os.path.exists(latest_scan_file):
        last_mod_time = _dt.fromtimestamp(_os.path.getmtime(latest_scan_file))
        time_diff_hours = (_dt.now() - last_mod_time).total_seconds() / 3600
        if time_diff_hours <= 24:
            status_text = f"âœ… ìµœì‹  ë°ì´í„°: {last_mod_time.strftime('%Y-%m-%d %H:%M')}"
        else:
            status_text = f"âš ï¸ ì˜¤ë˜ëœ ë°ì´í„°: {last_mod_time.strftime('%Y-%m-%d %H:%M')}"
    st.info(status_text)

    BATCH_SCRIPT_NAME = "run_scan_batch.py"
    is_batch_running = False
    try:
        for proc in psutil.process_iter(['name', 'cmdline']):
            cmdline = proc.info.get('cmdline')
            if cmdline and BATCH_SCRIPT_NAME in " ".join(map(str, cmdline)):
                is_batch_running = True
                break
    except Exception:
        is_batch_running = False

    if is_batch_running:
        st.warning("â³ ë°°ì¹˜ ìŠ¤ìº”ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤...")

    if st.button("ğŸ”„ ì§€ê¸ˆ ë°°ì¹˜ ê°•ì œ ì‹¤í–‰", help="ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì „ì²´ ìœ ë‹ˆë²„ìŠ¤ ìŠ¤ìº”ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. (ê¸°ì¡´ ìŠ¤ìº”ì€ ê°•ì œ ì¢…ë£Œ)"):
        if is_batch_running:
            try:
                for proc in psutil.process_iter(['name', 'cmdline']):
                    cmdline = proc.info.get('cmdline')
                    if cmdline and BATCH_SCRIPT_NAME in " ".join(map(str, cmdline)):
                        proc.kill()
                        st.toast(f"ê¸°ì¡´ ìŠ¤ìº”(PID: {proc.pid})ì„ ì¤‘ì§€í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"ê¸°ì¡´ ìŠ¤ìº” ì¤‘ì§€ ì‹¤íŒ¨: {e}")

        try:
            subprocess.Popen(["cmd", "/c", "start", "run_batch_manual.bat"], shell=True)
            st.toast("ìƒˆë¡œìš´ ë°°ì¹˜ ìŠ¤ìº”ì„ ì‹œì‘í•©ë‹ˆë‹¤! (ìƒˆ ì½˜ì†” ì°½ í™•ì¸)")
            st.rerun()
        except Exception as e:
            st.error(f"ë°°ì¹˜ ìŠ¤ìº” ì‹œì‘ ì‹¤íŒ¨: {e}")
    
    # ë°°ì¹˜ ìŠ¤ìº” ê²°ê³¼ í‘œì‹œ
    if _os.path.exists(latest_scan_file):
        st.divider()
        st.markdown("**ğŸ“‹ ë°°ì¹˜ ìŠ¤ìº” ê²°ê³¼**")
        
        try:
            scan_results_df = pd.read_csv(latest_scan_file, index_col=0)
            
            # FMS ì„ê³„ê°’ í•„í„°ë§ ë° ì´ë¯¸ ê´€ì‹¬ì¢…ëª©ì— ì¶”ê°€ëœ ì¢…ëª© ì œì™¸
            fms_threshold_scan = st.slider("FMS ì„ê³„ê°’", 0.0, 5.0, 0.0, 0.1, key="scan_fms_threshold")
            filtered_results = scan_results_df[
                (scan_results_df['FMS'] >= fms_threshold_scan) & 
                (~scan_results_df.index.isin(st.session_state.watchlist))
            ].sort_values('FMS', ascending=False)
            
            if not filtered_results.empty:
                st.info(f"ì´ {len(filtered_results)}ê°œ ì¢…ëª© (FMS â‰¥ {fms_threshold_scan})")
                
                # í˜ì´ì§€ë‹¹ í‘œì‹œ ê°œìˆ˜
                items_per_page = st.selectbox("í˜ì´ì§€ë‹¹ í‘œì‹œ", [5, 10, 20, 30], index=1, key="scan_items_per_page")
                
                # í˜ì´ì§• ê³„ì‚°
                total_pages = max(1, (len(filtered_results) + items_per_page - 1) // items_per_page)
                current_page = st.session_state.get('scan_page', 1)
                if current_page > total_pages:
                    current_page = 1
                    st.session_state.scan_page = 1
                
                start_idx = (current_page - 1) * items_per_page
                end_idx = start_idx + items_per_page
                page_results = filtered_results.iloc[start_idx:end_idx]
                
                # í˜ì´ì§• ì»¨íŠ¸ë¡¤
                prev_col, info_col, next_col = st.columns([0.5, 1, 0.5])
                with prev_col:
                    if st.button("â¬…ï¸", disabled=(current_page <= 1), key="scan_prev"):
                        st.session_state.scan_page = max(1, current_page - 1)
                        st.rerun()
                with info_col:
                    st.caption(f"{current_page}/{total_pages}")
                with next_col:
                    if st.button("â¡ï¸", disabled=(current_page >= total_pages), key="scan_next"):
                        st.session_state.scan_page = min(total_pages, current_page + 1)
                        st.rerun()
                
                # ê²°ê³¼ í‘œì‹œ
                for symbol in page_results.index:
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        fms_score = page_results.loc[symbol, 'FMS']
                        st.write(f"**{symbol}** (FMS: {fms_score:.2f})")
                    with col2:
                        if st.button("â•", key=f"add_scan_{symbol}"):
                            st.session_state.watchlist = add_to_watchlist(st.session_state.watchlist, [symbol])
                            st.rerun()
            else:
                st.info("ì¡°ê±´ì— ë§ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            st.error(f"ìŠ¤ìº” ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

# 4. ìˆ˜ë™ ê´€ë¦¬ (ê°„ë‹¨í•œ ì¶”ê°€/ì‚­ì œ)
with st.sidebar.expander("âœï¸ ìˆ˜ë™ ê´€ë¦¬", expanded=False):
    # í‹°ì»¤ ì¶”ê°€
    new_ticker = st.text_input("í‹°ì»¤ ì¶”ê°€ (ì˜ˆ: AAPL)", "").upper().strip()
    if st.button("â• ì¶”ê°€"):
        if new_ticker and new_ticker not in st.session_state.watchlist:
            st.session_state.watchlist = add_to_watchlist(st.session_state.watchlist, [new_ticker])
            st.success(f"'{new_ticker}' ì¶”ê°€ë¨")
            st.rerun()
        elif new_ticker in st.session_state.watchlist:
            st.warning(f"'{new_ticker}'ëŠ” ì´ë¯¸ ê´€ì‹¬ì¢…ëª©ì— ìˆìŠµë‹ˆë‹¤.")
        else:
            st.error("ìœ íš¨í•œ í‹°ì»¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    # í‹°ì»¤ ì‚­ì œ
    if st.session_state.watchlist:
        ticker_to_remove = st.selectbox("ì‚­ì œí•  í‹°ì»¤ ì„ íƒ", [""] + st.session_state.watchlist)
        if st.button("ğŸ—‘ï¸ ì‚­ì œ"):
            if ticker_to_remove:
                st.session_state.watchlist = remove_from_watchlist(st.session_state.watchlist, [ticker_to_remove])
                st.success(f"'{ticker_to_remove}' ì‚­ì œë¨")
                st.rerun()
            else:
                st.error("ì‚­ì œí•  ì¢…ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

with st.sidebar.expander("ğŸ”§ ë„êµ¬ ë° ë„ì›€ë§", expanded=False):
    # FMS ì„¤ëª…
    st.markdown("**ğŸ“Š FMS (Fast Momentum Score)**")
    
    st.markdown(f"""
    **FMS = {FMS_FORMULA}**
    
    â€¢ **ì¶”ì„¸ ì§€ì†ì„±**: 1M + 3M ìˆ˜ìµë¥ ë¡œ ë‹¨ê¸°/ì¤‘ê¸° ëª¨ë©˜í…€ ì¢…í•© í‰ê°€
    â€¢ **ì•ˆì •ì„± ì¤‘ì‹œ**: ë³€ë™ì„± í˜ë„í‹° ê°•í™” (-0.4)ë¡œ ê¸‰ë“± ì¢…ëª© í•„í„°ë§
    â€¢ **EMA ìƒëŒ€ìœ„ì¹˜**: 50ì¼ ì§€ìˆ˜ì´ë™í‰ê·  ëŒ€ë¹„ í˜„ì¬ê°€ ìœ„ì¹˜ë¡œ ì¶”ì„¸ ê°•ë„ ì¸¡ì •
    â€¢ **ê±°ë˜ ì í•©ì„± í•„í„°**: 
      - ì¹˜ëª…ì  ë³€ë™ì„±: 63ê±°ë˜ì¼ ë‚´ ì¼ì¼ ë³€ë™í­ 30% ì´ˆê³¼ ì‹œ ì‹¤ê²©
      - ë°˜ë³µì  í•˜ë°©ë¦¬ìŠ¤í¬: 20ê±°ë˜ì¼ ë‚´ í•˜ë°©ë¦¬ìŠ¤í¬ -7% ë¯¸ë§Œ 4ì¼ ì´ìƒ ì‹œ ì‹¤ê²©
    â€¢ **ëª©í‘œ**: ê¾¸ì¤€í•˜ê³  ì§€ì† ê°€ëŠ¥í•œ ìƒìŠ¹ ì¶”ì„¸ ì¢…ëª© ë°œêµ´
    """)
    
    st.markdown("---")
    
    # ë„êµ¬ ë²„íŠ¼ë“¤
    if st.button("ğŸ—‚ï¸ ë°ì´í„° ìºì‹œ ì´ˆê¸°í™”"):
        st.cache_data.clear()
        st.success("ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    is_scanning, is_reassessing, button_disabled = get_button_states()
    if st.button("ğŸ”„ ê´€ì‹¬ì¢…ëª© ì´ˆê¸°í™”", disabled=button_disabled):
        default_symbols = DEFAULT_USD_SYMBOLS + DEFAULT_KRW_SYMBOLS + DEFAULT_JPY_SYMBOLS
        st.session_state.watchlist = default_symbols
        save_watchlist(default_symbols)
        st.success("ê´€ì‹¬ì¢…ëª©ì´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.rerun()



@st.cache_data(ttl=60*60*6, show_spinner=True)
def build_prices_krw(period_key="6M", watchlist_symbols=None):
    period_map = {"3M":"6mo","6M":"1y","1Y":"2y","2Y":"5y","5Y":"10y"}
    yf_period = period_map.get(period_key, "1y")
    interval = "1d"

    # ê´€ì‹¬ì¢…ëª© ëª©ë¡ì„ ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ì•„ì„œ ìºì‹œ í‚¤ì— í¬í•¨
    if watchlist_symbols is None:
        watchlist_symbols = st.session_state.watchlist

    # í˜„ì¬ ê´€ì‹¬ì¢…ëª©ì—ì„œ êµ­ê°€ë³„ë¡œ ë¶„ë¥˜
    usd_symbols = [str(s) for s in watchlist_symbols if classify(s) == "USA"]
    krw_symbols = [str(s) for s in watchlist_symbols if classify(s) == "KOR"]
    jpy_symbols = [str(s) for s in watchlist_symbols if classify(s) == "JPN"]

    usdkrw, usdjpy, jpykrw, fx_missing = download_fx(yf_period, interval)
    usd_df, miss_us = download_prices(usd_symbols, yf_period, interval)
    krw_df, miss_kr = download_prices(krw_symbols, yf_period, interval)
    jpy_df, miss_jp = download_prices(jpy_symbols, yf_period, interval)

    usd_df = align_bday_ffill(usd_df)
    krw_df = align_bday_ffill(krw_df)
    jpy_df = align_bday_ffill(jpy_df)
    usdkrw = align_bday_ffill(usdkrw.to_frame()).iloc[:,0] if not usdkrw.empty else usdkrw
    jpykrw = align_bday_ffill(jpykrw.to_frame()).iloc[:,0] if not jpykrw.empty else jpykrw

    frames=[]
    if not usd_df.empty and not usdkrw.empty:
        usdkrw_matched = usdkrw.reindex(usd_df.index).ffill()
        frames.append(usd_df.mul(usdkrw_matched, axis=0))
    if not krw_df.empty:
        frames.append(krw_df)
    if not jpy_df.empty and not jpykrw.empty:
        jpykrw_matched = jpykrw.reindex(jpy_df.index).ffill()
        frames.append(jpy_df.mul(jpykrw_matched, axis=0))

    if not frames:
        return pd.DataFrame(), {"fx_missing": fx_missing, "price_missing": miss_us+miss_kr+miss_jp}

    prices_krw = pd.concat(frames, axis=1).sort_index()
    prices_krw = prices_krw.loc[:, ~prices_krw.columns.duplicated()]
    prices_krw = harmonize_calendar(prices_krw, coverage=0.9)

    miss_dict = {
        "fx_missing": fx_missing,
        "price_missing": sorted(list(set(miss_us+miss_kr+miss_jp)))
    }
    last_row = prices_krw.iloc[-1]
    usa_cols = [c for c in prices_krw.columns if classify(c)=="USA"]
    na_usa = last_row[usa_cols].isna().sum()
    log(f"Final DF shape: {prices_krw.shape}; last row USA NaNs: {na_usa}/{len(usa_cols)}")
    return prices_krw, miss_dict

# ------------------------------
# ì´ë¦„ ìºì‹œ (ì˜êµ¬ íŒŒì¼ ê¸°ë°˜)
# ------------------------------
SYMBOL_NAMES_CACHE_FILE = "symbol_names_cache.json"

def load_symbol_names_cache():
    """
    ì¢…ëª©ëª… ìºì‹œ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Returns:
        dict: {symbol: name} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    try:
        if os.path.exists(SYMBOL_NAMES_CACHE_FILE):
            with open(SYMBOL_NAMES_CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        log(f"WARNING: Failed to load symbol names cache: {e}")
    return {}

def save_symbol_names_cache(cache_dict):
    """
    ì¢…ëª©ëª… ìºì‹œë¥¼ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        cache_dict (dict): {symbol: name} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    try:
        with open(SYMBOL_NAMES_CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(cache_dict, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log(f"WARNING: Failed to save symbol names cache: {e}")

def load_korean_stock_names():
    """
    korean_universe.csv íŒŒì¼ì—ì„œ í•œêµ­ ì¢…ëª©ëª…ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Returns:
        dict: {symbol: name} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    korean_names = {}
    try:
        if os.path.exists('korean_universe.csv'):
            df = pd.read_csv('korean_universe.csv')
            if 'Symbol' in df.columns and 'Name' in df.columns:
                for _, row in df.iterrows():
                    symbol = str(row['Symbol']).strip()
                    name = str(row['Name']).strip() if pd.notna(row['Name']) else None
                    if symbol and name:
                        korean_names[symbol] = name
    except Exception as e:
        log(f"WARNING: Failed to load Korean stock names: {e}")
    return korean_names

@st.cache_data(ttl=60*60*24, show_spinner=False)
def fetch_long_names(symbols):
    """
    ì¢…ëª©ëª…ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. í•œêµ­ ì¢…ëª©ì€ korean_universe.csvì—ì„œ ì½ê³ , 
    ë‹¤ë¥¸ ì¢…ëª©ì€ ì˜êµ¬ ìºì‹œ íŒŒì¼ ë˜ëŠ” yfinanceë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Args:
        symbols (list): ì¢…ëª© ì‹¬ë³¼ ëª©ë¡
    
    Returns:
        dict: {symbol: name} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    # í•œêµ­ ì¢…ëª©ëª… íŒŒì¼ì—ì„œ ë¡œë“œ
    korean_names = load_korean_stock_names()
    
    # ìºì‹œ íŒŒì¼ì—ì„œ ê¸°ì¡´ ì¢…ëª©ëª… ë¡œë“œ (í•œêµ­ ì¢…ëª© ì œì™¸)
    cache = load_symbol_names_cache()
    
    # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
    out = {}
    new_symbols = []
    
    # ì¢…ëª©ë³„ë¡œ ì²˜ë¦¬
    for symbol in symbols:
        # í•œêµ­ ì¢…ëª©(.KS)ì€ korean_universe.csvì—ì„œ ìš°ì„  í™•ì¸
        if symbol.endswith('.KS'):
            if symbol in korean_names:
                out[symbol] = korean_names[symbol]
            else:
                # íŒŒì¼ì— ì—†ìœ¼ë©´ ì¢…ëª©ì½”ë“œ ì‚¬ìš©
                out[symbol] = symbol
                log(f"WARNING: Korean stock name not found in korean_universe.csv: {symbol}")
        else:
            # í•œêµ­ ì¢…ëª©ì´ ì•„ë‹Œ ê²½ìš° ìºì‹œ í™•ì¸
            if symbol in cache:
                out[symbol] = cache[symbol]
            else:
                new_symbols.append(symbol)
    
    # ìºì‹œì— ì—†ëŠ” ë¹„í•œêµ­ ì¢…ëª©ë§Œ yfinanceì—ì„œ ê°€ì ¸ì˜¤ê¸°
    if new_symbols:
        log(f"Fetching names for {len(new_symbols)} non-Korean symbols from yfinance...")
        for symbol in new_symbols:
            name = None
            try:
                ticker = yf.Ticker(symbol)
                info = ticker.get_info()
                raw_name = info.get("longName") or info.get("shortName")
                
                if raw_name:
                    name = raw_name
                else:
                    name = symbol
                    
            except Exception as e:
                log(f"INFO name fetch fail: {symbol} -> {e}")
                name = symbol
            
            # ê²°ê³¼ ì €ì¥
            out[symbol] = name
            # ìºì‹œì—ë„ ì €ì¥
            cache[symbol] = name
        
        # ìºì‹œ íŒŒì¼ ì—…ë°ì´íŠ¸
        save_symbol_names_cache(cache)
    
    return out





# ------------------------------
# ë°ì´í„° ë¡œë“œ ë° ì´ë¦„
# ------------------------------
with st.spinner("ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
    prices_krw, miss = build_prices_krw(period, st.session_state.watchlist)
if prices_krw.empty:
    st.error("ê°€ê²© ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

with st.spinner("ì¢…ëª©ëª…(í’€ë„¤ì„) ë¡œë”© ì¤‘â€¦(ìµœì´ˆ 1íšŒë§Œ ë‹¤ì†Œ ì§€ì—°)"):
    NAME_MAP = fetch_long_names(list(prices_krw.columns))


st.title("âš¡ KRW Momentum Radar v3.6.0")



# ------------------------------
# ëª¨ë©˜í…€/ê°€ì† ê³„ì‚° (ê±°ë˜ ì í•©ì„± í•„í„° ì ìš©)
# ------------------------------
with st.spinner("ëª¨ë©˜í…€/ê°€ì† ê³„ì‚° ì¤‘â€¦"):
    # ê´€ì‹¬ì¢…ëª©ì˜ OHLC ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ê±°ë˜ ì í•©ì„± í•„í„°ìš©)
    watchlist_symbols = list(prices_krw.columns)
    period_map = {"3M":"6mo","6M":"1y","1Y":"2y","2Y":"5y","5Y":"10y"}
    ohlc_data, ohlc_missing = download_ohlc_prices(watchlist_symbols, period_map.get(period, "1y"), "1d")
    if ohlc_data.empty:
        ohlc_data = None
    
    mom = momentum_now_and_delta(prices_krw, reference_prices_krw=prices_krw, ohlc_data=ohlc_data, symbols=watchlist_symbols)
rank_col = {"Î”FMS(1D)":"Î”FMS_1D","Î”FMS(5D)":"Î”FMS_5D","FMS(í˜„ì¬)":"FMS","1M ìˆ˜ìµë¥ ":"R_1M"}[rank_by]
mom_ranked = mom.sort_values(rank_col, ascending=False)

# ------------------------------
# â‘  ê°€ì† ë³´ë“œ
# ------------------------------
st.subheader("ê°€ì† ë³´ë“œ")
topN = mom_ranked.head(TOP_N)
bar = go.Figure([go.Bar(
    x=topN.index, y=topN[rank_col],
    customdata=np.array([only_name(s) for s in topN.index]),
    hovertemplate="%{customdata} (%{x})<br>"+rank_col+": %{y:.2f}<extra></extra>"
)])
bar.update_layout(height=320, margin=dict(l=10,r=10,t=10,b=10), xaxis_tickangle=-45, yaxis_title=rank_col)
st.plotly_chart(bar, use_container_width=True, config={"displayModeBar": False})

# ------------------------------
# â‘¡ ë¹„êµ ì°¨íŠ¸ â€” Top N
# ------------------------------
st.subheader(f"ë¹„êµ ì°¨íŠ¸ â€” ìƒìœ„ {TOP_N} (ê¸°ì¤€: {rank_col})")
sel_syms = list(topN.index)
df_view = prices_krw[sel_syms].dropna(how="all")
win_map={"3M":63,"6M":126,"1Y":252,"2Y":504,"5Y":1260}
win = win_map.get(period,126)
if df_view.shape[0]>win: df_view = df_view.iloc[-win:]
df_base = df_view/df_view.iloc[0]*100.0
fig_comp = go.Figure()
for c in df_base.columns:
    nm_only = only_name(c)
    fig_comp.add_trace(go.Scatter(
        x=df_base.index, y=df_base[c], mode="lines", name=c,
        customdata=np.array([nm_only]*len(df_base)),
        hovertemplate="%{customdata} ("+c+")<br>%{x|%Y-%m-%d}<br>Index:%{y:.2f}<extra></extra>"
    ))
fig_comp.update_layout(
    height=420, margin=dict(l=10,r=10,t=10,b=10),
    yaxis=dict(type="log" if use_log_scale else "linear", title="Rebased 100"),
    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
)
st.plotly_chart(fig_comp, use_container_width=True)

# ------------------------------
# â‘¢ ì„¸ë¶€ ë³´ê¸°
# ------------------------------
st.subheader("ì„¸ë¶€ ë³´ê¸°")
ordered_options = list(mom_ranked.index)

if not ordered_options:
    st.session_state.detail_symbol_index = 0
    st.info("í‘œì‹œí•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. í•„í„° ì¡°ê±´ì„ ì¡°ì •í•˜ê±°ë‚˜ ë°ì´í„°ë¥¼ ìƒˆë¡œ ê³ ì¹¨í•´ ì£¼ì„¸ìš”.")
else:
    default_candidates = [sym for sym in sel_syms if sym in ordered_options]
    default_sym = default_candidates[0] if default_candidates else ordered_options[0]

    if "detail_symbol_index" not in st.session_state:
        st.session_state.detail_symbol_index = ordered_options.index(default_sym)

    # í˜„ì¬ ì„ íƒëœ ì¸ë±ìŠ¤ê°€ ìœ íš¨í•œ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ëŠ”ì§€ í™•ì¸
    if st.session_state.detail_symbol_index >= len(ordered_options):
        st.session_state.detail_symbol_index = len(ordered_options) - 1
    if st.session_state.detail_symbol_index < 0:
        st.session_state.detail_symbol_index = 0

    option_count = max(1, len(ordered_options))
    index_width = max(2, len(str(option_count)))
    option_labels = {
        sym: f"[{idx:0{index_width}d}] {display_name(sym)}"
        for idx, sym in enumerate(ordered_options, 1)
    }

    # selectboxì™€ ë„¤ë¹„ê²Œì´ì…˜ ë²„íŠ¼ì„ í•œ ì¤„ì— ë°°ì¹˜
    detail_col1, detail_col2, detail_col3, detail_col4 = st.columns([11, 1, 1, 1])

    # ë²„íŠ¼ í´ë¦­ ì²˜ë¦¬
    with detail_col2:
        # ì´ì „ ë²„íŠ¼ (â–²)
        prev_disabled = st.session_state.detail_symbol_index <= 0
        if st.button("â–²", disabled=prev_disabled, key="detail_prev", help="ì´ì „ ì¢…ëª©", use_container_width=True):
            if st.session_state.detail_symbol_index > 0:
                st.session_state.detail_symbol_index -= 1
                st.rerun()

    with detail_col3:
        # ë‹¤ìŒ ë²„íŠ¼ (â–¼)
        next_disabled = st.session_state.detail_symbol_index >= len(ordered_options) - 1
        if st.button("â–¼", disabled=next_disabled, key="detail_next", help="ë‹¤ìŒ ì¢…ëª©", use_container_width=True):
            if st.session_state.detail_symbol_index < len(ordered_options) - 1:
                st.session_state.detail_symbol_index += 1
                st.rerun()

    with detail_col4:
        # ë§¨ ëìœ¼ë¡œ ê°€ê¸° ë²„íŠ¼ (â¬)
        end_disabled = st.session_state.detail_symbol_index >= len(ordered_options) - 1
        if st.button("â¬", disabled=end_disabled, key="detail_end", help="ë§¨ ëìœ¼ë¡œ ì´ë™", use_container_width=True):
            if st.session_state.detail_symbol_index < len(ordered_options) - 1:
                st.session_state.detail_symbol_index = len(ordered_options) - 1
                st.rerun()

    with detail_col1:
        # selectboxì˜ keyë¥¼ ì¸ë±ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ë™ì  ìƒì„±í•˜ì—¬ ë²„íŠ¼ í´ë¦­ ì‹œ ìƒˆë¡œìš´ ìƒíƒœë¡œ ì¸ì‹
        selectbox_key = f"detail_selectbox_{st.session_state.detail_symbol_index}"

        detail_sym = st.selectbox(
            "",
            options=ordered_options,
            index=st.session_state.detail_symbol_index,
            format_func=lambda s: option_labels.get(s, display_name(s)),
            key=selectbox_key,
            label_visibility="collapsed",
        )

        # selectbox ë³€ê²½ ì‹œ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ (ì‚¬ìš©ìê°€ ì§ì ‘ ì„ íƒí•œ ê²½ìš°)
        if detail_sym in ordered_options:
            new_index = ordered_options.index(detail_sym)
            if new_index != st.session_state.detail_symbol_index:
                st.session_state.detail_symbol_index = new_index
                st.rerun()

    s = prices_krw[detail_sym].dropna()
    e20, e50, e200 = ema(s, 20), ema(s, 50), ema(s, 200)
    fig_det = go.Figure()
    fig_det.add_trace(go.Scatter(x=s.index, y=s.values, mode="lines", name="KRW"))
    fig_det.add_trace(go.Scatter(x=e20.index, y=e20.values, mode="lines", name="EMA20"))
    fig_det.add_trace(go.Scatter(x=e50.index, y=e50.values, mode="lines", name="EMA50"))
    fig_det.add_trace(go.Scatter(x=e200.index, y=e200.values, mode="lines", name="EMA200"))
    fig_det.update_layout(
        height=420,
        margin=dict(l=10, r=10, t=10, b=10),
        yaxis_title="KRW",
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=-0.15,
            xanchor="center",
            x=0.5,
        ),
    )
    st.plotly_chart(fig_det, use_container_width=True, config={"displayModeBar": False})

    roll_max = s.cummax()
    dd = (s / roll_max - 1.0) * 100.0
    fig_dd = go.Figure([go.Scatter(x=dd.index, y=dd.values, mode="lines", name="Drawdown(%)")])
    fig_dd.update_layout(height=180, margin=dict(l=10, r=10, t=10, b=10), yaxis_title="%")
    st.plotly_chart(fig_dd, use_container_width=True, config={"displayModeBar": False})

    row = mom.loc[detail_sym]
    badges = []
    if row["R_1M"] > 0:
        badges.append("1M +")
    if row["AboveEMA50"] > 0:
        badges.append("EMA50 ìƒíšŒ")

    # FMS ì§€í‘œ í‘œì‹œ
    if "R_3M" in row and row["R_3M"] > 0:
        badges.append("3M +")

    if row["Î”FMS_1D"] > 0:
        badges.append("ê°€ì†(1D+)")
    if row["Î”FMS_5D"] > 0:
        badges.append("ê°€ì†(5D+)")
    st.markdown(
        " ".join([f"<span class='badge'>{b}</span>" for b in badges]) or "<span class='small'>ìƒíƒœ ë°°ì§€ ì—†ìŒ</span>",
        unsafe_allow_html=True,
    )

# ==============================
# â‘£ ìˆ˜ìµë¥ â€“ë³€ë™ì„± ì´ë™ë§µ
# ==============================
st.subheader("ìˆ˜ìµë¥ â€“ë³€ë™ì„± ì´ë™ë§µ (ìµœê·¼ ìƒíƒœ â†’ ì–´ë””ì„œ ì™”ëŠ”ê°€)")

cc1, cc2, cc3, cc4 = st.columns([1.2,1.2,1.2,1.6])
with cc1:
    rv_window = st.selectbox("ìˆ˜ìµë¥ /ë³€ë™ì„± ì°½(ê±°ë˜ì¼)", [21, 42, 63], index=0, help="ì—°ìœ¨í™”: 252 ê¸°ì¤€")
with cc2:
    plot_n = st.selectbox("í‘œì‹œ ì¢…ëª© ìˆ˜", [10, 15, 20, 25, 30], index=2, help="ìƒìœ„ ë­í‚¹ ê¸°ì¤€ìœ¼ë¡œ ì œí•œí•´ ê³¼ë°€ë„ ì™„í™”")
with cc4:
    motion_mode = st.selectbox("ëª¨ì…˜(ì• ë‹ˆë©”ì´ì…˜)", ["ë„ê¸°", "ìµœê·¼ 10ì¼", "ìµœê·¼ 20ì¼"], index=0,
                               help="í”„ë ˆì„ë§ˆë‹¤ í˜„ì¬ ìœ„ì¹˜ì™€ ê¼¬ë¦¬ë¥¼ ë™ì‹œì— ê°±ì‹ ")
with cc3:
    # ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œê°€ ì„ íƒë˜ë©´ ê¼¬ë¦¬ ê¸¸ì´ë¥¼ 5ë¡œ ìë™ ì„¤ì •
    if motion_mode != "ë„ê¸°":
        tail_days = st.selectbox("ê¼¬ë¦¬ ê¸¸ì´(ìµœê·¼ nì¼ ê²½ë¡œ)", [0, 3, 5, 10], index=2, help="ì˜¤ëŠ˜ ê¸°ì¤€ ê³¼ê±° nê±°ë˜ì¼ì˜ ì´ë™ ê²½ë¡œë¥¼ ì ì„ ìœ¼ë¡œ í‘œì‹œ")
    else:
        tail_days = st.selectbox("ê¼¬ë¦¬ ê¸¸ì´(ìµœê·¼ nì¼ ê²½ë¡œ)", [0, 3, 5, 10], index=0, help="ì˜¤ëŠ˜ ê¸°ì¤€ ê³¼ê±° nê±°ë˜ì¼ì˜ ì´ë™ ê²½ë¡œë¥¼ ì ì„ ìœ¼ë¡œ í‘œì‹œ")

def ann_vol(series, win):
    r = series.pct_change().dropna()
    if len(r) < max(5, int(win/3)): return np.nan
    r = r.tail(win);  return r.std() * np.sqrt(252.0)

def ann_cagr(series, win):
    s = series.dropna().tail(win+1)
    if len(s) < win+1: return np.nan
    start, end = s.iloc[-(win+1)], s.iloc[-1]
    if start <= 0 or end <= 0: return np.nan
    return (end/start)**(252.0/win) - 1.0

def scatter_points_for_date(df_prices, ref_loc, win):
    if ref_loc < 1: return pd.DataFrame()
    pts = {}
    for c in df_prices.columns:
        s = df_prices[c].iloc[:ref_loc+1]
        v = ann_vol(s, win); g = ann_cagr(s, win)
        pts[c] = (v, g)
    return pd.DataFrame(pts, index=["Vol","CAGR"]).T

plot_syms = list(mom_ranked.head(plot_n).index)
idx_all = prices_krw.index
today_loc = len(idx_all) - 1
yesterday_loc = max(0, today_loc - 1)
monthago_loc = max(0, today_loc - 21)

pts_today = scatter_points_for_date(prices_krw[plot_syms], today_loc, rv_window)
pts_yest  = scatter_points_for_date(prices_krw[plot_syms], yesterday_loc, rv_window)
pts_mago  = scatter_points_for_date(prices_krw[plot_syms], monthago_loc, rv_window)

# --- ê¼¬ë¦¬ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ìœ í‹¸(ì—°í•œâ†’ì§„í•œ)
def add_tail_segments(fig, sym, tail_len, color="rgba(0,0,0,1)"):
    if tail_len <= 0: return
    # loc: today - tail_len ... today
    prev_xy = None
    for k in range(tail_len, -1, -1):
        loc = max(0, today_loc - k)
        p = scatter_points_for_date(prices_krw[[sym]], loc, rv_window)
        if p.empty or p.isna().any().any(): 
            prev_xy = None
            continue
        x = float(p.iloc[0,0])*100.0  # Vol%
        y_raw = float(p.iloc[0,1])*100.0  # CAGR%
        y = max(y_raw + 100.0, 0.1)  # ë¡œê·¸ ìŠ¤ì¼€ì¼ì„ ìœ„í•œ offset ì ìš© (100 = 0%, ìµœì†Œê°’ 0.1 ë³´ì¥)
        if prev_xy is not None:
            age = (tail_len - k + 1)  # ìµœê·¼ì¼ìˆ˜ë¡ ì‘ìŒ
            alpha = max(0.15, min(0.5, age/(tail_len+1)))  # 0.15~0.5
            fig.add_trace(go.Scatter(
                x=[prev_xy[0], x], y=[prev_xy[1], y],
                mode="lines", line=dict(width=2, dash="dot"),
                showlegend=False, hoverinfo="skip", opacity=alpha, name=f"{sym}-tail"
            ))
        prev_xy = (x, y)

# --- ì •ì (3ì  + ì´ë™ì„  + ê¼¬ë¦¬)
def make_static_scatter():
    fig = go.Figure()
    # ê¼¬ë¦¬: ì‹¬ë³¼ë³„ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
    for c in plot_syms:
        add_tail_segments(fig, c, tail_days)

    # ê¼¬ë¦¬ ê¸¸ì´ê°€ 0ì¼ ë•Œë§Œ ê³¼ê±° ì‹œì ë“¤ í‘œì‹œ
    if tail_days == 0:
        # 1M ago (ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ í‘œì‹œ)
        if not pts_mago.empty and "CAGR" in pts_mago.columns:
            cagr_mago = pts_mago["CAGR"]*100
            fig.add_trace(go.Scatter(
                x=pts_mago["Vol"]*100, y=(cagr_mago + 100).clip(lower=0.1), mode="markers",
                marker=dict(size=7, color="lightgray"),
                text=[display_name(s) for s in pts_mago.index],
                customdata=cagr_mago.values,
                hovertemplate="%{text}<br>1M ago<br>Vol: %{x:.2f}% | CAGR: %{customdata:.2f}%<extra></extra>",
                name="1M ago", showlegend=True
            ))
        # Yesterday (ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ í‘œì‹œ)
        if not pts_yest.empty and "CAGR" in pts_yest.columns:
            cagr_yest = pts_yest["CAGR"]*100
            fig.add_trace(go.Scatter(
                x=pts_yest["Vol"]*100, y=(cagr_yest + 100).clip(lower=0.1), mode="markers",
                marker=dict(size=8, color="silver"),
                text=[display_name(s) for s in pts_yest.index],
                customdata=cagr_yest.values,
                hovertemplate="%{text}<br>Yesterday<br>Vol: %{x:.2f}% | CAGR: %{customdata:.2f}%<extra></extra>",
                name="Yesterday", showlegend=True
            ))
    # Today (ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ í‘œì‹œ)
    if not pts_today.empty and "CAGR" in pts_today.columns:
        cagr_today = pts_today["CAGR"]*100
        fig.add_trace(go.Scatter(
            x=pts_today["Vol"]*100, y=(cagr_today + 100).clip(lower=0.1), mode="markers+text",
            marker=dict(size=9),
            text=[display_name(s) for s in pts_today.index],
            textposition="top center",
            customdata=cagr_today.values,
            hovertemplate="%{text}<br>Today<br>Vol: %{x:.2f}% | CAGR: %{customdata:.2f}%<extra></extra>",
            name="Today", showlegend=True
        ))
    # ê¼¬ë¦¬ ê¸¸ì´ê°€ 0ì¼ ë•Œë§Œ 1Mâ†’Yestâ†’Today ì—°ê²°ì„  í‘œì‹œ (ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ)
    if tail_days == 0:
        for c in plot_syms:
            xs=[]; ys=[]
            for dfp in (pts_mago, pts_yest, pts_today):
                if not dfp.empty and "CAGR" in dfp.columns and c in dfp.index and not dfp.loc[c].isna().any():
                    xs.append(float(dfp.loc[c,"Vol"])*100)
                    y_val = float(dfp.loc[c,"CAGR"])*100 + 100
                    ys.append(max(y_val, 0.1))  # offset ì ìš© (ìµœì†Œê°’ 0.1 ë³´ì¥)
            if len(xs)>=2:
                fig.add_trace(go.Scatter(x=xs, y=ys, mode="lines",
                                         line=dict(width=1), opacity=0.35,
                                         name=f"path-{c}", showlegend=False, hoverinfo="skip"))
    fig.update_layout(
        height=520, margin=dict(l=10,r=10,t=10,b=10),
        xaxis_title="Volatility (ann, %)", yaxis_title="CAGR (ann, %), log scale (100 = 0%)",
        yaxis=dict(type="log"),
        hovermode="closest"
    )
    return fig

# --- ì• ë‹ˆë©”ì´ì…˜: í”„ë ˆì„ë§ˆë‹¤ í˜„ì¬ ìœ„ì¹˜ + ê° ì¢…ëª© ê¼¬ë¦¬ ë™ì‹œ ê°±ì‹ 
def make_motion_scatter(days):
    days = min(days, len(idx_all)-1)
    start_loc = max(0, today_loc - days)
    frames = []

    # ì´ˆê¸° í”„ë ˆì„ ë°ì´í„°
    p0 = scatter_points_for_date(prices_krw[plot_syms], start_loc, rv_window)
    traces = []

    # ê¼¬ë¦¬ëŠ” ì‹¬ë³¼ë³„ë¡œ ê°œë³„ traceë¥¼ ì‚¬ìš©(í”„ë ˆì„ë§ˆë‹¤ ì¬ê³„ì‚°)
    # ì´ˆê¸° ê¼¬ë¦¬
    tail_traces = []
    for c in plot_syms:
        # ë¹ˆ ê¼¬ë¦¬(ì´ˆê¸°)
        tail_traces.append(go.Scatter(x=[], y=[], mode="lines", line=dict(width=2, dash="dot"),
                                      showlegend=False, hoverinfo="skip", name=f"{c}-tail"))

    # ì´ˆê¸° í¬ì¸íŠ¸ (ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ)
    traces.extend(tail_traces)
    if not p0.empty and "CAGR" in p0.columns:
        cagr_p0 = p0["CAGR"]*100
        traces.append(go.Scatter(
            x=p0["Vol"]*100, y=(cagr_p0 + 100).clip(lower=0.1), mode="markers+text",
            marker=dict(size=9),
            text=[display_name(s) for s in p0.index],
            textposition="top center",
            customdata=cagr_p0.values,
            hovertemplate="%{text}<br>Vol: %{x:.2f}% | CAGR: %{customdata:.2f}%<extra></extra>",
            name="Points", showlegend=False
        ))

    # í”„ë ˆì„ ìƒì„±
    for loc in range(start_loc, today_loc+1):
        p = scatter_points_for_date(prices_krw[plot_syms], loc, rv_window)
        frame_data = []

        # ê° ì¢…ëª© ê¼¬ë¦¬ ì¢Œí‘œ ê³„ì‚°
        for c in plot_syms:
            xs=[]; ys=[]
            for k in range(tail_days, -1, -1):
                loc_k = max(0, loc - k)
                pk = scatter_points_for_date(prices_krw[[c]], loc_k, rv_window)
                if pk.empty or pk.isna().any().any(): 
                    continue
                xs.append(float(pk.iloc[0,0])*100.0)
                y_val = float(pk.iloc[0,1])*100.0 + 100.0
                ys.append(max(y_val, 0.1))  # offset ì ìš© (ìµœì†Œê°’ 0.1 ë³´ì¥)
            frame_data.append(go.Scatter(x=xs, y=ys, mode="lines", line=dict(width=2, dash="dot"),
                                         showlegend=False, hoverinfo="skip", name=f"{c}-tail"))
        # í¬ì¸íŠ¸ (ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ)
        if not p.empty and "CAGR" in p.columns:
            cagr_p = p["CAGR"]*100
            frame_data.append(go.Scatter(
                x=p["Vol"]*100, y=(cagr_p + 100).clip(lower=0.1), mode="markers+text",
                marker=dict(size=9),
                text=[display_name(s) for s in p.index],
                textposition="top center",
                customdata=cagr_p.values,
                hovertemplate="%{text}<br>Vol: %{x:.2f}% | CAGR: %{customdata:.2f}%<extra></extra>",
                name="Points", showlegend=False
            ))

        frames.append(go.Frame(data=frame_data, name=str(prices_krw.index[loc].date())))

    fig = go.Figure(data=traces, frames=frames)
    # ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œì— ë”°ë¥¸ ìë™ ì¬ìƒ ì„¤ì •
    auto_play = motion_mode != "ë„ê¸°"
    
    fig.update_layout(
        height=520, margin=dict(l=10,r=10,t=10,b=10),
        xaxis_title="Volatility (ann, %)", yaxis_title="CAGR (ann, %), log scale (100 = 0%)",
        yaxis=dict(type="log"),
        updatemenus=[{
            "type": "buttons", "showactive": False,
            "buttons": [
                {"label":"â–¶ Play","method":"animate",
                 "args":[None, {"frame":{"duration":300, "redraw":True}, "fromcurrent":True, "transition":{"duration":0}}]},
                {"label":"â¸ Pause","method":"animate","args":[[None], {"frame":{"duration":0}, "mode":"immediate"}]}
            ]
        }],
        sliders=[{
            "steps":[{"label":f.name, "method":"animate", "args":[[f.name], {"mode":"immediate","frame":{"duration":0,"redraw":True}}]} for f in frames],
            "currentvalue":{"prefix":"Date: "}
        }]
    )
    
    # ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œê°€ ì„ íƒë˜ë©´ ìë™ ì¬ìƒ
    if auto_play:
        fig.update_layout(
            updatemenus=[{
                "type": "buttons", "showactive": False,
                "buttons": [
                    {"label":"â–¶ Play","method":"animate",
                     "args":[None, {"frame":{"duration":300, "redraw":True}, "fromcurrent":True, "transition":{"duration":0}}]},
                    {"label":"â¸ Pause","method":"animate","args":[[None], {"frame":{"duration":0}, "mode":"immediate"}]}
                ]
            }]
        )
    return fig

# ë Œë”

if motion_mode == "ë„ê¸°":
    fig_mv = make_static_scatter()
else:
    days = 10 if "10" in motion_mode else 20
    fig_mv = make_motion_scatter(days)
    
    # ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œì¼ ë•Œ ìë™ ì¬ìƒì„ ìœ„í•œ JavaScript ì¶”ê°€
    if motion_mode != "ë„ê¸°":
        st.markdown("""
        <script>
        setTimeout(function() {
            var plotlyDiv = document.querySelector('[data-testid="stPlotlyChart"] iframe');
            if (plotlyDiv) {
                plotlyDiv.onload = function() {
                    var plotlyFrame = plotlyDiv.contentWindow;
                    if (plotlyFrame && plotlyFrame.Plotly) {
                        setTimeout(function() {
                            plotlyFrame.Plotly.animate(plotlyFrame.document.querySelector('.plotly-graph-div'), null, {
                                frame: {duration: 300, redraw: true},
                                fromcurrent: true,
                                transition: {duration: 0}
                            });
                        }, 1000);
                    }
                };
            }
        }, 500);
        </script>
        """, unsafe_allow_html=True)

st.plotly_chart(fig_mv, use_container_width=True)
st.caption("ì„¤ëª…: ê° ì ì€ ì„ íƒí•œ ì°½(ê¸°ë³¸ 21ê±°ë˜ì¼)ì˜ ì—°ìœ¨í™” ìˆ˜ìµë¥ (CAGR)Â·ì—°ìœ¨í™” ë³€ë™ì„±ì…ë‹ˆë‹¤. "
           "â€˜ê¼¬ë¦¬ ê¸¸ì´â€™ëŠ” ì˜¤ëŠ˜ ê¸°ì¤€ ê³¼ê±° nê±°ë˜ì¼ ë™ì•ˆ ì¢Œí‘œì˜ ì´ë™ ê²½ë¡œë¥¼ ì ì„ ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤. "
           "ì• ë‹ˆë©”ì´ì…˜ ëª¨ë“œì—ì„œëŠ” ë‚ ì§œê°€ ë°”ë€œì— ë”°ë¼ í˜„ì¬ ìœ„ì¹˜ì™€ ê¼¬ë¦¬ê°€ í•¨ê»˜ ê°±ì‹ ë©ë‹ˆë‹¤.")

# ------------------------------
# â‘¤ í‘œ (ì»¬ëŸ¼ ìë™ ì¬êµ¬ì„±)
# ------------------------------
st.subheader("ëª¨ë©˜í…€ í…Œì´ë¸” (ê°€ì†/ì¶”ì„¸/ìˆ˜ìµë¥ )")
disp = mom.copy()

# FMS ì»¬ëŸ¼ í‘œì‹œ
for c in ["R_1W","R_1M","R_3M","R_6M","R_YTD","AboveEMA50"]:
    if c in disp: disp[c] = (disp[c]*100).round(2)

for c in ["FMS","Î”FMS_1D","Î”FMS_5D"]:
    if c in disp: disp[c] = disp[c].round(2)

# ì»¬ëŸ¼ ìë™ ì¬êµ¬ì„±: FMS ì „ëµì— ë§ì¶° ë™ì  ì»¬ëŸ¼ ìˆœì„œ ìƒì„±
def generate_dynamic_column_order(fms_formula, available_columns):
    """
    FMS ì „ëµì— ë§ì¶° ë™ì  ì»¬ëŸ¼ ìˆœì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        fms_formula (str): FMS ê³µì‹ ë¬¸ìì—´
        available_columns (list): ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ ëª©ë¡
    
    Returns:
        list: ì¬êµ¬ì„±ëœ ì»¬ëŸ¼ ìˆœì„œ
    """
    
    # 1. Symbol ì»¬ëŸ¼ (ê°€ì¥ ì™¼ìª½)
    column_order = []
    if 'Symbol' in available_columns:
        column_order.append('Symbol')
    
    # 2. FMS ì»¬ëŸ¼ (ë‘ ë²ˆì§¸)
    if 'FMS' in available_columns:
        column_order.append('FMS')
    
    # 3. FMS ê³µì‹ì—ì„œ ì‚¬ìš©ëœ ë³€ìˆ˜ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì¶”ì¶œ
    fms_variables = []
    
    # ê³µì‹ì—ì„œ ë³€ìˆ˜ëª… ì¶”ì¶œ (ì •ê·œì‹ ì‚¬ìš©)
    # ì˜ˆ: "0.4 * Z('1Mìˆ˜ìµë¥ ') + 0.3 * Z('3Mìˆ˜ìµë¥ ')" -> ['1Mìˆ˜ìµë¥ ', '3Mìˆ˜ìµë¥ ']
    variable_pattern = r"Z\('([^']+)'\)"
    matches = re.findall(variable_pattern, fms_formula)
    
    # ë³€ìˆ˜ëª…ì„ ì‹¤ì œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë§¤í•‘
    variable_mapping = {
        '1Mìˆ˜ìµë¥ ': 'R_1M',
        '3Mìˆ˜ìµë¥ ': 'R_3M', 
        'EMA50ìƒëŒ€ìœ„ì¹˜': 'AboveEMA50',
        '20ì¼ë³€ë™ì„±': 'Vol20(ann)'
    }
    
    for var_name in matches:
        if var_name in variable_mapping:
            col_name = variable_mapping[var_name]
            if col_name in available_columns and col_name not in column_order:
                fms_variables.append(col_name)
    
    # FMS ë³€ìˆ˜ë“¤ì„ ê³µì‹ì— ë‚˜íƒ€ë‚œ ìˆœì„œëŒ€ë¡œ ì¶”ê°€
    column_order.extend(fms_variables)
    
    # 4. ë‚˜ë¨¸ì§€ ë³´ì¡° ë³€ìˆ˜ë“¤ ì¶”ê°€
    remaining_columns = [col for col in available_columns if col not in column_order]
    
    # ë³´ì¡° ë³€ìˆ˜ë“¤ì„ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì •ë ¬
    priority_order = ['Î”FMS_1D', 'Î”FMS_5D', 'R_1W', 'R_6M', 'R_YTD']
    prioritized_remaining = []
    for priority_col in priority_order:
        if priority_col in remaining_columns:
            prioritized_remaining.append(priority_col)
            remaining_columns.remove(priority_col)
    
    # ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ë“¤ì„ ì•ŒíŒŒë²³ ìˆœìœ¼ë¡œ ì •ë ¬
    remaining_columns.sort()
    
    column_order.extend(prioritized_remaining)
    column_order.extend(remaining_columns)
    
    return column_order

# í˜„ì¬ FMS ì „ëµì˜ ê³µì‹ ê°€ì ¸ì˜¤ê¸°
current_fms_formula = FMS_FORMULA

# ë™ì  ì»¬ëŸ¼ ìˆœì„œ ìƒì„±
dynamic_column_order = generate_dynamic_column_order(current_fms_formula, list(disp.columns))

# ì»¬ëŸ¼ ìˆœì„œ ì ìš© (ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ)
final_column_order = [col for col in dynamic_column_order if col in disp.columns]

# ë°ì´í„°í”„ë ˆì„ ì¬êµ¬ì„±
disp_reordered = disp[final_column_order]

# ì •ë ¬ ì ìš©
disp_reordered = disp_reordered.sort_values(rank_col if rank_col in disp_reordered.columns else "FMS", ascending=False)

st.dataframe(disp_reordered, use_container_width=True)

# ------------------------------
# â‘¥ ë””ë²„ê·¸/ì§„ë‹¨
# ------------------------------
with st.expander("ë””ë²„ê·¸ ë¡œê·¸ / ì§„ë‹¨ (ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥)"):
    last_row = prices_krw.iloc[-1]
    usa_cols = [c for c in prices_krw.columns if classify(c)=="USA"]
    kor_cols = [c for c in prices_krw.columns if classify(c)=="KOR"]
    jpn_cols = [c for c in prices_krw.columns if classify(c)=="JPN"]
    diag = {
        "last_date": str(prices_krw.index[-1].date()),
        "cols_total": prices_krw.shape[1],
        "last_notna_total": int(last_row.notna().sum()),
        "last_notna_USA": int(last_row[usa_cols].notna().sum()),
        "last_notna_KOR": int(last_row[kor_cols].notna().sum()),
        "last_notna_JPN": int(last_row[jpn_cols].notna().sum()),
        "env_CURL_CFFI_DISABLE_CACHE": os.environ.get("CURL_CFFI_DISABLE_CACHE")
    }
    st.json(diag)
    st.text_area("LOG", value="\n".join(st.session_state["LOG"][-400:]), height=200)
